{"./":{"url":"./","title":"README","keywords":"","body":"《Introduce》 有些知识曾经会过！ 好记性不如烂笔头！ 关于 Notes 这是我利用 GitBook 搭建的笔记记录：📖 Ariescat's Notes 此非大而全的知识图谱，是踏上编程的不归路后，陆陆续续把学到的重要知识记录于此 可能有些知识现在不记得了，但曾经记录过，就说明会过（doge 好记性不如烂笔头，也便于温故知新 （我还搭建了个小Blog网页 Ariescat's Blog，偶尔想起来的时候也会写写博客的） 栖身之所： 现源代码托管于 Github，由 GitHub 自动部署于 Vercel、Coding Pages。 为何选择 Vercel? 折腾的心不想受限于 Github Page； 至于 Coding Pages，那是因为以上平台对墙内的世界并不友好，访问速度让人 jio 急。 （现在境内的线路会自动分发至 Coding Pages，并由 腾讯云的 CDN 加速 🚀🚀 ） Timeline： 2021-09-15：把 源笔记 迁移至此，小站此步；由本地搭建 gitbook-cli 环境，build 后手动推送页面到仓库的 gh-pages 分支，部署于 Github Pages。 2021-09-16：由于部署太繁琐，采用了 gh-pages - npm (npmjs.com)，并编写了脚本进行部署。 2021-09-17：完成模块拆分，细分笔记。 2021-09-18：采用 Github Actions，自动持续集成部署，解放双手~~ 此后只要提交到 Github 就行啦。 2021-09-30：引入 gittalk 评论系统。 2021-12-25：由于 Coding Page 将于年底停止提供「网站托管」服务，现已迁移至某云的 Serverless 托管。 2024-03-15：CSS 实现 auto-numbering。 关于 我 Hey，I'm Ariescat，一只在广州苟活的程序猿。 九〇后，性别男，直男，爱好女。 有时文艺，有时逗比，乐观，不怕生。 有时候看书，喜欢折腾一些东西。 现在躺平，可能是一个废物。 感谢 GitBook：GitBook 简明教程 在线排版工具：TTS (cyc2018.github.io) 表格转HTML：要想 MarkDown 中插入复杂表格时，可以先在 word 或 excel 中把表格写好，然后在如下网站进行转化为标记对形式：http://pressbin.com/tools/excel_to_html_table/index.html Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Base/Java.html":{"url":"Note_Base/Java.html","title":"Java","keywords":"","body":"《Java》 思想是灵魂， 实现是形式。 Java 基础 基本类型 强转 long 转 int 注意：最高位为 1 强转会为负数！ 如：正数 2147483648（long 类型）强转 int 会变成负数，（int）0x80000000 => -2147483648(Integer.MIN_VALUE) 无符号类型 java 中无符号类型的解决方案 Java8 包装类 新增 无符号运算方法 byte 转换 int 时与 0xff 进行与运算的原因 Integer Java Integer(-128~127)值的==和equals比较产生的思考 - CSniper - 博客园 (cnblogs.com) 浮点数怎么存储 计算机与数学 —— 雷神之锤3源码中的快速逆平方根算法 String 正则表达式 Java 中的 String 有没有长度限制？ 数组呢？ StringJoiner（Java 8 中提供的可变字符串类） char JAVA 的 char 内部编码为 UTF-16 ，而与 Charset.defaultCharset() 无关 String s = new String(\"a\") 到底产生几个对象？ 对于通过 new 产生一个字符串（\"a\"）时，会先去常量池中查找是否已经有了”a”对象，如果没有则在常量池中创建一个此字符串对象，然后堆中再创建一个常量池中此\"a\"对象的拷贝对象。 也就是说准确答案是产生了一个或两个对象，如果常量池中原来没有\"a\"，就是两个。反之就是一个。 是的！如果面试官问到，回答一个或两个即可，但是…毕竟…毕竟 毕竟我和在座的各位都是人才，Java 知识底蕴不能如此短浅，这题还没谢幕我们还能对面试官多哔哔几句：字符串常量池在不同版本的 jvm 中可能位置不同，那么这又是一个老梗了。（在 JDK6.0 及之前版本，字符串常量池是放在 Perm Gen 区 (也就是方法区) 中；在 JDK7.0 版本，字符串常量池被移到了堆中了） StringBuilder 国内 Java 面试总是问 StringBuffer，StringBuilder 区别是啥？档次为什么这么低？ 扩展： intern 方法 深入解析 String#intern 关键点是 jdk7 中常量池不在 Perm 区域了，这块做了调整。常量池中不需要再存储一份对象了，可以直接存储堆中的引用 此外，Java 中的常量池有字符串常量池、class 常量池和运行时常量池。原文 常量池会被回收吗？ 枚举 枚举详解之 EnumSet、EnumMap 用法 RegularEnumSet里面有这样一行代码： elements = -1L >>> -universe.length; 无符号右移一个负数！是一个负移位量！ 换个例子看一下：-1 >>> -5 其实等同 -1 >>> 27；-1L >>> -5 等同 -1L >>> 59 如果移位量超过位数：-1 >>> 32 其实等同 -1 >>> 0；-1 >>> 33 等同 -1 >>> 1 数组 二维数组按行和按列遍历效率？ CPU 高速缓存 内存分页调度 参考：二维数组按行和按列遍历效率醒来明月的博客-CSDN 博客二维数组访问效率 运算符 左移 右移 操作符 描述 例子 按位左移运算符。左操作数按位左移右操作数指定的位数。 A >> 按位右移运算符。左操作数按位右移右操作数指定的位数。 A >> 2 得到 15 即 1111 >>> 按位右移补零操作符。左操作数的值按右操作数指定的位数右移，移动得到的空位以零填充。 A>>>2 得到 15 即 0000 1111 优先级 运算符优先级，左右优先级 日期与时间 Date 和 Calendar，LocalDateTime（Java8），ZonedDateTime（时区），Instant LocalDate/LocalTime 类 Java 8 新增了 LocalDate 和 LocalTime 接口，为什么要搞一套全新的处理日期和时间的 API？因为旧的 java.util.Date 实在是太难用了： java.util.Date 月份从0开始，一月是 0，十二月是 11，变态吧！java.time.LocalDate 月份和星期都改成了 enum，就不可能再用错了。 java.util.Date 和 SimpleDateFormatter 都不是线程安全的，而 LocalDate 和 LocalTime 和最基本的 String 一样，是不变类型，不但线程安全，而且不能修改。 Instant Instant 获取的是 UTC 的时间，而 Date 是根据当前服务器所处的环境的默认时区来获取的当前时间。 泛型 擦拭，extends 通配符，super 通配符 问题： 为什么泛型编译期擦除了，getGenericSuperclass 或反射等还能获取得到？ Java 泛型类型擦除与运行时类型获取 - linghu_java - 博客园 (cnblogs.com) 异常 Error 和 Exception 的区别 finally语句到底是在return之前还是之后执行？ 不管有木有出现异常，finally块中代码都会执行； 当try和catch中有return时，finally仍然会执行； finally是在return语句执行之后，返回之前执行的（此时并没有返回运算后的值，而是先把要返回的值保存起来，不管finally中的代码怎么样，返回的值都不会改变，仍然是之前保存的值），所以函数返回值是在finally执行前就已经确定了； finally中如果包含return，那么程序将在这里返回，而不是try或catch中的return返回，返回值就不是try或catch中保存的返回值了。 位运算 ^“异或运算”的特殊作用： （1）使特定位翻转找一个数，对应 X 要翻转的各位，该数的对应位为 1，其余位为零，此数与 X 对应位异或即可。 例：X=10101110，使 X 低 4 位翻转，用 X ^ 0000 1111 = 1010 0001 即可得到。 （2）与 0 相异或，保留原值 ，X ^ 0000 0000 = 1010 1110。 ~取反: 注意最高位也会取反 Math log 在 Java 中求 log2N，首先要弄明白一个初中学到的公式 log2N=logeN/loge2 ，logeN 代表以 e 为底的 N 的对数，loge2 代表以 e 为底的 2 的对数 在 java.lang.math 类中的 log(double a) 代表以 e 为底的 a 的对数，因此 log2N 在 Java 中的表示为 log((double)N)/log((double)2) pow 数据结构 位集合（BitSet） JDK 中的 BitSet 集合对是布隆过滤器中经常使用的数据结构Bitmap的相对简单的实现。BitSet 采用了Bitmap 的算法思想。 向量（Vector） 线程安全 栈（Stack） 字典（Dictionary） 哈希表（Hashtable） 属性（Properties） 集合容器 HashMap Java 集合比如说 HashMap 和 ConcurrentHashMap 我觉得，最好在平时能去耐心读一下源码，搜一搜相关的博客，最好能知道每个参数为什么设置成这么大？有什么好处？为什么？ hash 算法 详细梳理 JAVA7 和 JAVA8 HashMap 的 hash 实现 优化 最近它有两个主要的更新——一个在 Java 7u40 版本中对于空 map 的共享的底层存储，以及在 Java 8 中将底层 hash bucket 链接成为哈希树（改进更差情况下的性能）。 jdk1.7 中的线程安全问题 resize 死循环： ConcurrentModificationException 疫苗：JAVA HASHMAP 的死循环 jdk8 中是如何解决 jdk7 中的 HashMap 死循环的 hashmap缓存很多key value，查询会不会成为性能瓶颈 HashMap是一种基于哈希表的键值对数据结构，它的查询性能通常非常高效。理想情况下，HashMap的查询时间复杂度是O(1)，也就是说，无论HashMap中有多少元素，查询一个元素的时间都是常数。 然而，实际上HashMap的性能并不总是这么理想。以下是一些可能影响HashMap性能的因素： 哈希冲突：如果多个键的哈希值相同，它们会被放在哈希表的同一个位置，形成一个链表。这时，查询这些键就需要遍历链表，时间复杂度变为O(n)。如果哈希冲突非常严重，HashMap的性能就会大大降低。 负载因子和扩容：HashMap有一个“负载因子”参数，用于控制哈希表的密度。当哈希表的元素数量超过负载因子乘以哈希表的容量时，哈希表就会进行扩容。扩容操作需要重新计算所有元素的哈希值，并将它们重新插入新的哈希表，这是一个时间复杂度为O(n)的操作。如果HashMap的元素数量增长非常快，频繁的扩容操作可能会成为性能瓶颈。 键和值的大小：如果键和值的大小非常大，那么HashMap就需要消耗更多的内存和CPU时间来处理它们。特别是如果键的哈希函数计算非常复杂，那么每次查询都需要计算哈希值，可能会成为性能瓶颈。 总的来说，只要正确使用，HashMap的查询性能通常不会成为性能瓶颈。如果你发现HashMap的性能不佳，可能需要检查你的哈希函数、负载因子设置，或者考虑使用其他数据结构。 IdentityHashMap 和 HashMap 最大的不同，就是使用==而不是 equals 比较 key WeakHashMap 会内存泄漏？ ConcurrentSkipListMap 跳表 ConcurrentSkipListMap ConcurrentHashMap 死循环 ConcurrentHashMap BUG 死锁 死锁（该问题由 fly 提出并收录） ConcurrentHashMap map = new ConcurrentHashMap<>(); map.put(1, 1); map.put(2, 2); Thread t1 = new Thread(() -> { LockSupport.parkNanos(TimeUnit.SECONDS.toNanos(2)); map.computeIfAbsent(4, key -> { map.clear(); System.out.println(\"4\"); return key; }); }); Thread t2 = new Thread(() -> { LockSupport.parkNanos(TimeUnit.SECONDS.toNanos(2)); map.computeIfAbsent(3, key -> { map.clear(); System.out.println(\"3\"); return key; }); }); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(\"finish\"); ConcurrentHashMap 1194 行会死锁 TreeMap 各种乱七八糟的结构都是为了在「特定场景」下尽可能高效地进行增删查改。 你比如 HashMap 的优势是能够在 O(1) 时间通过键查找对应的值，但要求键的类型 K 必须是「可哈希」的；而 TreeMap 的特点是方便根据键的大小进行操作，但要求键的类型 K 必须是「可比较」的。 TreeSet 同理，红黑树实现。 List CopyOnWriteArrayList 附：Redis 写快照的时候，用到了 Linux 底层的 Copy-On-Write 技术 一个著名 BUG c.toArray might (incorrectly) not return Object[] (see 6260652) 原文 java.util.ArrayList 元素类型为Object[] elementData，toArray()方法实质返回Object[] java.util.Arrays.ArrayList 元素类型为E[] a，toArray()方法实质返回E[] 因此，虽然List的toArray接口表面都返回 Object[]，但他们的实质返回值还是有差的。所以我们不能将其他类型的对象，放进java.util.Arrays.ArrayList#toArray()返回的数组中。 List list = Arrays.asList(\"abc\"); // class java.util.Arrays$ArrayList System.out.println(list.getClass()); Object[] objArray = list.toArray(); // class [Ljava.lang.String; System.out.println(objArray.getClass()); // cause ArrayStoreException objArray[0] = new Object(); Queue 接口的几个主要方法 add/offer, remove/poll, element/peek DelayQueue ScheduledThreadPoolExecutor 其任务队列默认是 DelayedWorkQueue 的变种 Arrays 几个类 TimSort，ComparableTimSort，DualPivotQuicksort 几个方法 binarySort 折半插入排序 mergeSort Koloboke （第三方的集合库） 原始类型集合库Koloboke，避免大量的装箱拆箱，Koloboke 的目标是替换标准的 Java 集合和流的 API，提供更高效的实现。 同类型的还有 HPPC，Eclipse Collections 等。 线程安全的类 另看：并发容器 fail-fast 和 fail-safe 快速失败(fail-fast)和安全失败(fail-safe)的区别 - 那啥快看 - 博客园 (cnblogs.com) Java 高级 代理 按照代理的创建时期，代理类可以分为两种。 静态代理：由程序员创建或特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class 文件就已经存在了。 动态代理：在程序运行时，运用反射机制动态创建而成。 动态代理方案 jdk 动态代理 cglib 动态代理 JDK 的动态代理机制只能代理实现了接口的类，而不能实现接口的类就不能实现 JDK 的动态代理，cglib 是针对类来实现代理的，他的原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强，但因为采用的是继承，所以不能对 final 修饰的类进行代理。 Cglib 与 JDK 动态代理 javassist 动态代理 ASM 字节码 javassist 字节码 深入理解 RPC 之动态代理篇 - 徐靖峰|个人博客 (cnkirito.moe) Q&A 为什么 cglib 为什么生成两个 fastclass，methodProxy.invokeSuper(“代理对象”, args) 和 methodProxy.invoke(“原对象”, args) 虽然底层分别调用两个不同的 fastclass，但结果是一样的。 // 自定义 Cglib 代理拦截 public class DemoInterceptor implements MethodInterceptor { // @param o cglib 生成的代理对象 // @param method 被代理对象方法 // @param objects 方法入参 // @param methodProxy 代理方法 public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.err.println(\"intercept\"); // invokeSuper，o 为 cglib 生成的代理对象 return methodProxy.invokeSuper(o, objects); } } // org.springframework.aop.framework.CglibAopProxy.CglibMethodInvocation private static class CglibMethodInvocation extends ReflectiveMethodInvocation { private final MethodProxy methodProxy; private boolean protectedMethod; public CglibMethodInvocation(Object proxy, Object target, Method method, Object[] arguments, Class targetClass, List interceptorsAndDynamicMethodMatchers, MethodProxy methodProxy) { super(proxy, target, method, arguments, targetClass, interceptorsAndDynamicMethodMatchers); this.methodProxy = methodProxy; this.protectedMethod = Modifier.isProtected(method.getModifiers()); } protected Object invokeJoinpoint() throws Throwable { // invoke，target 为原对象 return this.protectedMethod ? super.invokeJoinpoint() : this.methodProxy.invoke(this.target, this.arguments); } } 可扩展看看 Spring 的 JdkDynamicAopProxy，其实本质上 Spring 对代理的处理都差不多 创建和销毁对象 单例 与 序列化 一般来说，一个类实现了 Serializable 接口，我们就可以把它往内存地写再从内存里读出而\"组装\"成一个跟原来一模一样的对象。不过当序列化遇到单例时，这里边就有了个问题：从内存读出而组装的对象破坏了单例的规则。单例是要求一个 JVM 中只有一个类对象的，而现在通过反序列化，一个新的对象克隆了出来。 解决方案：加上 readResolve() 方法 public final class MySingleton implements Serializable { private MySingleton() { } private static final MySingleton INSTANCE = new MySingleton(); public static MySingleton getInstance() { return INSTANCE; } private Object readResolve() throws ObjectStreamException { // instead of the object we're on, // return the class variable INSTANCE return INSTANCE; } } 对象实例化顺序 父类的静态成员变量和静态代码块加载 子类的静态成员变量和静态代码块加载 父类成员变量和方法块加载 父类的构造函数加载 子类成员变量和方法块加载 子类的构造函数加载 参考： Java 类的实例化顺序 java 类实例化顺序+经典的面试题 测试：com.ariescat.metis.base.jdk.TestSameField java 中父类与子类有相同属性调谁？ 继承中： 属性：不可被重写，只会被隐藏 方法：会被重写，不会隐藏 多态中， 成员变量无论编译和运行，都参考左边 (引用型变量所属的类)。 也就是说 Fu f = new Zi();System.out.println(f.age); 打印的还是父类的值。 参考： java 中父类与子类有相同属性调谁？取决于左边 父类和子类同时存在相同属性 BeanUtils 的 copyProperties 复制 对象引用 WeakReference 看 ThreadLocal 源码的时候，其中嵌套类 ThreadLocalMap 中的 Entry 继承了 WeakReference，为了能搞清楚 ThreadLocal，只能先了解下了 WeakReference： WeakReference 如字面意思，弱引用， 当一个对象仅仅被 WeakReference（弱引用）指向, 而没有任何其他 strong reference（强引用）指向的时候, 如果这时 GC 运行, 那么这个对象就会被回收，不论当前的内存空间是否足够，这个对象都会被回收。 注意：回收的是 WeakReference 引用的对象！若存在 ReferenceQueue 队列，WeakReference 本身会入队，但此时 get()==null WeakHashMap SoftReference 若清楚了上面的原理，SoftReference 只是生命周期变成内存将要被耗尽的时候。 from 关于 SoftReference 被回收的时机 下面，我们来总结一下: 1.当发生 GC 时，虚拟机可能会回收 SoftReference 对象所指向的软引用，是否被回收取决于该软引用是否是新创建或近期使用过。 2.在虚拟机抛出 OutOfMemoryError 之前，所有软引用对象都会被回收。 3.只要一个软引用对象由一个强引用指向，那么即使是 OutOfMemoryError 时，也不会被回收。 from JVM - 优化案例（SoftRefLRUPolicyMSPerMB） 那么 SoftReference 对象到底在 GC 的时候要不要回收是通过什么公式来判断的呢？ 是如下的一个公式： clock - timestamp 这个公式的意思就是说，“clock - timestamp”代表了一个软引用对象他有多久没被访问过了，freespace 代表 JVM 中的空闲内存空间，SoftRefLRUPolicyMSPerMB 代表每一 MB 空闲内存空间可以允许 SoftReference 对象存活多久。 guava cache： CacheBuilder.newBuilder().softValues().build() 当然 softValues() 可以替换成 weakKeys() / weakValues() ... 实现原理可具体看 com.google.common.cache.LocalCache.Strength LRU 缓存实现 (Java) 软引用和弱引用 被软引用关联的对象只有在内存不足时才会被回收，而被弱引用关联的对象在JVM进行垃圾回收时总会被回收。针对上面的特性，软引用适合用来进行缓存，当内存不够时能让JVM回收内存，弱引用能用来在回调函数中防止内存泄露。因为回调函数往往是匿名内部类，隐式保存有对外部类的引用，所以如果回调函数是在另一个线程里面被回调，而这时如果需要回收外部类，那么就会内存泄露，因为匿名内部类保存有对外部类的强引用。 对象序列化 Serializable readResolve() 与 单例 ObjectInputStream、ObjectOutputStream 看看readObject与writeObject方法源码 对象拷贝 深复制（深克隆）和浅复制（浅克隆） BeanUtils 对象属性 copy 的性能对比以及源码分析 拷贝方式 对象数量: 1 对象数量: 1000 对象数量: 100000 对象数量: 1000000 Hard Code 0 ms 1 ms 18 ms 43 ms cglib.BeanCopier 111 ms 117 ms 107 ms 110 ms spring.BeanUtils 116 ms 137 ms 246 ms 895 ms apache.PropertyUtils 167 ms 212 ms 601 ms 7869 ms apache.BeanUtils 167 ms 275 ms 1732 ms 12380 ms Observable 操作 Vector 型变量 obs 的四个方法都加有同步关键字，Vector 类型为线程安全的，而上述四个方法为什么还要加同步关键字呢？ Java 注解处理器 Annotation Processor javax.annotation.processing.AbstractProcessor 编译时执行 JMX JMX 是 Java Management Extensions，它是一个 Java 平台的管理和监控接口。 了解不深== 启动 jsvc 在 linux 上以服务的方式启动 java 程序，需要提前安装 jsvc。linux 是利用 daemon(jsvc) 构建 java 守护进程。 语法糖 有认真了解过 Java 的语法糖吗？ Java 中的 10 颗语法糖 字符编解码 字符集 ASCII Unicode 目前 Unicode 字符分为 17 组编排，0x0000 至 0x10FFFF,每组称为平面（Plane）,每个面拥有 65536 个码位，共 1114112 个。 字符编码 UTF-32、UTF-16 和 UTF-8 是 Unicode 标准的编码字符集的字符编码方案 附： Java 的char内部编码为UTF-16，而与Charset.defaultCharset()无关。 看 Unicode 编码理解 可知UTF-16编码完全可以满足 Unicode 的 17 组编排（平面），因为有平面 0 的 0xD800-0xDFFF 代理区。 关于 java 中 char 占几个字节，汉字占几个字节，这里指出 Java 中的char是占用两个字节，只不过有些字符需要两个 char 来表示，同时这篇博客也给了一个官方 Oracle 链接里面明确的说明了值在 16 位范围之外且在 0x10000 到 0x10FFFF 范围内的字符称为补充字符，并定义为一对 char 值。 测试代码： public static void main(String[] args) { char[] c = new char[]{'一'}; System.err.println(Integer.toHexString(c[0])); String s = new String(c); // String#length事实上调用了char[].length System.err.println(s + \" \" + s.length()); String str = \"一\"; System.err.println(str + \" \" + str.length()); // Unicode编码 汉字扩展B '𠀀' 字 c = new char[]{'\\uD840', '\\uDC00'}; s = new String(c); System.err.println(s + \" \" + s.length()); str = \"\\uD840\\uDC00\"; System.err.println(str + \" \" + str.length()); // 输出：由输出可见这个字用了两个char来存 // 一 1 // 一 1 // 𠀀 2 // 𠀀 2 } UniCode 编码表 汉字 unicode 编码范围 参考博客： 吴秦（Tyler）字符集和字符编码（Charset & Encoding） 廖雪峰 字符串和编码 该文有简单有效的解释了： 在计算机内存中，统一使用 Unicode 编码，当需要保存到硬盘或者需要传输的时候，就转换为 UTF-8 编码。 用记事本编辑的时候，从文件读取的 UTF-8 字符被转换为 Unicode 字符到内存里，编辑完成后，保存的时候再把 Unicode 转换为 UTF-8 保存到文件： 浏览网页的时候，服务器会把动态生成的 Unicode 内容转换为 UTF-8 再传输到浏览器： 所以你看到很多网页的源码上会有类似的信息，表示该网页正是用的 UTF-8 编码。 Base64 编码： Base64 编码本质上是一种将二进制数据转成文本数据的方案。对于非二进制数据，是先将其转换成二进制形式，然后每连续 6 比特（2 的 6 次方=64）计算其十进制值，根据该值在上面的索引表中找到对应的字符，最终得到一个文本字符串。 常见问题处理之 Emoji 所谓 Emoji 就是一种在 Unicode 位于\\u1F601–\\u1F64F 区段的字符。这个显然超过了目前常用的 UTF-8 字符集的编码范围\\u0000–\\uFFFF。Emoji 表情随着 IOS 的普及和微信的支持越来越常见。 那么 Emoji 字符表情会对我们平时的开发运维带来什么影响呢？最常见的问题就在于将他存入 MySQL 数据库的时候。一般来说 MySQL 数据库的默认字符集都会配置成 UTF-8，mysql 支持的 utf8 编码最大字符长度为 3 字节，而 utf8mb4 在 5.5 以后才被支持，也很少会有 DBA 主动将系统默认字符集改成 utf8mb4。那么问题就来了，当我们把一个需要 4 字节 UTF-8 编码才能表示的字符存入数据库的时候就会报错：ERROR 1366: Incorrect string value: '\\xF0\\x9D\\x8C\\x86' for column 。 如果认真阅读了上面的解释，那么这个报错也就不难看懂了。我们试图将一串 Bytes 插入到一列中，而这串 Bytes 的第一个字节是\\xF0 意味着这是一个四字节的 UTF-8 编码。但是当 MySQL 表和列字符集配置为 UTF-8 的时候是无法存储这样的字符的，所以报了错。 那么遇到这种情况我们如何解决呢？有两种方式：升级 MySQL 到 5.6 或更高版本，并且将表字符集切换至 utf8mb4。第二种方法就是在把内容存入到数据库之前做一次过滤，将 Emoji 字符替换成一段特殊的文字编码，然后再存入数据库中。之后从数据库获取或者前端展示时再将这段特殊文字编码转换成 Emoji 显示。第二种方法我们假设用--1F601--来替代 4 字节的 Emoji，那么具体实现 python 代码可以参见Stackoverflow 上的回答 补码 补码(为什么按位取反再加一)：告诉你一个其实很简单的问题 原文 其核心思想就是：一个正数对应的负数（也就是俩相反数），这两个数的二进制编码加起来必须等于 0 才对 System#exit 注册的关闭勾子会在以下几种时机被调用到 程序正常退出 最后一个非守护线程执行完毕退出时 System.exit 方法被调用时 程序响应外部事件 程序响应用户输入事件，例如在控制台按 ctrl+c(^+c) 程序响应系统事件，如用户注销、系统关机等 这种方法永远不会正常返回。 意味着该方法不会返回；一旦一个线程进入那里，就不会再回来了。 链接： Java System#exit 无法退出程序的问题探索 java System.exit(0) 结束不了其他线程? 最后一楼说了：将 A 线程变为 while(true) 一直执行，就会发现 A 线程也会中止。两个线程各自执行，之前都循环十次，A 线程可能在 B 线程调用 System.exit(0) 之前就执行完了 设计模式 六大设计原则 单一职责原则(Single Responsibility Principle - SRP) 开放封闭原则(Open Closed Principle - OCP) 里氏替换原则(Liskov Substitution Principle - LSP) 最少知识原则(Least Knowledge Principle - LKP) 接口隔离原则(Interface Segregation Principle - ISP) 依赖倒置原则(Dependence Inversion Principle - DIP) 设计模式 单例 double check volatile 禁止new的指令重排 参考： Java开发中的23种设计模式详解(转) - maowang - 博客园 (cnblogs.com) 反模式 上帝类(God Class)，这个类里面控制了很多其他的类，同时也依赖其他很多类。整个类不光负责自己的主要单一功能，而且还负责了其他很多功能，包括一些辅助功能。 Swing/Awt EventQueue 与 AWTEvent from https://github.com/jzyong/game-server.git game-tool/src/main/java/com/jzy/game/tool/db/DBTool.java java.awt.EventQueue.invokeLater EventQueue里有一条dispatchThread线程，在postEventPrivate里检测为 null 则进行初始化，然后一直调用pumpEvents取出优先级最高的AWTEvent进行分发： eq.dispatchEvent(event); 如java.awt.Component#dispatchEventImpl里会触发各种监听 Polygon，区域超区校验 Java IO IO 流 对文件进行操作：FileInputStream（字节输入流），FileOutputStream（字节输出流），FileReader（字符输入流），FileWriter（字符输出流） 2020 年 3 月 17 日追加： FileReader，可以理解成他把 FileInputStream 和 Decoder 封装了起来，本质上还是用 FileInputStream 读了一层字节流 byte[] (这里的 read 是一个 native 方法)，然后通过 Decoder 把他转成了 char[]。 BufferedReader，他默认开辟了一份 defaultCharBufferSize = 8192 长度的 cb[] 数组（缓冲区），读之前会把这个数组fill()满，之后都是操作这个数组，操作完了就再次更新数组，提高数据访问的效率。 测试代码：study-metis: com.ariescat.metis.base.io.iostream.Test 对管道进行操作：PipedInputStream（字节输入流），PipedOutStream（字节输出流），PipedReader（字符输入流），PipedWriter（字符输出流） PipedInputStream 的一个实例要和 PipedOutputStream 的一个实例共同使用，共同完成管道的读取写入操作，主要用于线程操作。 有空看看这里的实现 简介,源码分析和示例 在一个线程里使用 PipedInputStream 和 PipedOutputStream 会造成死锁：这意味着，如果你用同一个线程既读又写（read() 和 write() 方法是阻塞的方法），那么就会造成这个线程的死锁。 字节/字符数组：ByteArrayInputStream，ByteArrayOutputStream，CharArrayReader，CharArrayWriter 在内存中开辟了一个字节或字符数组。 Buffered 缓冲流：BufferedInputStream，BufferedOutputStream，BufferedReader，BufferedWriter 带缓冲区的处理流，缓冲区的作用的主要目的是：避免每次和硬盘打交道，提高数据访问的效率。 转化流： InputStreamReader：在读入数据的时候将字节转换成字符。 OutputStreamWriter：在写出数据的时候将字符转换成字节。 数据流：DataInputStream，DataOutputStream 因为平时若是我们输出一个 8 个字节的 long 类型或 4 个字节的 float 类型，那怎么办呢？可以一个字节一个字节输出，也可以把转换成字符串输出，但是这样转换费时间，若是直接输出该多好啊，因此这个数据流就解决了我们输出数据类型的困难。数据流可以直接输出 float 类型或 long 类型，提高了数据读写的效率。 打印流：printStream，printWriter 一般是打印到控制台，可以进行控制打印的地方和格式，其中的 print 方法不会抛出异常，可以通过 checkError 方法来查看异常。 对象流：ObjectInputStream，ObjectOutputStream 把封装的对象直接输出，而不是一个个在转换成字符串再输出。 RandomAccessFile 随机访问文件 java.io 包中是一个特殊的类, 既可以读文件，也可以写文件。 有空也要看看这里的实现，log4j2 的 Appender 里就有这个：RandomAccessFileAppender、RollingRandomAccessFileAppender RandomAccessFile 的绝大多数功能，但不是全部，已经被 JDK 1.4 的 nio 的内存映射文件(memory-mapped files)给取代了，你该考虑一下是不是用\"内存映射文件\"来代替 RandomAccessFile 了。 ZipInputStream、ZipOutputStream 读取 zip 文档 getNextEntry、putNextEntry 得到或创建 ZipEntry 对象。 close() 为什么要用 close() 关掉流？ 有些资源 GC 回收不掉？ Path/Files IO 操作你还在用 File 吗，该拥抱 Path 和 Files 了 NIO Channel，Buffer，Selector 高性能 IO 之 Reactor 模式 Java 并发 概述 JUC 包，毫无疑问的，得去学，哪怕平时编程根本不去用，但是得会，至少得知道有这个东西，至少得知道 aba，cas，aqs，unsafe，volatile，sync，常见的各种 lock，死锁，线程池参数和如何合理的去设置，必须明白自旋，阻塞，死锁和它如何去定位，oom 如何定位问题，cpu 过高如何定位等基本的操作。你可以没有生产调试经验，但不代表你可以不会 top，jps，jstack，jmap 这些可能会问的东西。 进程 进程是一个独立的运行环境，而线程是在进程中执行的一个任务。 进程单独占有一定的内存地址空间，进程的创建和销毁不仅需要保存寄存器和栈信息，还需要资源的分配回收以及页调度，开销较大；线程只需要保存寄存器和栈信息，开销较小。 另外一个重要区别是，进程是操作系统进行资源分配的基本单位，而线程是操作系统进行调度的基本单位，即CPU分配时间的单位 。 总结： 线程 是 进程 划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反 线程 线程创建 有三种使用线程的方法： 继承 Thread 类 实现 Runnable 接口 实现 Callable 接口 Future接口 FutureTask类 参考：Java 并发的四种风味 线程优先级 Java中线程优先级可以指定，范围是1~10。 Java只是给操作系统一个优先级的参考值，线程最终在操作系统的优先级是多少还是由操作系统决定。 Java默认的线程优先级为5，线程的执行顺序由调度程序来决定，线程的优先级会在线程被调用之前设定。 线程状态 java.lang.Thread.State，里面的注释内容讲解得很清楚了 // Thread.State 源码 public enum State { NEW,//（新建） RUNNABLE,//（可运行） BLOCKED,//（阻塞） WAITING,//（等待） TIMED_WAITING,//（定时等待） TERMINATED;//（终止） } 链接： Java 线程的 6 种状态及切换 (透彻讲解) Java 中一个线程只有六个状态。至于阻塞、可运行、挂起状态都是人们为了便于理解，自己加上去的 基础机制 sleep yield 静态方法 Thread.yield() ，切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。 守护线程 守护线程是指为其他线程服务的线程。在 JVM 中，所有非守护线程都执行完毕后，无论有没有守护线程，虚拟机都会自动退出。因此，JVM 退出时，不必关心守护线程是否已结束。 线程之间协作 join 在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。 wait() notify() notifyAll() 调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。 它们都属于 Object 的一部分，而不属于 Thread。 wait() 和 sleep() 的区别 wait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。 当使用调用 wait 时，虽然当前的线程还在 schronized 同步块中， 但是也会让出锁，要不然，notify 永远拿不到锁，永远得不到执行。 同样当使用完 notify 后，是不会立即释放锁的，必须使你当前线程走完 schronized 的代码，也就是说只有当前线程走完 schronized 代码块之后，wait 才会被执行。 可以看下这个：13 案例分析：多线程锁的优化.md (lianglianglee.com) 里面的 synchronied 小节 await() signal() signalAll() java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。 相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。 ReentrantLock 就用了 Condition 类。 他们释放锁吗？这里其实没这个说法，想想是不是这样~ LockSupport.park（ReentrantLock） 白话讲懂 wait notify 和 park unpark 的使用示例和区别_pengweismile 的专栏-CSDN 博客 面试 LockSupport.park() 会释放锁资源吗？ 中断线程 InterruptedException 何时抛出？ java.util.concurrent.ThreadPoolExecutor#shutdown 看看 interruptWorkers，interruptIdleWorkers interrupted 和 isInterrupted 区别 线程池 介绍：Executor 之 线程池及定时器 (novoland.github.io) 另外： 《阿里巴巴 Java 开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 返回线程池对象的弊端如下： FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。 主要参数 corePoolSize maximumPoolSize keepAliveTime workQueue handler 三种队列 队列 简单解释 SynchrousQueue 不会保存提交任务，超出直接 corePoolSize 个任务，直接创建新的线程来执行任务，直到 (corePoolSize＋新建线程) > maximumPoolSize。 LinkedBlockingQueue 基于链表的先进先出，无界队列。超出直接 corePoolSize 个任务，则加入到该队列中，直到资源耗尽，所以 maximumPoolSize 不起作用。 ArrayBlockingQueue 基于数组的先进先出，创建时必须指定大小，超出直接 corePoolSize 个任务，则加入到该队列中，只能加该 queue 设置的大小，其余的任务则创建线程，直到 (corePoolSize＋新建线程) > maximumPoolSize。 上表收录自：线程池的三种缓存队列 解释看起来文邹邹的，要不直接上代码：execute： public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) 注意： ？SynchronousQueue误区：很多人把其认为其没有容量，不存储元素，这是错的。 好好了解这个结构，并看看其核心算法transfer。后来实在看不懂...，先记住这句话吧：生产者线程对其的插入操作 put 必须等待消费者的移除操作 take，反过来也一样。你不能调用 peek() 方法来看队列中是否有数据元素，因为数据元素只有当你试着取走的时候才可能存在，不取走而只想偷窥一下是不行的，当然遍历这个队列的操作也是不允许的。 链接： SynchronousQueue应用 - hongdada - 博客园 (cnblogs.com) 四种拒绝策略 AbortPolicy // 默认，队列满了丢任务抛出异常 DiscardPolicy // 队列满了丢任务不异常 DiscardOldestPolicy // 将最早进入队列的任务删，之后再尝试加入队列 CallerRunsPolicy // 如果添加到线程池失败，那么主线程会自己去执行该任务 原理 ThreadPoolExecutor 和 ScheduledThreadPoolExecutor 原理 Java线程池详解2--任务提交及执行 ScheduledThreadPoolExecutor 原理 线程池运行状态 线程池终止 Java线程池详解3--线程池终止 shutdown 执行完shutdown，线程池状态首先会更新为shutdown，然后中断所有空闲线程，当剩余工作线程执行完持有的任务，且将阻塞队列中的任务也执行完毕，变为空闲线程时，执行tryTerminate()操作将线程池状态更新为tidying，待线程池完成terminated()操作后，线程池状态最终变为terminated。 shutdownNow 执行完shutdownNow，线程池状态首先会更新为stop，接着中断所有已启动worker，然后执行tryTerminate()操作将线程池状态更新为tidying，待线程池完成terminated()操作后，线程池状态最终变为terminated。 awaitTermination 判定当前线程池已处于terminated状态 注意 一旦线程池有任务开始跑，就算任务都跑完了，也会等待keepAliveTime时候后才会停止。一般测试小 demo 的时候发现程序一直得不到结束，原因基本是这个。 public static void main(String[] args) throws InterruptedException { ExecutorService executor = Executors.newCachedThreadPool(); executor.execute(() -> System.err.println(\"executor\")); // TimeUnit.SECONDS.sleep(5L); // executor.shutdown(); System.err.println(\"finish\"); // 两个打印都输出后，程序还要等待 60s 才会结束！！ } 源码分析： java.util.concurrent.ThreadPoolExecutor#runWorker这里会一直调用task = getTask()，getTask里会调用workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS)或者workQueue.take()，因此没任务后它也会阻塞keepAliveTime时间 或者 永久阻塞。 分析一下shutdown()，它里面调用了interruptIdleWorkers()，它会打断上述的wait keepAliveTime的状态，抛出中断异常，而getTask()会捕获这个异常，从而打破阻塞状态。 线程池自动关闭 除了 keepAliveTime 外，还有一个因素 corePoolSize，runWorker 的最后有个 processWorkerExit 处理，也就是当前 thread 结束后，如果当前线程池未关闭，并且当前 workerCount 小于 corePoolSize，还会继续 addWorker。 那么我们将核心线程数设置成0，设置非核心线程存活时间，当所有非核线程空闲时间到达指定的存活时间，会消亡，那么线程池就会自动关闭了： private static ThreadPoolExecutor EXECUTOR = new ThreadPoolExecutor(0, 50, 5L, TimeUnit.MINUTES, new ArrayBlockingQueue<>(10), new ThreadPoolExecutor.CallerRunsPolicy()); Executors.newCachedThreadPool() 也是可以的。 Executors.newSingleThreadScheduledExecutor() 就不会自动关闭，除非 shutdown。 线程池异常处理 java.util.concurrent.ThreadPoolExecutor#runWorker 使用 execute 方法提交的任务一般没问题 有需要可以重写 afterExecute 但注意 sumbit 这种情况，FutureTask 自己封装处理了异常，不通过 Future 是获取不到的，看看这篇文章： 记一次线程池引发的故障 排查下来是三歪的锅 这篇文章其实是有点问题的，他最后的 setUncaughtExceptionHandler 是获取不到 sumbit 的异常的，但还是可以通过这篇文章了解下整体的脉络。 协程 协程，英文 Coroutines，是一种比线程更加轻量级的存在。正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程。最重要的是，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。 Java 语言并没有对协程的原生支持，但是某些开源框架模拟出了协程的功能，有兴趣的小伙伴可以看一看 Kilim 框架的源码 同步互斥 锁分类 可重入锁和非可重入锁 synchronized关键字就是使用的重入锁。 ReentrantLock的中文意思就是可重入锁。 公平锁和非公平锁 一般情况下，非公平锁能提升一定的效率。但是非公平锁可能会发生线程饥饿（有一些线程长时间得不到锁）的情况。 ReentrantLock支持非公平锁和公平锁两种。 读写锁和排他锁 synchronized用的锁和ReentrantLock，其实都是“排它锁”。 ReentrantReadWriteLock类作为读写锁的默认实现，内部维护了两个锁：一个读锁，一个写锁。通过分离读锁和写锁，使得在“读多写少”的环境下，大大地提高了性能。 synchronized 使用 同步一个对象、一个类、一个对象方法、一个静态方法 原理 Java 对象 在 JVM 中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。 对象头：Java 对象头一般占有 2 个机器码（在 32 位虚拟机中，1 个机器码等于 4 字节，也就是 32bit，在 64 位虚拟机中，1 个机器码是 8 个字节，也就是 64bit），但是 如果对象是数组类型，则需要 3 个机器码，因为 JVM 虚拟机可以通过 Java 对象的元数据信息确定 Java 对象的大小，但是无法从数组的元数据来确认数组的大小，所以用一块来记录数组长度。 实例数据：存放类的属性数据信息，包括父类的属性信息。 对齐填充：由于虚拟机要求 对象起始地址必须是 8 字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐。 对象头 Mark Work 指向类的指针 数组长度 Mark Work 锁状态 25bit 4bit 1bit 2bit 23bit 2bit 是否偏向锁 锁标志位 无锁 对象的 HashCode 分代年龄 0 01 偏向锁 线程 ID Epoch 分代年龄 1 01 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向重量级锁的指针 10 GC 标记 空 11 原理 死磕Synchronized底层实现 (qq.com) Java synchronized原理总结 - 知乎 (zhihu.com) 保证了原子性、可见性、有序性 可重入、不可中断 同步代码 所有的互斥，其实是获取 monitor 的所有权。 当我们进入一个人方法的时候，执行 monitorenter，就会获取当前对象的一个所有权，这个时候 monitor 进入数为 1，当前的这个线程就是这个 monitor 的 owner。 如果你已经是这个 monitor 的 owner 了，你再次进入，就会把进入数+1. 同理，当他执行完 monitorexit，对应的进入数就-1，直到为 0，才可以被其他线程持有。 同步方法 ACC_SYNCHRONIZED 标志位 同步方法的时候，一旦执行到这个方法，就会先判断是否有标志位，然后，ACC_SYNCHRONIZED 会去隐式调用刚才的两个指令：monitorenter 和 monitorexit。 所以归根究底，还是 monitor 对象的争夺。 Monitor 对象 Monitor 其实是一种同步工具，也可以说是一种同步机制，它通常被描述为一个对象。 主要特点： 对象的所有方法都被“互斥”的执行 通常提供 singal 机制 “ Java 对象是天生的 Monitor。” 关于Monitor对象在sychronized实现中的应用_super_x_man的博客-CSDN博客_monitor撖寡情 其他 用户态和内核态的转换 过程是很复杂的，也涉及很多值的传递；synchronized 在 1.6 之前之所以说重量级，有部分原因在这，大量的系统资源消耗。 偏向锁与 hashcode 能共存吗 偏向锁与 hashcode 能共存吗？_Saintyyu 的博客-CSDN 博客 Q&A synchronized 或其他锁的产生的阻塞，其和 wait 的区别？ 当一个线程的时间片耗尽之后，其 synchronized 的代码会发生原子性问题吗？ 线程 1 在执行monitorenter指令的时候，会对 Monitor 进行加锁，加锁后其他线程无法获得锁，除非线程 1 主动解锁。即使在执行过程中，由于某种原因，比如 CPU 时间片用完，线程 1 放弃了 CPU，但是，他并没有进行解锁。而由于synchronized的锁是可重入的，下一个时间片还是只能被他自己获取到，还是会继续执行代码。直到所有代码执行完。这就保证了原子性。 锁优化 这里的锁优化主要是指 JVM 对 synchronized 的优化。 JDK1.6 后对锁进行的优化，轻量级锁，偏向锁，锁消除，适应性自旋锁，锁粗化 (自旋锁在 1.4 就有，只不过默认的是关闭的，jdk1.6 是默认开启的) 自旋锁、锁消除、锁粗化 偏向锁、轻量级锁、重量级锁 彻底搞懂 synchronized(从偏向锁到重量级锁) 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用于只有一个线程访问同步块场景。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗 CPU。 追求响应时间。同步块执行速度非常快。 重量级锁 线程竞争不使用自旋，不会消耗 CPU。 线程阻塞，响应时间缓慢。 追求吞吐量。同步块执行速度较长。 volatile 可见性 重排序（编译器重排，处理器重排） happen-before 原则： 深入理解 happens-before 规则 深入理解 Happens-Before 原则-happens before原则 (51cto.com) 原理 Java volatile原理总结 - 知乎 (zhihu.com) 内存模型 对 volatile 的进一步补充，jvm 的内存模型。 并发三大特性 原子性，可见性，有序性 现代计算机内存模型 处理器与内存的速度矛盾，加入了一层读写速度尽可能接近处理器运算速度的 高速缓存（Cache），但它引入了一个新的问题：缓存一致性（CacheCoherence）。 在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory）。 JMM Java 内存模型 (JavaMemoryModel) 描述了 Java 程序中各种变量（线程共享变量）的访问规则，以及在 JVM 中将变量，存储到内存和从内存中读取变量这样的底层细节。 JMM 有以下规定： 所有的共享变量都存储于主内存，这里所说的变量指的是实例变量和类变量，不包含局部变量，因为局部变量是线程私有的，因此不存在竞争问题。 每一个线程还存在自己的工作内存，线程的工作内存，保留了被线程使用的变量的工作副本。 线程对变量的所有的操作 (读，取) 都必须在工作内存中完成，而不能直接读写主内存中的变量。 不同线程之间也不能直接访问对方工作内存中的变量，线程间变量的值的传递需要通过主内存中转来完成。 正是因为这样的机制，才导致了可见性问题的存在 主要有三种实现可见性的方式： volatile 每个线程操作数据的时候会把数据从主内存读取到自己的工作内存，如果他操作了数据并且写会了，他其他已经读取的线程的变量副本就会失效了，需要都数据进行操作又要再次去主内存中读取了。 volatile 保证不同线程对共享变量操作的可见性，也就是说一个线程修改了 volatile 修饰的变量，当修改写回主内存时，另外一个线程立即看到最新的值。 synchronized 某一个线程进入 synchronized 代码块前后，线程会获得锁，清空工作内存，从主内存拷贝共享变量最新的值到工作内存成为副本，执行代码，将修改后的副本的值刷新回主内存中，线程释放锁。 final 被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。 缓存一致性协议 别看加一个 volatile 关键字很简单，但实际上他在背后含辛茹苦默默付出了不少，了解下计算机层面的缓存一致性协议。 当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致，那同步回到主内存时以谁的缓存数据为准呢？ 为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有 MSI、MESI（IllinoisProtocol）、MOSI、Synapse、Firefly 及 DragonProtocol 等。 MESI Intel 的 MESI 嗅探 重排序 为了提高性能，编译器和处理器常常会对既定的代码执行顺序进行指令重排序。 一般重排序可以分为如下三种： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序; 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序; 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行的。 as-if-serial 不管怎么重排序，单线程下的执行结果不能被改变。 编译器、runtime 和处理器都必须遵守 as-if-serial 语义。 Volatile 是怎么保证不会被执行重排序? 内存屏障 为了实现 volatile 的内存语义，JMM 会限制特定类型的编译器和处理器重排序，JMM 会针对编译器制定 volatile 重排序规则表： 需要注意的是：volatile 写是在前面和后面分别插入内存屏障，而 volatile 读操作是在后面插入两个内存屏障。 写 读 happens-before 上面提过的重排序原则，为了提高处理速度，JVM 会对代码进行编译优化，也就是指令重排序优化，并发编程下指令重排序会带来一些安全隐患：如指令重排序导致的多个线程操作之间的不可见性。 如果让程序员再去了解这些底层的实现以及具体规则，那么程序员的负担就太重了，严重影响了并发编程的效率。 从 JDK5 开始，提出了happens-before的概念 无法保证原子性 说了这么多，但 Volatile 是没办法保证原子性的，一定要保证原子性，得使用其他方法（比如原子类 AtomicInteger，加锁）。 常见应用：单例，用双重检查+synchronized+volatile 可能好奇为啥要双重检查？如果不用 Volatile 会怎么样？ 这个就得了解下创建对象的几个步骤，可能二三步会重排 分配内存空间。 调用构造器，初始化实例。 返回地址给引用 补充一些 对任意单个 volatile 变量的读/写具有原子性，但类似于 volatile++这种复合操作不具有原子性 内存间交互操作 Java 内存模型定义了 8 种操作来完成主内存和工作内存的变量访问： lock，unlock，read，load，use，assign，stroe，write 一些底层实现 内存屏障是什么？如何工作的？如何实现？在哪个层面上实现？ MESI 协议，Store Buffere（存储缓存），Invalidate Queue（失效队列） 搜索关键词（CPU 和 volatile ） final 一个类的 final 字段会在初始化后插入一个 store 屏障，来确保 final 字段在构造函数初始化完成并可被使用时可见。 参考文章： 面试官想到，一个 Volatile，敖丙都能吹半小时 既生 synchronized，何生 volatile？！ 非原子操作！！！ 一文解决内存屏障 - 简书 (jianshu.com) x86 架构的内存屏障 内存屏障 | 并发编程网 – ifeve.com 全面理解 Java 内存模型 (JMM) 及 volatile 关键字 - CSDN 博客 Java内存模型（JMM）总结 - 知乎 (zhihu.com) 乐观锁 Atomic 类 概念：原子变量，CAS 其他： AtomicStampedReference 它还维护了一个时间戳，解决 ABA 问题 AtomicXXXFieldUpdater 原子更新器 在 Java5 中，JDK 就开始提供原子类了，当然也包括原子的更新器——即后缀为 FieldUpdater 的类 已经有了原子类，为啥还额外提供一套原子更新器呢？ 简单的说有两个原因，以 int 变量为例，基于 AtomicIntegerFieldUpdater 实现的原子计数器，比单纯的直接用 AtomicInteger 包装 int 变量的花销要小，因为前者只需要一个全局的静态变量 AtomicIntegerFieldUpdater 即可包装 volatile 修饰的非静态共享变量，然后配合 CAS 就能实现原子更新，而这样做，使得后续同一个类的每个对象中只需要共享这个静态的原子更新器即可为对象计数器实现原子更新，而原子类是为同一个类的每个对象中都创建了一个计数器 + AtomicInteger 对象，这种开销显然就比较大了。 了解一下 LongAdder 与 Striped64 LongAdder 区别于 AtomicLong ，在高并发中有更好的性能体现 JDK 1.8 中新增的 LongAdder，通过把原值进行拆分，最后再以 sum 的方式，减少 CAS 操作冲突的概率，性能要比 AtomicLong 高出 10 倍左右。 链接 《吊打面试官》系列-乐观锁、悲观锁 妹妹问我：互斥锁、自旋锁、读写锁、悲观锁、乐观锁的应用场景 Java 并发问题--乐观锁与悲观锁以及乐观锁的一种实现方式-CAS ReentrantLock 应用场景 还有 ReadWriteLock，StampedLock，应用场景的选择？ 公平，非公平 阿里面试官：说一下公平锁和非公平锁的区别？_敖丙-CSDN 博客 核心就是 tryAcquire 时，公平锁多了一个 !hasQueuedPredecessors() 判断 比较 synchronized 1. 锁的实现 synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。 2. 性能 新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。 3. 等待可中断 当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。 ReentrantLock 可中断，而 synchronized 不行。 4. 公平锁 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。 synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。 5. 锁绑定多个条件 一个 ReentrantLock 可以同时绑定多个 Condition 对象。 伴生类 Condition 可以看看上面的中断线程，提供了 await() 和 singal() 的功能，可以用于线程间消息通信。 AQS AbstractQueuedSynchronizer 它维护了一个volatile int state（代表共享资源）和一个 FIFO 线程等待队列（多线程争用资源被阻塞时会进入此队列）。这里 volatile 是核心关键词 AQS 框架借助于两个类： Unsafe（提供 CAS 操作，可以了解一下） objectFieldOffset compareAndSwap... LockSupport（提供 park/unpark 操作） AbstractFuture (一旦调用 get 就会阻塞) unpark必须在thread start之后才有用，之前调用没有任何效果；thread start之后，unpark在park之前还是之后，作用是一样的，都会重新唤醒线程。 与 Object 类的 wait/notify 机制相比，park/unpark 有两个优点： 以 thread 为操作对象更符合阻塞线程的直观定义 操作更精准，可以准确地唤醒某一个线程（notify 随机唤醒一个线程，notifyAll 唤醒所有等待的线程），增加了灵活性。 应用： CountDownLatch、CyclicBarrier 和 Semaphore ReentrantLock 等 参考链接 https://blog.51cto.com/14220760/2390586?source=dra https://www.jianshu.com/p/da9d051dcc3d 并发容器 下面的每一个对比，都是面试中的知识点，想要更加深入地理解，你需要阅读 JDK 的源码。 StringBuilder 对应着 StringBuffer。后者主要是通过 synchronized 关键字实现了线程的同步。值得注意的是，在单个方法区域里，这两者是没有区别的，JIT 的编译优化会去掉 synchronized 关键字的影响。 HashMap ConcurrentHashMap：ConcurrentHashMap 的话题很大，java8 中的 ConcurrentHashMap 实现已经抛弃了 java7 中分段锁的设计，而采用更为轻量级的 CAS 来协调并发，效率更佳。 了解 computeIfAbsent 等并发处理方法 ConcurrentHashMapV8 (netty 提供) LinkedList ArrayBlockingQueue： ArrayBlockingQueue 对默认是不公平锁，可以修改构造参数，将其改成公平阻塞队列，它在 concurrent 包里使用得非常频繁。 同时还有 LinkedBlockingQueue，ConcurrentLinkedQueue 等，要看看源码如何实现（offer，take 方法）！ ConcurrentLinkedQueue： 最典型的无锁队列实现，使用 CAS 来处理对数据的并发访问，这是无锁算法得以实现的基础。 CAS 指令不会引起上下文切换和线程调度，是非常轻量级的多线程同步机制。它还把入队、出队等对 head 和 tail 节点的一些原子操作，拆分出更细的步骤，进一步缩小了 CAS 控制的范围。 性能很高，但不是很常用。千万不要和阻塞队列 LinkedBlockingQueue（内部基于锁）搞混了。 阻塞队列归类： 不存储元素： SynchronousQueue：一个不存储元素的阻塞队列。 有界： ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。 无界： PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。 DelayQueue：一个使用优先级队列实现的无界阻塞队列。 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。 ArrayList 对应着 CopyOnWriteArrayList。后者是写时复制的概念，适合读多写少的场景。 HashSet 对应着 CopyOnWriteArraySet。 了解： SkipList（跳表） ConcurrentSkipListMap（使用跳表实现 Map） 和使用哈希算法实现 Map 的另外一个不同之处是：哈希并不会保存元素的顺序，而跳表内所有的元素都是排序的。因此在对跳表进行遍历时，你会得到一个有序的结果。所以，如果你的应用需要有序性，那么跳表就是你不二的选择。 并发组件 FastThreadLocal： 既然 Java 中有了 ThreadLocal 类了，为什么 Netty 还自己创建了一个叫作 FastThreadLocal 的结构？ 底层的 InternalThreadLocalMap 对 cacheline 也做了相应的优化。（伪共享问题） WeakReference 和 ReferenceQueue 这里重点看 ReferenceQueue，引用相关请看下面的对象引用小节 Callable 和 Future（Since 1.5） 在并发编程中，我们经常用到非阻塞的模型，在之前的多线程的三种实现中，不管是继承 thread 类还是实现 runnable 接口，都无法保证获取到之前的执行结果。通过实现 Callback 接口，并用 Future 可以来接收多线程的执行结果。 Future 表示一个可能还没有完成的异步任务的结果，针对这个结果可以添加 Callback 以便在任务执行成功或失败后作出相应的操作。 实现类： CompletableFuture（Since 1.8） Guava——AbstractFuture ForkJoin 和 ForkJoinPool 内存泄露 ThreadLocal 隐患：ThreadLocal 有一个 value内存泄露 的隐患 Thread init方法： this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); 新建线程的时候会封装上下文类保护域，即 AccessControlContext 的 ProtectionDomain，里面拥有一个 classloader 字段。如果是自定义的 classloader 加载的类，并且由该类去新建 thread，那么该 thread 就会 \"keep\" 住这个自定义的 classloader，只要 thread 没结束，那么自定义的 classloader 将得不到gc释放，那么加载的 class 也得不到gc释放。 例如：Executors.newSingleThreadExecutor()，单线程，因为 keepAliveTime 为 0，线程池会一直 workQueue.take() 取任务，thread 是不会结束的。 GC 停顿点 安全点（Safepoint） 撤销偏向锁（在一个安全点停止拥有锁的线程，具体看流程） Q&A 什么是上下文切换？ 并发与并行的区别？ 几个问题 Bounded-Buffer 问题： 生产者消费者问题（Producer-consumer problem），也称有限缓冲问题（Bounded-buffer problem），是一个多线程同步问题的经典案例。原文 并发中的伪共享问题（false sharing）： CPU 缓存是以缓存行（cache line）为单位存储的。缓存行通常是 64 字节，并且它有效地引用主内存中的一块地址。并发的修改在一个缓存行中的多个独立变量，看起来是并发执行的，但实际在 CPU 处理的时候，是串行执行的，并发的性能大打折扣。 Java 中通过填充缓存行，sun.misc.Contended 注解来解决伪共享问题。LMAX Disruptor Sequence采用了填充缓存行。 并不是所有的场景都需要解决伪共享问题，因为 CPU 缓存是有限的，填充会牺牲掉一部分缓存。 Java 虚拟机 前言 JVM 很难，网上错误的观点很多 垃圾回收算法，垃圾收集器，jvm 内存模型，每个区域用途，各种 oom 的种类，jvm 调优经验，没有你也要做过，自己去设置启动参数，知道常见参数的含义，类加载过程，双亲委派，什么时候 young gc，full gc，各种情况进入老年代的方式，你知道的越多越好，因为吹起来就越自信，举个例子，逃逸分析是什么？markword 里面有什么？ 不错的系列文章 JVM 核心技术 32 讲（完） (lianglianglee.com) 内存管理 内存划分 JVM中的五大内存区域划分详解及快速扫盲 注意 1.7 和 1.8之后的区别 1.7之前： 1.8之后： 注意：Metaspace 使用的是本地内存（native memory），所以它的最大内存可以达到机器内存的极限 -XX:MetaspaceSize 并不代表初始的 Metaspace 大小。大致意思就是当 MetaspaceSize 接近一个指定水位（high-water mark）的时候，会引发垃圾回收。 G1调优实践日记--被误解的MetaspaceSize_葵续浅笑的博客-CSDN博客 堆是线程共享的内存区域？ 不完全正确。因为 HotSpot 中，TLAB 是堆内存的一部分，他在读取上确实是线程共享的，但是在内存分配上，是线程独享的。链接 字符串常量池在那个区域中？ 答案：这个要看 JDK 版本。 在 JDK 1.8 之前，是没有元空间这个概念的，当时的方法区是放在一个叫作永久代的空间中。 而在 JDK 1.7 之前，字符串常量池也放在这个叫作永久带的空间中。但在 JDK 1.7 版本，已经将字符串常量池从永久带移动到了堆上。 所以，从 1.7 版本开始，字符串常量池就一直存在于堆上。对于 JDK1.8 时，HostSpot VM 对 JVM 模型进行了改造，将元数据放到本地内存，将常量池和静态变量放到了Java堆里。 直接内存和本地内存 直接内存，指的是使用了 Java 的直接内存 API，进行操作的内存。这部分内存可以受到 JVM 的管控，比如 ByteBuffer 类所申请的内存，就可以使用具体的参数进行控制。 需要注意的是直接内存和本地内存不是一个概念。 直接内存比较专一，有具体的 API（这里指的是ByteBuffer），也可以使用 -XX:MaxDirectMemorySize 参数控制它的大小； 本地内存是一个统称，比如使用 native 函数操作的内存就是本地内存，本地内存的使用 JVM 是限制不住的，使用的时候一定要小心。 内存模型 这个关系到线程，线程安全，具体看 Java并发-同步互斥-内存模型 （不要和内存管理的内存划分搞混） 扩展： 计算机内存模型 与 Java 内存模型 内存分析 一个Java对象到底占多少个字节？ 可以用 ClassLayout.parseInstance(new Integer(5)).toPrintable() 工具输出，注意在不同位数的JVM和是否开启指针压缩的场景下，输出会有不同。 字节码 局部变量表中的 Slot 为什么 JVM 局部变量表的一个 slot 至少要能容纳一个 int 类型的变量？ 为什么 Java 虚拟机 JVM 要把 byte 和 short 的运算都转为 int ？ Class 类的文件结构 方法表，属性表... 类加载 ClassLoader Bootstrap ClassLoader、 Extention ClassLoader、AppClassLoader Classloader 将数据加载到内存中经过的步骤： 加载：加载类的二进制数据 链接 验证 确保加载的类的正确性。准备 类中的静态变量分配内存，并且其初始化为默认值。解析 把类中的符号引用变为直接引用。 初始化 为类中的类中的静态变量赋值（正确的初始值） 参考：ClassLoader 那事儿 问题： Q：同一个 Class 的static 字段，被不同的 ClassLoader 加载，会有产生几份？ A：会是两份，也就是 JVM 里有两份内存（某次面试时问到的，但自己没试过） 反射 Reflection Class Class类 与 Class 对象 Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的，因此不能显式地声明一个Class对象。 虚拟机为每种类型管理一个独一无二的Class对象。也就是说，每个类（型）都有一个Class对象。运行程序时，Java虚拟机(JVM)首先检查是否所要加载的类对应的Class对象是否已经加载。如果没有加载，JVM就会根据类名查找.class文件，并将其Class对象载入。 基本的 Java 类型（boolean、byte、char、short、int、long、float 和 double）和关键字 void 也都对应一个 Class 对象。 每个数组属于被映射为 Class 对象的一个类，所有具有相同元素类型和维数的数组都共享该 Class 对象。 Class 对象的获取方式 Class.forName(\"类名字符串\") 类名.class 实例对象.getClass() 关键字 instanceof VS Class.isInstance（参数） System.err.println(son instanceof Parent); System.err.println(Parent.class.isInstance(son)); Class 的 getSuperclass 与 getGenericSuperclass getGenericSuperclass 会包含该超类的泛型。 判断当前类是什么类 boolean isLocalClass(); //判断是不是局部类，也就是方法里面的类，其实现：isLocalOrAnonymousClass() && !isAnonymousClass(); boolean isLocalOrAnonymousClass(); boolean isMemberClass(); //判断是不是成员内部类，也就是一个类里面定义的类 boolean isAnonymousClass(); //判断当前类是不是匿名类，一般为实例化的接口或实例化的抽象类 boolean isAnnotation();// 判断 Class 对象是否是注解类型 boolean isPrimitive(); // 判断 Class 是否为原始类型（int，double 等） boolean isSynthetic(); // 判断是否由 Java 编译器生成（除了像默认构造函数这一类的）的方法或者类，Method 也有这个方法 参考： Java 中冷门的 synthetic 关键字原理解读 - 老白讲互联网 - 博客园 (cnblogs.com) 返回字符串 (String) 的方法 String getCanonicalName(); //返回 Java Language Specification 中所定义的底层类的规范化名称 String getName(); //以 String 的形式返回此 Class 对象所表示的实体（类、接口、数组类、基本类型或 void）名称（全限定名：包名.类名）。 String getSimpleName(); //返回源代码中给出的底层类的简称。 String toString(); //将对象转换为字符串。 Class.forName 和 ClassLoader 的区别 都可用来对类进行加载。 不同： 1）Class.forName() 除了将类的.class 文件加载到 jvm 中之外，还会对类进行解释，执行类中的 static 块，还会执行给静态变量赋值的静态方法 2）classLoader 只干一件事情，就是将.class 文件加载到 jvm 中，不会执行 static 中的内容,只有在 newInstance 才会去执行 static 块。 使用 Class.getResource 和 ClassLoader.getResource 方法获取文件路径 对于class.getResource(path)方法，其中的参数 path 有两种形式，一种是以“/”开头的，另一种是不以\"/\"开头 Class.getClassLoader().getResource(String path)，该方法中的参数 path 不能以“/“开头，path 表示的是从 classpath 下获取资源的 Method Method.invoke() 的实现原理 假笨说-从一起 GC 血案谈到反射原理 获取 Method： reflectionData，这个属性主要是 SoftReference 的 我们每次通过调用 getDeclaredMethod 方法返回的 Method 对象其实都是一个新的对象，所以不宜多调哦，如果调用频繁最好缓存起来。不过这个新的方法对象都有个 root 属性指向 reflectionData 里缓存的某个方法，同时其 methodAccessor 也是用的缓存里的那个 Method 的 methodAccessor。 Method 调用： 其实 Method.invoke 方法就是调用 methodAccessor 的 invoke 方法 MethodAccessor 的实现： 所有的方法反射都是先走 NativeMethodAccessorImpl，默认调了15次之后，才生成一个 GeneratedMethodAccessorXXX 类 而 GeneratedMethodAccessorXXX 的类加载器会 new 一个 DelegatingClassLoader(var4)，之所以搞一个新的类加载器，是为了性能考虑，在某些情况下可以卸载这些生成的类，因为类的卸载是只有在类加载器可以被回收的情况下才会被回收的 并发导致垃圾类创建： 假如有 1000 个线程都进入到创建 GeneratedMethodAccessorXXX 的逻辑里，那意味着多创建了 999 个无用的类，这些类会一直占着内存，直到能回收 Perm 的 GC 发生才会回收（关于元空间的回收看JVM内存管理） 后来发现JDK17加了个乐观锁判断 U.compareAndSetInt(this, GENERATED_OFFSET, 0, 1)，应该是修复过这个问题了（但JDK8并没有修复） 其他 JVM 相关文章: 该文章最后有其他 JVM 相关文章，感觉是干货 反射代理类加载器的潜在内存使用问题！！ 大量的类加载器 sun/reflect/DelegatingClassLoader，用来加载 sun/reflect/GeneratedMethodAccessor 类，可能导致潜在的占用大量本机内存空间问题，应用服务器进程占用的内存会显著增大。 其他链接 JDK1.8里Method.invoke()的实现原理 - 简书 (jianshu.com) 反射缺点 由于是本地方法调用，让 JVM 无法优化 (还有 JIT？) 反射方法调用还有验证过程和参数问题，参数需要装箱拆箱、需要组装成 Object[] 形式、异常的包装等等问题 热更新 自定义类加载器 探秘 Java 热部署 CSDN·自定义 classloader 实现 JAVA 热替换 java.lang.instrument 类重新定义，这是 Instrumentation 提供的基础功能之一，这个类很早就出了，redefineClasses 这个方法可以更新方法级别的代码，但是不会触发一个类的初始化方法。 游戏服务器之 Java 热更新 动态加载 class 文件 JVM 源码分析之 javaagent 原理完全解读 探秘 Java 热部署二（Java agent premain） 探秘 Java 热部署三（Java agent agentmain） 第三方工具 Arthas的使用 Github · HotswapAgent 脚本语言 groovy 使用 groovy 类加载器重载 java 代码 重载的 java 文件可以直接使用源文件，无需编译为 class JVMTI JVM Tool Interface，是jvm暴露出来的一些供用户扩展的接口集合，JVMTI是基于事件驱动的，JVM每执行到一定的逻辑就会调用一些事件的回调接口（如果有的话），这些接口可以供开发者去扩展自己的逻辑。 JVMTIAgent JVMTIAgent其实就是一个动态库，利用JVMTI暴露出来的一些接口来干一些我们想做但是正常情况下又做不到的事情，不过为了和普通的动态库进行区分，它一般会实现如下的一个或者多个函数： JNIEXPORT jint JNICALL Agent_OnLoad(JavaVM *vm, char *options, void *reserved); JNIEXPORT jint JNICALL Agent_OnAttach(JavaVM* vm, char* options, void* reserved); JNIEXPORT void JNICALL Agent_OnUnload(JavaVM *vm); JVM启动参数：-agentlib:libname[=options]、-agentpath:pathname[=options]。 比如：-agentlib:hprof，会搜到环境变量PATH中的dll/so库；而-agentpath会按全路径装载本地库，不再搜索PATH中的路径，其他功能和agentlib相同。 javaagent javaagent是由一个叫做instrument的JVMTIAgent（linux下对应的动态库是libinstrument.so）来实现的，另外instrument agent还有个别名叫JPLISAgent（Java Programming Language Instrumentation Services Agent），从这名字里也完全体现了其最本质的功能：就是专门为java语言编写的插桩服务提供支持的。 JVM启动参数：-javaagent:jarpath[=options] 参考：java agent基础原理_ancinsdn的博客 ServiceLoader Java 中 SPI 全称为（Service Provider Interface，服务提供者接口） 该类通过在资源目录 META-INF/services 中放置提供者配置文件来标识服务提供者。 应用场景： JDBC 驱动加载 java.sql.DriverManager#loadInitialDrivers这里调用了ServiceLoader.load(Driver.class); 因此只要 pom 引入了mysql-connector-java这个包，就会加载jar包下META-INF/services/java.sql.Driver文件中的com.mysql.jdbc.Driver类，而com.mysql.jdbc.Driver在静态代码块里往DriverManager注册了自己的驱动。所以以后就不用写下面的 a 段代码啦。 //a.导入驱动，加载具体的驱动类 Class.forName(\"com.mysql.jdbc.Driver\"); //b.与数据库建立连接 connection = DriverManager.getConnection(URL, USERNAME, PASSWORD); netty/Java 的 NIO 采用 SelectorProvider 创建：io.netty.channel.nio.NioEventLoop#provider 而java.nio.channels.spi.SelectorProvider#provider采用了 SPI Dubbo 的扩展点加载 Dubbo 的 SPI 扩展是自己实现的，在启动加载的时候会依次从以下目录中读取配置文件： META-INF/dubbo/internal/、META-INF/dubbo/、META-INF/services/ ——《高可用可伸缩微服务架构：基于 Dubbo、Spring Cloud 和 Service Mesh》3.2.3 节 Dubbo Extension 机制 Java SPI机制与Thread Context Classloader 以DriverManager为例，假设它在⾃⼰的代码⾥调⽤Class.forName(\"com.mysql.cj.jdbc.driver\"); 我们看forName的代码 @CallerSensitive public static Class forName(String className) throws ClassNotFoundException { Class caller = Reflection.getCallerClass(); return forName0(className, true, ClassLoader.getClassLoader(caller), caller); } 此处会寻找caller的类，然后找它的classloader，DriverManager调⽤的forName，所以此处的caller就是DriverManager.class，但是我们知道DriverManager是bootstrap加载的，那此处获取classloader就是null。forName0是native⽅法，它发现classloader是null就尝试⽤bootstrap加载，但是我们要加载的是mysql的类，bootstrap肯定是不能加载的。 那怎么办呢？谁调⽤我，我就⽤谁的加载器，这个加载器放在哪呢，就跟线程绑定，也就是Thread Context ClassLoader。 以上摘抄自：Java SPI机制与Thread Context Classloader 指令集 方法调用指令 JVM提供了5种方法调用指令，其作用列举如下： invokestatic：该指令用于调用静态方法，即使用 static 关键字修饰的方法； invokespecial：该指令用于三种场景：调用实例构造方法，调用私有方法（即private关键字修饰的方法）和父类方法（即super关键字调用的方法）； invokeinterface：该指令用于调用接口方法，在运行时再确定一个实现此接口的对象； invokevirtual：该指令用于调用虚方法（就是除了上述三种情况之外的方法）； invokedynamic：在运行时动态解析出调用点限定符所引用的方法之后，调用该方法；在JDK1.7中推出，主要用于支持JVM上的动态脚本语言（如Groovy，Jython等）。 参考： 通过实例一行一行分析JVM的invokespecial和invokevirtual指令 | wxweven 梦想之家，这篇文章一定要认真读一下！！ 方法调用的本质（含重载与重写区别） Java中方法选择的三个步骤： 步骤1：生成符号引用（编译时） 步骤2：解析（类加载时） 静态方法、私有实例方法、实例构造器、父类方法以及final修饰这五种方法（对应的关键字： static、private、、super、final）可以在编译期确定版本，因为无论运行时加载多少个类，这些方法都保证唯一的版本。 既然可以确定方法的版本，虚拟机在处理invokestatic、invokespecial、invokevirtual(final)时，就可以提前将符号引用转换为直接引用，不必延迟到方法调用时确定，具体来说，是在类加载的解析阶段完成转换的。 步骤3：动态分派（类使用时） 动态分派分为invokevitrual、invokeinterface 与 invokedynamic，其中动态调用invokedynamic是 JDK 1.7 新增的指令。有些同学可能会觉得方法不重写不就只有一个版本了吗？这个想法忽略了Java动态链接的特性，Java可以从任何途径加载一个class，除非解析的 5 种的情况外，无法保证方法不被重写。 invokevirtual指令 虚拟机为每个类生成虚方法表vtable（virtual method table）的结构，类中声明的方法的入口地址会按固定顺序存放在虚方法表中；虚方法表还会继承父类的虚方法表，顺序与父类保持一致，子类新增的方法按顺序添加到虚方法末尾（这以Java单继承为前提）；若子类重写父类方法，则重写方法位置的入口地址修改为子类实现； 1）类加载解析阶段：解析类的继承关系，生成类的虚方法表 （包含了这个类型所有方法的入口地址）。举个例子，有Class B继承与Class A，并重写了A中的方法： Object是所有类的父类，所有每个类的虚方法表头部都会包含Object的虚方法表。另外，B重写了A#printMe()，所以对应位置的入口地址方法被修改为B重写方法的入口地址。 需要注意的是，被final、static或private修饰的方法不会出现在虚方法表中，因为这些方法无法被继承重写。 2）调用阶段（动态分派）：解析阶段生成虚方法表后，每个方法在虚方法表中的索引是固定的，这是不会随着实际类型变化影响的。调用方法时，首先根据变量的实际类型获得对应的虚方法表（包含了这个类型所有方法的入口地址），然后根据索引找到方法的入口地址。 invokeinterface指令 接口方法的选择行为与类方法的选择行为略有区别，主要原因是Java接口是支持多继承的，就没办法像虚方法表那样直接继承父类的虚方法表。虚拟机提供了itable（interface method table）来支持多接口，itable由偏移量表offset table与方法表method table两部分组成。 当需要调用某个接口方法时，虚拟机会在offset table查找对应的method table，随后在该method table上查找方法。 invokedynamic指令 详细看 JDK 1.7 与动态类型 参考： Java | 深入理解方法调用的本质（含重载与重写区别） - 知乎 (zhihu.com) JDK 1.7 与动态类型 invokedynamic指令 TODO MethodHandle static class ClassA { public void println(String s) { System.out.println(s); } } public static void main(String[] args) throws Throwable { Object obj = System.currentTimeMillis() % 2 == 0 ? System.out : new ClassA(); // 无论obj最终是哪个实现类，下面这句都能正确调用到println方法 getPrintlnMH(obj).invokeExact(\"icyfenix\"); } private static MethodHandle getPrintlnMH(Object reveiver) throws Throwable { // MethodType：代表“方法类型”，包含了方法的返回值（methodType（）的第一个参数）和具体参数（methodType（）第二个及以后的参数） MethodType mt = MethodType.methodType(void.class, String.class); /* lookup（）方法来自于MethodHandles.lookup，这句的作用是在指定类中查找符合给定的方法名称、方法类型，并且符合调用权限的方法句柄 因为这里调用的是一个虚方法，按照Java语言的规则，方法第一个参数是隐式的，代表该方法的接收者，也即是this指向的对象， 　　　　这个参数以前是放在参数列表中进行传递的，而现在提供了bindTo（）方法来完成这件事情*/ return lookup().findVirtual(reveiver.getClass(), \"println\", mt).bindTo(reveiver); } MethodHandle 反射获取的信息比 MethodHandle 要多。 反射是模拟 java 代码层面的调用，MethodHandle 是模拟字节码层面的调用。 MethodHandle 和 反射 相比好处是： 调用 invoke() 已经被 JVM 优化，类似直接调用一样。 性能好得多，类似标准的方法调用。 当我们创建 MethodHandle 对象时，实现方法检测，而不是调用 invoke() 时。 VarHandle VarHandle主要用于动态操作数组的元素或对象的成员变量。VarHandle与MethodHandle非常类似，它也需要通过MethodHandles来获取实例。 CallSite Groovy中方法的调用实现 参考 invokedynamic指令 - wade&luffy - 博客园 (cnblogs.com) Java中MethodHandle的使用问题？ - 知乎 (zhihu.com) 编译与优化 执行 解释执行 逐条将字节码翻译成机器码并执行 即时编译（Just-in-time ，JIT） 将一个方法中包含的所有字节码编译成机器码后再执行。 HotSpot 虚拟机 JIT JITWatch： jitwatch介绍和使用 - 树之下 - 博客园 (cnblogs.com) 逃逸分析 JVM 优化之逃逸分析与分配消除 面试问我 Java 逃逸分析，瞬间被秒杀了。。 GC 垃圾收集事件 Minor GC（小型 GC） 简单定义：Minor GC 清理的是年轻代，又或者说 Minor GC 就是“年轻代 GC”（Young GC，简称 YGC）。 关于 Minor GC 事件，我们需要了解一些相关的内容： 当 JVM 无法为新对象分配内存空间时就会触发 Minor GC（ 一般就是 Eden 区用满了）。如果对象的分配速率很快，那么 Minor GC 的次数也就会很多，频率也就会很快。 Minor GC 事件不处理老年代，所以会把所有从老年代指向年轻代的引用都当做 GC Root。从年轻代指向老年代的引用则在标记阶段被忽略。 与我们一般的认知相反，Minor GC 每次都会引起 STW 停顿（stop-the-world），挂起所有的应用线程。对大部分应用程序来说，Minor GC 的暂停时间可以忽略不计，因为 Eden 区里面的对象大部分都是垃圾，也不怎么复制到存活区/老年代。但如果不符合这种情况，那么很多新创建的对象就不能被 GC 清理，Minor GC 的停顿时间就会增大，就会产生比较明显的 GC 性能影响。 Major GC vs. Full GC 值得一提的是，这几个术语都没有正式的定义--无论是在 JVM 规范中还是在 GC 论文中。 我们知道，除了 Minor GC 外，另外两种 GC 事件则是： Major GC（大型 GC）：清理老年代空间（Old Space）的 GC 事件。 Full GC（完全 GC）：清理整个堆内存空间的 GC 事件，包括年轻代空间和老年代空间。 其实 Major GC 和 Full GC 有时候并不能很好地区分。更复杂的情况是，很多 Major GC 是由 Minor GC 触发的，所以很多情况下这两者是不可分离的。 另外，像 G1 这种垃圾收集算法，是每次找一小部分区域来进行清理，这部分区域中可能有一部分是年轻代，另一部分区域属于老年代。 所以我们不要太纠结具体是叫 Major GC 呢还是叫 Full GC，它们一般都会造成单次较长时间的 STW 暂停。所以我们需要关注的是：某次 GC 事件，是暂停了所有线程、进而对系统造成了性能影响呢，还是与其他业务线程并发执行、暂停时间几乎可以忽略不计。 垃圾收集器 Serial、Serial Old ParNew Parallel Scavenge、Parallel Old CMS CMS 也可称为“并发标记清除垃圾收集器”。其设计目标是避免在老年代 GC 时出现长时间的卡顿。默认情况下，CMS 使用的并发线程数等于 CPU 内核数的 1/4。 CMS 垃圾回收器详解 过程 阶段 1：Initial Mark（初始标记） 阶段 2：Concurrent Mark（并发标记） 阶段 3：Concurrent Preclean（并发预清理） 阶段 4：Concurrent Abortable Preclean（可取消的并发预清理） 阶段 5：Final Remark（最终标记） 阶段 6：Concurrent Sweep（并发清除） 阶段 7：Concurrent Reset（并发重置） 结合下面两篇文章看： 14 常见的 GC 算法（ParallelCMSG1）.md (lianglianglee.com) 19 GC 日志解读与分析（实例分析中篇）.md (lianglianglee.com) CMS 之 promotion failed & concurrent mode failure 然后 CMS 的并发周期就会被一次 Full GC 代替，退回到 Serial Old 收集器进行回收，这是一次长 Stop The World 关于 CMS 垃圾回收失败是不是进行 FULL GC 问题的记录 G1 概要 实现高吞吐量的同时，尽可能的满足垃圾收集暂停时间的要求。 它仍然属于分代收集器，但新生代，老年代的物理空间划分取消了，传统上的堆内存结构被抛弃。 G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有 cms 内存碎片问题的存在了。 不要设置年轻代的大小，通过-Xmn显式设置年轻代的大小，会干扰G1收集器的默认行为 开发人员仅仅需要声明以下参数即可： -XX:+UseG1GC -Xmx32g -XX:MaxGCPauseMillis=200 其中-XX:+UseG1GC为开启G1垃圾收集器，-Xmx32g设计堆内存的最大内存为32G，-XX:MaxGCPauseMillis=200设置GC的最大暂停时间为200ms。如果我们需要调优，在内存大小一定的情况下，我们只需要修改最大暂停时间即可。 -XX:InitiatingHeapOccupancyPercent 整个堆使用到达这个阈值时，触发一次 mixed gc，默认是45% 并发标记过程 阶段 1：Initial Mark（初始标记） 阶段 2：Root Region Scan（Root 区扫描） 阶段 3：Concurrent Mark（并发标记） 阶段 4：Remark（再次标记） 阶段 5：Cleanup（清理） Full GC G1中的 Full GC 也而是单线程串行的，而且是全暂停，使用的是标记-整理算法，代价非常高。G1的初衷就是要避免 Full GC 的出现。 CMS 收集器和 G1 收集器 他们的优缺点对比 参考： 可能是最全面的 Java G1学习笔记_xiaoye的博客-CSDN博客 转：深入理解Java G1垃圾收集器 - sidesky - 博客园 (cnblogs.com) G1垃圾回收器详解 - 简书 (jianshu.com) ZGC 新一代垃圾回收器ZGC的探索与实践 - 美团技术团队 (meituan.com) Shenandoah Epsilon：实验性的 GC，供性能分析使用 他们什么阶段会stop the world？ 看《深入理解 Java 虚拟机》3.5 节 经典垃圾收集器，这里每种收集器的执行图讲解了哪个阶段会 STW JVM 默认启用的收集器是哪些？ 看《深入理解 Java 虚拟机》3.7.4 节 垃圾收集器参数总结，这个讲解了 client 和 server 模式下的默认值，以及开启其他收集器的参数 参考： Java虚拟机垃圾回收——7种垃圾收集器 垃圾收集器_晏霖/胖虎的博客 GC 性能优化 4. GC 算法(实现篇) - GC 参考手册 7. GC 调优(实战篇) - GC参考手册 Java 方法 finalize() 该方法会在垃圾收集器交换回收对象之前被调用。如果在finalize()方法中，又使得该对象被程序引用(俗称复活了)，则该对象就变成了可触及的对象，暂时不会被垃圾收集了。每个对象只能调用一次finalize( )方法，所以每个对象也只可能 \"复活 \"一次。 System.gc() 建议执行垃圾收集 GC 日志 日志解读 注意 Minor GC 和 Full GC 时的日志 17 GC 日志解读与分析（基础配置）.md (lianglianglee.com) 18 GC 日志解读与分析（实例分析上篇）.md (lianglianglee.com) 19 GC 日志解读与分析（实例分析中篇）.md (lianglianglee.com) Java9 后的日志格式变化 使用：-XX:+PrintCommandLineFlags -Xlog:gc*=debug:./gc.log:level,time,tags Disruptive Changes to GC Logging in Java 9 - DZone Java 分析工具 Universal JVM GC analyzer - Java Garbage collection log analysis made easy (gceasy.io) 调优 GC日志中 real 时间比 user + sys 时间长该如何处理？ 可能导致 FullGC 的原因有以下几种。 老年代空间不足。 永生代或者元数据空间不足。 程序执行了 System.gc() //建议 jvm 执行 fullgc，并不一定会执行。 CMS GC 时出现 promotion failed 和 concurrent mode failure YoungGC 时晋升老年代的内存平均值大于老年代剩余空间（执行 minor gc 的时候进行的一系列检查） 有连续的大对象需要分配 执行了 jmap -histo:live pid 命令 //这个会立即触发 fullgc 出现 Full GC 一般是不正常 参数 Young Tenured JVM options Incremental(增量GC) Incremental -Xincgc Serial Serial -XX:+UseSerialGC Parallel Scavenge Serial -XX:+UseParallelGC -XX:-UseParallelOldGC Parallel New Serial N/A Serial Parallel Old N/A Parallel Scavenge Parallel Old -XX:+UseParallelGC -XX:+UseParallelOldGC Parallel New Parallel Old N/A Serial CMS -XX:-UseParNewGC -XX:+UseConcMarkSweepGC Parallel Scavenge CMS N/A Parallel New CMS -XX:+UseParNewGC -XX:+UseConcMarkSweepGC G1 -XX:+UseG1GC 主要使用的是上表中黑体字表示的这四种组合。其余的要么是被废弃(deprecated)，要么是不支持或者是不太适用于生产环境。 eg. Jdk8： -XX:+PrintCommandLineFlags -Xms52m -Xmx52m -Xloggc:gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps Serial：-XX:+UseSerialGC Parallel：-XX:+UseParallelGC -XX:+UseParallelOldGC CMS：-XX:+UseConcMarkSweepGC G1：-XX:+UseG1GC Jdk9+： -XX:+PrintCommandLineFlags -Xms52m -Xmx52m -Xlog:gc*=debug:gc.log:level,time,tags Q&A static 会被 GC 回收吗？static 的在内存中的存放位置？ 永久代不够会触发 Full GC 吗 性能调优 JVM参数 注意 JDK 版本，不一定都通用 堆区： -Xms and -Xmx (or: -XX:InitialHeapSize and -XX:MaxHeapSize，实际上是两者的缩写) -Xmn（or: -XX:NewSize and -XX:MaxnewSize，-Xmn 是对两者的同时配置，JDK4生效） -Xss，设置每个线程的堆栈大小，JDK5.0以后每个线程堆栈大小为1M -XX:NewRatio -XX:SurvivorRatio -XX:MetaspaceSize -XX:MaxMetaspaceSize，JDK8后替换永久代 -XX:+UseCompressedOops -XX:+UseCompressedClassPointers，目的是为了在 64bit 机器上使用 32bit 的原始对象指针 非堆区： -XX:PermSize -XX:MaxPermSize JVM调优总结 -Xms -Xmx -Xmn -Xss 工具 原生工具 jps、jstat、jinfo、jstack、jmap、jhat jstat -gcutil Java性能调优工具 图形化工具 JMC（JDK Mission Control） JFR（Java Flight Recorder） JVisualVM 使用 VisualVM 进行性能分析及调优 MAT（Eclipse Memory Analyzer） Atthas Arthas 是基于 Greys 进行二次开发的全新在线诊断工具 Arthas 使用指南 快速入门 — Arthas 3.5.5 文档 (aliyun.com) FastThread FastThread 是一款线程转储(Thread Dump)分析工具，官网地址为：http://fastthread.io/ 。 这款工具由 tier1app 公司 开发和支持，这家公司现在主要提供 3 款 JVM 分析工具，除了 FastThread 还有： GCEasy，访问地址：https://gceasy.io/，详情请参考前面的文章 [《GC 日志解读与分析（番外篇可视化工具）》]。 HeapHero，官网地址：https://heaphero.io/，顾名思义，这是一款 Heap Dump 分析工具。 反汇编 大多数情况下，通过诸如javap等反编译工具来查看源码的字节码已经能够满足我们的日常需求，但是不排除在有些特定场景下，我们需要通过反汇编来查看相应的汇编指令。 两个很好用的工具——HSDIS、JITWatch Java反汇编：HSDIS、JITWatch - 知乎 (zhihu.com) Linux 看linux章节的系统监控小结 Java 新特性 Java 7 JDK7 动态方法调用 java.lang.invoke 包 主要包含了 CallSite、MethodHandle、MethodType 等类 MethodHandle 看 MethodHandle 新增了 invokedynamic 指令 ForkJoin Java 8 时间类：Instant 和 LocalDate，LocalTime，LocalDateTime 如果是 JDK8 的应用，可以使用 Instant 代替 Date，LocalDateTime 代替 Calendar，DateTimeFormatter 代替 Simpledateformatter，官方给出的解释：simple beautiful strong immutable thread-safe。 附：测试代码请看 metis: com.ariescat.metis.base.time.LocalDateTimeTest stream parallelStream 函数式编程 Java 函数优雅之道 Optional 类 Supplier 接口和 Consumer 接口 （JDK8 以下可用 guava 替代） Alyx 的 FileLoader 优化用到了 Supplier CompletableFuture 强大的函数式异步编程辅助类 可以比较一下 Google Guava，其也提供了通用的扩展 Future：ListenableFuture、SettableFuture 以及辅助类 Futures 等，方便异步编程。 windforce AbstractChatChannel Java CompletableFuture 详解 · 鸟窝 (colobu.com) [译]20 个使用 Java CompletableFuture 的例子 · 鸟窝 (colobu.com) 语法糖 Lambda 实现原理 非捕获式 (non-capturing lambda) 和捕获式 (capturing lambda) Java 中的 lambda 每次执行都会创建一个新对象吗？ 测试代码：study-metis: com.ariescat.metis.base.jdk8.lambda.LambdaTest2，参考链接 ::（双冒号）的实现原理 List al = Arrays.asList(\"a\", \"b\", \"c\", \"d\"); al.forEach(AcceptMethod::printValur); //下面的方法和上面等价的 Consumer methodParam = AcceptMethod::printValur; //方法参数 al.forEach(x -> methodParam.accept(x));//方法执行 accept JVM 元空间（Metaspace） Java 9 Reactive Streams Flow API HTTP / 2 Client 统一的JVM日志系统 Java 11 直接运行源代码 ZGC 垃圾收集器 Java 12 Shenandoah 垃圾收集器 Q&A JDK 1.8 下的 java.lang.Class 对象和 static 成员变量在堆还是方法区？ 书单 《深入理解 Java 虚拟机（第 3 版）（周志明）》 《Java 并发编程实战》 《Effective Java》 Groovy 入门： 30 分钟 groovy 快速入门并掌握 Groovy 语言快速入门 Java中使用： 实战 Groovy，在 Java 应用程序中加一些 Groovy 进来 利用 SPRING 管理热加载的 GROOVY 对象 spring + groovy 很强大 Spring 动态部署 Bean/Controller/Groovy Controller Gradle中使用： Groovy as DSL 与 Gradle Gradle：新一代自动化构建工具 Groovy DSL 百度搜索 gradle dsl Android UI 使用 NavigationUI 更新界面组件 抽屉式导航栏 Material Design NavigationView FlaotingActionBar SnackBar Design Support Library RecyclerView SwipeRefreshLayout 控件点击水波纹 权限 Android 6.0在运行时申请权限解释与实例_Widsom的博客-CSDN博客 EventBus 3事件总线 从源码入手来学习EventBus 3事件总线机制 图表 hellocharts 工具 AndroidDevTools - Android 开发工具 Android SDK 下载 Android Studio 下载 Gradle 下载 SDK Tools 下载 doc 开发者指南 · Android 开发者 · Android Developers android-open-source-project-analysis henrymorgen / android-advanced-decode 《Android 进阶解密》源码 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Base/C++.html":{"url":"Note_Base/C++.html","title":"C++","keywords":"","body":"《C++》 C++基础 基本类型 浮点数比较 fabs(f1-f2) 而abs()函数是针对整数的 字符串string C语言没有原生的字符串类型！ C风格字符串就是最后一位为'\\0'的字符数组！C语言通过字符指针来管理字符串！ 在C++语言中，除了继承了C语言中的这种字符串表达形式外，还新添了string类用来表达字符串。为了区分C++中这两种不同的字符串，使用”C风格字符串”来特指来源于C语言的字符串存储方式。 string.h 注意： #include 和 #include 是相同作用的，而#include 是C++字符串变量 string 必须要的头文件（包含一些操作符的重载等）。 一些重要的方法： memcpy memset C 标准库 – | 菜鸟教程 (runoob.com) \"\\ddd\" 和 \"\\xhh\" 分别是什么意思? \"\\ddd\" 表示1~3位八进制数ddd对应的字符，例如 '\\141' 代表字符常量 'a' \"\\xhh\" 表示1~2位十六进制数hh对应的字符，例如 '\\x41' 代表字符常量 'A' 如：putchar('\\101')输出字符A；putchar('\\015')输出回车，不换行，使输出的当前位置移到本行开头 数组/vector 数组长度 C++中没有直接提供求数组长度的方法，提供了sizeof(),begin(),end()等方法，可以供求数组长度使用。 sizeof不是函数，是操作符，它是编译时求一个类型所占的字节数。 ​ begin(),end() C++11标准库函数 C++ STL 迭代器的成员函数 C++标准库函数 end 的实现原理： 在刚开始学习《C++ Primer》的时候遇到了 end 函数，感觉很神奇，但又很迷惑：为什么能获得数组的尾后指针呢？编译器也不会在内存中申请一块空间放数组元素的个数啊！最近再一次遇到了 end 就看了一下它的实现终于明白了。 先说以下C语言中获得数组元素个数的方法。 int arr[] = {1, 2, 3}; size_t n = sizeof(arr) / sizeof(int); //n为元素个数 sizeof 返回一个常量表达式，是在编译时期确定返回值的。也就是说在编译时期是可以知道数组的长度的。 再看看 C++标准库中 end 的实现（关键部分：非类型模板参数 N 及函数形参）： //编译器再编译时期会根据数组的元素个数来代替N，从而实例化模板 template inline constexpr T* end(T (&arr)[N]) { //由于不能拷贝一个数组，所以将参数定义为了数组的引用 return arr + N; //指针和一个整数N（数组元素个数）相加，从而返回数组arr的尾后指针 } 模板参数列表中的 N 是一个非类型模板参数，而非类型模板参数是在编译时期被确定的常量表达式。end 函数的形参是一个（长度为N）数组的引用，因为 N 是一个非类型模板参数，所以编译器会在编译时期（前面说过，在编译时期是可以确定数组长度的）用数组的长度来初始化 N。最后将 arr 和 N 相加即获得了数组的尾后指针。 ​ 动态申请二维数组 动态申请二维数组（C语言版）_楚楚可薇的博客-CSDN博客 利用一个二级指针来实现 //5 行 2 列的数组 int **p = (int **)malloc(sizeof(int *) * 5); for (int i = 0; i 利用数组指针来实现 //申请一个 5 行 2 列的整型数组 int(*p)[2] = (int(*)[2])malloc(sizeof(int) * 5 * 2); //输出数组每个元素地址 printf(\"%p\\n\", &p[i][j]); 利用一维数组来模拟二维数组 int *p = (int *)malloc(sizeof(int) * 5 * 2); //输出数组每个元素地址 printf(\"%p\\n\", &p[i*2+j]); malloc返回的其实是void *，所以其需要强转，void *的用处还有memcpy，memset等 指针数组&数组指针 指针数组，首先它是一个数组，数组里面的每个元素都是一个指针，例如比如int *p[4] 就是一个指针数组，因为运算符[]的优先级比运算符*的优先级高，所以p优先和[]组成数组，然后*和类型int组合成数组元素的类型。 数组指针，首先它是一个指针，这个指针所指向的对象是数组，比如这个指针是p，那么通过解引用*p获得内容就是一个数组，例如int (*p)[4]，主意带上括号， 通常数组指针也作为一个二维数组来使用。 int a[2][3]={ {1,2,3}, {4,5,6} }; int (*p)[3] = a; 等价关系： a+i == p+i a[i] == p[i] == *(a+i) == *(p+i) a[i][j] == p[i][j] == *(a[i]+j) == *(p[i]+j) == *(*(a+i)+j) == *(*(p+i)+j) const const int* pInt; 和 int *const pInt = &someInt;，前者是 pInt 不能改变，而后者是 pInt 不能改变。因此指针本身是不是常量和指针所指向的对象是不是常量就是两个互相独立的问题。用顶层表示指针本身是个常量，*底层表示指针所指向的对象是个常量。 int i = 0; int *const p1 = &i; // 不能改变 p1 的值，这是一个顶层 const int ci = 42; // 不能改变 ci 的值，这是一个顶层 const int *p2 = &ci; // 允许改变 p2 的值，这是一个底层 const int *const p3 = p2; // 靠右的 const 是顶层 const，靠左的是底层 const const int &r = ci; // 所有的引用本身都是顶层 const，因为引用一旦初始化就不能再改为其他对象的引用，这里用于声明引用的 const 都是底层 const 静态变量与全局变量 全局变量：全局变量在整个程序中都是可见的，可以在任何函数中使用。全局变量在程序的生命周期内一直存在，直到程序结束才被销毁。全局变量在定义时可以不初始化，系统会自动初始化为0。 int global_var; // 全局变量 静态全局变量：静态全局变量的作用范围仅限于当前文件，其他文件不能访问。静态全局变量在程序的生命周期内一直存在，直到程序结束才被销毁。静态全局变量在定义时可以不初始化，系统会自动初始化为0。 static int static_global_var; // 静态全局变量 静态局部变量：静态局部变量只在定义它的函数内部可见，但它的生命周期和全局变量一样，直到程序结束才被销毁。静态局部变量在定义时可以不初始化，系统会自动初始化为0。 void func() { static int static_local_var; // 静态局部变量 } 局部变量：局部变量只在定义它的函数内部可见，当函数返回时，局部变量就会被销毁。局部变量在定义时必须初始化，否则其值是不确定的。 void func() { int local_var; // 局部变量 } 总结：全局变量和静态全局变量的区别在于作用范围，全局变量在整个程序中都可见，而静态全局变量只在当前文件中可见。静态局部变量和局部变量的区别在于生命周期，静态局部变量在程序结束时才销毁，而局部变量在函数返回时就销毁。 C++标准库 介绍 C++:STL（Standard Template Library，标准模板库） STL的代码从广义上讲分为三类：algorithm（算法）、container（容器）和iterator（迭代器），几乎所有的代码都采用了模板类和模版函数的方式，这相比于传统的由函数和类组成的库来说提供了更好的代码重用机会。在C++标准中，STL被组织为下面的13个头文件： 、、、、、、、、、、、、。 #include包含C++的全部头文件 C++:STL标准入门汇总 - 施杨 - 博客园 (cnblogs.com) C++ - STL常见容器及其常见操作_c++ set pop-CSDN博客 IO库 输入输出重定向 在默认情况下，cin 只能接收从键盘输入的数据，cout 也只能将数据输出到屏幕上。但通过重定向，cin 可以将指定文件作为输入源，同样 cout 可以将原本要输出到屏幕上的数据转而写到指定文件中。 实现： freopen()函数 rdbuf()函数 在控制台中使用 > 或者 C:\\Users\\mengma>D:\\demo.exe out.txt 打印格式 %3d 可以指定宽度，不足的左边补空格 %-3d 左对齐 %03d 一种左边补0 的等宽格式,比如数字12,%03d出来就是: 012 高级 指针 指针为什么有类型 为了指针运算和取值。 数组指针 看上面「数组」部分内容。 二级指针 指向指针的指针，道理是这么个道理，但有什么用？ 二级指针在C++中可能用的不多，但是在C中是经常使用的一把利器，它通常作为一个函数的参数，起到在函数内部对一个指针进行初始化的作用， 比如经典的音视频处理工具FFmpeg中就大量使用了二级指针。以下例子展示如何通过二级指针对指针形式赋值： void initP(int **p){ *p = new int(10); } int main() { int *p = nullptr; // 一个空的指针 initP(&p); // 通过二级指针初始化指针p std::cout 难道不能通过给函数传递一级指针给指针初始化吗？这是不行的，这是因为值传递的缘故。具体可看：二级指针作用_XZshijian的博客-CSDN博客 指针与多态绑定 在C++语言中，当我们使用基类的引用（或指针）调用一个虚函数时将发生动态绑定。也就是说使用通过父类的指针或引用就能按照实参的实际类型是父类还是子类调用不同的虚函数。 class Base{ public: virtual void print() const{ std::cout 为什么在上面的程序中变量a的实际类型是Child，但是函数testPrint内部调用的却是父类的打印方法呢？不是说引用会触发多态吗？函数testPrint也是通过引用传递的呀， 真是百思不得其jie呀。 要解开这个疑惑就得了解下静态类型和动态类型的知识了。静态类型在编译时总是已知的，首先静态类型是变量声明时的类型或表达式生成的类型；动态类型则是变量或表达式表示的内存中的对象的类型，动态类型直到运行时才可知。如果变量在定义时表达式既不是引用也不是指针，则它的动态类型永远与静态类型一致的，也就是声明时所指的类型，否则的话静态类型可能与动态类型不一致。 函数指针 返回值类型 (*函数名) (参数) 函数指针的一个重要用途就是作为函数的参数，用于在函数内部进行指针函数的调用，一般用作回调函数 类成员指针 ::* 类成员指针可以指向类的非静态成员。一般情况下，一个指针指向一个对象，但是成员指针指示的是类的成员，而非类的对象。指向类的静态成员的指针和普通指针没有什么区别。 类成员函数指针指向类的成员函数的指针。 引用 指针和引用的区别 指针可以为空，引用必须初始化，引用不能为空 指针可以被重新赋值，但是引用不行。也就是指针可以重新指向另外一个对象，而引用却不行，引用一直指向的都是最初的那个对象。 指针可以有多级，而引用只能是一级，例如我们平时说的指向指针的指针，也就是二级指针，但是就没有所谓的指向引用的引用。 有了指针为什么还需要引用？我们都知道指针在使用过程中需要特别地小心，很容易就出现空指针、野指针等令人诟病的问题。但是引用因为它自始至终都是指向一个单一的对象，所以引用比指针更具安全性， 而且使用引用在处理C++的某些问题更加的得心应手，例如运算符的重载等。 C语言是没有引用的，引用是在C++里面才存在的神级操作。 有了引用为什么还需要指针？在C++中既然有了引用，设置引用的性能比指针更高点，那么为什么还需要指针呢？为了兼容C语言。 返回引用还是返回指针？这个要看具体的使用场景，如果作为函数的返回值，C++明确表明是不可以返回局部对象的引用的，因为局部对象在函数返回后就会被析构掉，所以返回它的引用也就没有了意义。但返回非局部对象的引用是允许的，例如STL中vector中按下标取值就可以返回一个引用。 如果确实需要返回一个局部对象的话，可以返回一个在堆中的对象指针。暗示返回一个局部对象的指针的话会引发另外一个问题， 那就是这个指针什么时候释放呢？由谁来释放呢？一旦管理不好，内存泄漏是分分钟的事情。因此如果是非局部对象的话可以返回对象的引用，否则可以按值返回，按值返回特别是在C++11之后已经自带了RVO优化， 可以放心使用，更多RVO相关只是可以看《C++之RVO返回值优化》 。 指向指针的引用 首先要说明的是指向指针的引用，它是一个引用，而不是指针，指针本质上来说是一个内存地址，但是引用并不是一个对象，引用不会开辟新的内存空间，所以不存在着指向引用的指针这么一说。 例如下面的示例代码： int i = 100; int *p; int *&r = p; // r是一个引用，引用类型是指针 r = &i; //因为r是一个引用，所以给r赋值，就是将p指向i *r = 0; // 解引用r，也就是将指针p指向的值改为0，也就是将i改为0 从右向左阅读，r的定义离变量名最近的符号（此例中是&r的符号&）对变量的类型有最直接的影响。因此r是一个引用，它引用的对象是一个int类型的指针。 多态与重载 多态性分两个部分： 静态多态性：通过重载实现，同名不同参。 动态多态性：多态，子类覆盖父类方法，运行时根据指针的类型来决定最终执行的方法。即：虚函数。 delete和delete[] 如果调用delete，只会调用一次析构函数，如果调用delete[]会多次调用析构函数。当类的析构函数中需要去释放堆内存的时候，本该用delete[]多次调用析构函数，结果用delete，只调用了一次析构函数，那么就会造成内存泄漏。 模板编程 wuye9036/CppTemplateTutorial (github.com) ​ 中文的C++ Template的教学指南。与知名书籍C++ Templates不同，该系列教程将C++ Templates作为一门图灵完备的语言来讲授，以求帮助读者对Meta-Programming融会贯通。(正在施工中) ​ Introduction · C++ Template Tutorial (gitbooks.io) downdemo/Cpp-Templates-2ed (github.com) ​ C++11/14/17/20 templates and generic programming, the most complex and difficult technical details of C++, indispensable in building infrastructure libraries. 类型转换 C++ 四种强制类型转换 - 静悟生慧 - 博客园 (cnblogs.com) static_cast dynamic_cast const_cast reinterpret_cast 内存管理 C /C++的内存管理 C/C++内存管理详解 | ShinChan's Blog (chenqx.github.io) 内存分配方式 在C++中，内存分成5个区，他们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区。 栈：在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。 堆：就是那些由 new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个new就要对应一个 delete。如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收。 自由存储区：就是那些由malloc等分配的内存块，他和堆是十分相似的，不过它是用free来结束自己的生命的。 全局/静态存储区：全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。 常量存储区：这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。 alloca 和 malloc alloca(), malloc(), calloc() 和 realloc() 都是用于动态内存分配的函数，但它们的行为和用途有所不同。 alloca(): 在栈上分配内存，而不是在堆上。分配的内存会在函数返回时自动释放，无需手动释放。但是，alloca() 不是标准的 C 或 C++ 函数，因此可能在某些平台上不可用。 #include void func() { int* arr = (int*)alloca(10 * sizeof(int)); // 使用 arr... // 函数返回时，arr 会自动被释放 } malloc(): 在堆上分配指定大小的内存。返回的是一个指向分配的内存的指针，或者如果内存分配失败，则返回 NULL。需要使用 free() 手动释放内存。 #include int* arr = (int*)malloc(10 * sizeof(int)); if (arr != NULL) { // 使用 arr... free(arr); // 不再需要时，释放内存 } calloc(): 类似于 malloc()，但会将分配的内存初始化为零。它需要两个参数：要分配的元素数量和每个元素的大小。 #include int* arr = (int*)calloc(10, sizeof(int)); if (arr != NULL) { // 使用 arr... free(arr); // 不再需要时，释放内存 } realloc(): 改变已分配内存的大小。如果新的大小大于原来的大小，那么原来的内存区域将被复制到新的、更大的区域，原来的内存区域将被释放。如果新的大小小于原来的大小，那么原来的内存区域将被缩小，多余的内存将被释放。 #include int* arr = (int*)malloc(10 * sizeof(int)); if (arr != NULL) { // 使用 arr... arr = (int*)realloc(arr, 20 * sizeof(int)); // 扩大内存区域 if (arr != NULL) { // 使用新的 arr... free(arr); // 不再需要时，释放内存 } } 请注意，malloc(), calloc() 和 realloc() 分配的内存必须使用 free() 手动释放，否则会导致内存泄漏。 malloc 和 free 基于系统调用 sbrk 或 mmap 实现 分配的内存位于 [heap] 或者 匿名 mmap 编译 内存对齐 为什么要内存对齐：C++：内存对齐_六月的翅膀的博客-CSDN博客 结构体占用内存大小 .hpp与.h区别 .hpp，本质就是将.cpp的实现代码混入.h头文件当中，定义与实现都包含在同一文件，则该类的调用者只需要include该.hpp文件即可，无需再将cpp加入到project中进行编译。而实现代码将直接编译到调用者的obj文件中，不再生成单独的obj，采用hpp将大幅度减少调用project中的cpp文件数与编译次数，也不用再发布lib与dll文件，因此非常适合用来编写公用的开源库。 原文链接：https://blog.csdn.net/f_zyj/article/details/51735416 gcc与g++的区别 编译的四个阶段 预处理：编译处理宏定义等宏命令（eg:#define）——生成后缀为“.i”的文件 编译：将预处理后的文件转换成汇编语言——生成后缀为“.s”的文件 汇编：由汇编生成的文件翻译为二进制目标文件——生成后缀为“.o”的文件 连接：多个目标文件（二进制）结合库函数等综合成的能直接独立执行的执行文件——生成后缀为“.out”的文件 在我们理解了上述四个流程后，我们在关注gcc和g++在流程上的区别。 gcc无法进行库文件的连接，即无法编译完成步骤4；而g++则能完整编译出可执行文件。（实质上，g++从步骤1-步骤3均是调用gcc完成，步骤4连接则由自己完成） C++11 右值引用 意义 C++之右值引用 - 简书 (jianshu.com) 右值引用是 C++11 引入的与 Lambda 表达式齐名的重要特性之一。它的引入解决了 C++ 中大量的历史遗留问题，消除了诸如 std::vector、std::string 之类的额外开销。 左值就有内存地址的，存活的生命周期较长的，而右值一般是无法获取到内存地址的（比如整形字面量）。 右值引用的特点之一是可以延长右值的生命周期；但，延长临时对象生命周期并不是这里右值引用的最终目标，其真实目标应该是减少对象复制，提升程序性能。 将亡值 【乔红】裤衩 C++ 之 右值引用（一）为什么会有右值引用_哔哩哔哩_bilibili 移动构造函数 先说拷贝构造函数，默认拷贝构造函数： c++类的中有两个特殊的构造函数，(1)无参构造函数，(2)拷贝构造函数。它们的特殊之处在于： (1)当类中没有定义任何构造函数时，编译器会默认提供一个无参构造函数且其函数体为空； (2)当类中没有定义拷贝构造函数时，编译器会默认提供一个拷贝构造函数，进行成员变量之间的拷贝。(这个拷贝操作是浅拷贝) 了解深拷贝和浅拷贝： 拷贝者和被拷贝者若是同一个地址，则为浅拷贝，反之为深拷贝。 类的默认拷贝构造函数只会用被拷贝类的成员的值为拷贝类简单初始化，也就是说二者的p指针指向的内存空间是一致的。 默认拷贝构造函数的弊端： c++ 拷贝构造函数(重点在内含指针的浅拷贝和深拷贝) - 知行者的博客 - 博客园 (cnblogs.com) class TestCls{ public: int a; int *p; public: TestCls(){ p = new int; } ~TestCls(){ delete p; } }; int main(void){ TestCls t1; TestCls t2 = t1; //效果等同于TestCls t2(t1); return 0; } 编译器为我们默认定义的拷贝构造函数为： TestCls(const TestCls &testCls) { a = testCls.a; p = testCls.p; //两个类的p指针指向的地址一致。 }; main函数将要退出时，拷贝类t2的析构函数先得到执行，它把自身p指向的堆空间释放了；接下来，t1的析构函数得到调用，被拷贝类t1的析构函数得到调用，它同样要去析构自身的p指向指向的堆空间，但是该空间和t2类中p指向的空间一样，造成重复释放，程序运行崩溃。（当然，如果只有基本类型数据是没有问题的） 解决办法就是自定义拷贝构造函数： class TestCls{ public: int a; int *p; public: TestCls(){ p = new int; } TestCls(const TestCls &testCls){ a = testCls.a; // p = testCls.p; p = new int; *p = *(testCls.p); //为拷贝类的p指针分配空间，实现深度拷贝 } ~TestCls(){ delete p; } }; 所以，当类中拥有指针类型的成员变量时，拷贝构造函数中需要以深拷贝（而非浅拷贝）的方式复制该指针成员。 C++11移动构造函数的功能和用法： 直接看这篇吧： C++11移动构造函数的功能和用法_Hardy20200507的博客-CSDN博客 TestCls(TestCls &&t) : p(t.p) { t.p = NULL; std::cout 也就是，在之前 TestCls 类的基础上，我们手动为其添加了一个构造函数。和其它构造函数不同，此构造函数使用右值引用形式的参数，又称为移动构造函数。并且在此构造函数中，num 指针变量采用的是浅拷贝的复制方式，同时在函数内部重置了 d.num，有效避免了“同一块对空间被释放多次”情况的发生。 在实际开发中，通常在类中自定义移动构造函数的同时，会再为其自定义一个适当的拷贝构造函数，由此当用户利用右值初始化类对象时，会调用移动构造函数；使用左值（非右值）初始化类对象时，会调用拷贝构造函数。 std::move 什么是move？理解C++ Value categories，move， move in Rust c++ - std::move()源码分析 - chenBright - SegmentFault 思否 为什么C/C++等少数编程语言要区分左右值？ 参考： 为什么C/C++等少数编程语言要区分左右值？ - 知乎 (zhihu.com) 函数返回数据的 3 种处理方式： 直接存在寄存器里 直接操作用于接收返回值的变量（如果是平凡的，直接操作；如果是非平凡的，先操作好一个局部变量，然后再拷贝过来） 先放在一个临时的内存空间中，使用完后再析构掉 C++按照这个特征来划分了 prvalue 和 xvalue。 本文第四个重点！！「引用本身是 lvalue」。也就是说，函数返回值是 rvalue（有可能是 prvalue，也有可能是 xvalue），但如果你用引用来接收了，它就会变成 lvalue。 在使用智能指针时，通常需要使用 std::move 来进行对象的转移。 对于 std::unique_ptr，由于它不能被复制，因此只能使用 std::move 来将其转移给另一个 std::unique_ptr。对于 std::shared_ptr，由于它可以被多个指针共享，因此需要使用 std::move 来将其转移给另一个 std::shared_ptr，或者使用 std::make_shared 来创建一个新的 std::shared_ptr。 std::move 对于 std::shared_ptr 的行为与其他类型的对象略有不同。 std::shared_ptr 是一种智能指针，它会自动管理动态分配的内存，并在不再需要时自动释放。std::move 可以将 std::shared_ptr 的所有权转移给另一个 std::shared_ptr，但是不会影响内存的引用计数。 具体来说，当使用 std::move 将一个 std::shared_ptr 转移给另一个 std::shared_ptr 时，会将源 std::shared_ptr 中的指针和引用计数移动到目标 std::shared_ptr 中，同时将源 std::shared_ptr 置为空指针。这样做可以避免不必要的内存复制和引用计数的增加，从而提高性能。 下面是一个示例代码，演示了如何使用 std::move 将一个 std::shared_ptr 转移给另一个 std::shared_ptr： #include #include int main() { std::shared_ptr p1 = std::make_shared(42); std::shared_ptr p2 = std::move(p1); // 将 p1 的所有权转移给 p2 std::cout 需要注意的是，使用 std::move 转移 std::shared_ptr 时，需要确保源 std::shared_ptr 不再需要使用，否则可能会导致内存泄漏或者程序崩溃。此外，还需要注意避免出现循环引用的情况，否则可能会导致内存泄漏。 std::forward 回顾上面的「C++之右值引用 - 简书 (jianshu.com)」链接： 先了解万能引用： 所谓的万能引用就是既可以引用左值，也可以引用右值的引用。 void test(int &t){ // 左值引用 } void test(int &&t){ // 右值引用，有明确的类型 } template void test(T &&){ // 万能引用，因为模板需要类型推导 } int getNum(){ return 20; } int main() { int &&num1 = getNum(); // 右值引用 auto &&num2 = getNum(); // 万能引用，类型推导 return 0; } 在上面的注释中我们发现只要发生了类型推导就会是万能引用，在T&&和auto&&的初始化过程中都会发生类型的推导所以它们是万能引用。在这个推导过程中，初始化的源对象如果是一个左值，则目标对象会推导出左值引用；反之如果源对象是一个右值，则会推导出右值引用。 完美转发： 万能引用，它的一个重要用途就是进行完美转发，所谓完美转发指的是函数模板可以将自己的参数“完美”地转发给内部调用的其它函数，不仅能准确地转发参数的值，还能保证被转发参数的左、右值属性不变。在C++11使用标准库中的std::forward函数就可以试下完美转发： void test(int &t){ // 左值引用 cout void funcForward(T &&t){ // 进行了转发，根据传递进来的值类型而调用不同test test(std::forward(t)); } template void funcNormal(T &&t){ // 没有进行转发，始终调用的都是左值的test test(t); } int main() { int a = 20; funcNormal(1); // 右值，但是调用的是左值的test funcNormal(a); // 左值 cout RVO返回值优化 RVO的全称是Return Value Optimization。RVO是一种编译器优化技术，可以把通过函数返回创建的临时对象给”去掉”，然后可以达到少调用拷贝构造的操作目的， 它是C++11标准的一部分。 上面「引用」小节有一篇文章链接「《C++之RVO返回值优化》」，可以看看。 智能指针 C++11 新标准增添了 unique_ptr、shared_ptr 以及 weak_ptr 这 3 个智能指针来实现堆内存的自动回收。 C++之智能指针 (qq.com) 头文件 智能指针不是一个指针，它其实是一个对象。它是通过C++的RAII机制实现的。主要是利用C++中对象在释放的时候，会自动调用析构函数这一特性。 c++智能指针 - 知乎 (zhihu.com) 注意：不要使用裸指针进行初始化 因为使用裸指针初始化智能指针，容易导致多次使用同一个裸指针对多个智能对象进行初始化。这样就会导致两个智能指针在销毁的时候会去释放同一片内存空间。会造成程序异常崩溃。 如： Test* pTest = new Test(); shared_ptr t(pTest); //t1释放的时候会导致程序异常 shared_ptr t1(pTest); 注意：循环引用 shared_ptr的两个对象中各有一个智能指针类型的成员，而且这两个智能指针指向的都是对方的内存空间。 auto和decltype auto、decltype是C++11新增特性，主要是用来做类型推导。这个特性是C++11新增特性，但是这个功能，C++编译器之前就具备，只是未对开发者开放使用。 auto会忽略变量顶层的const、&属性，也就是说，一个变量如果是const int类型的，那么，如果用auto推导之后获取的变量类型则会是int。同样，&（引用）属性也会被忽略，如，int &，用auto推导之后就会变成int类型，但decltype不会这样： const int ci = 42, &cj = ci; decltype(ci) x = 0; //变量x的类型是const int auto z = ci; //变量z的类型是int decltype (cj) y = x; //变量y的类型是const int& auto w = cj; //变量w的类型是int 其他 调用其他语言 Python C++调用Python Python调用C++ 包管理工具 vcpkg microsoft/vcpkg: C++ Library Manager for Windows, Linux, and MacOS (github.com) vcpkg是Microsoft的跨平台开源软件包管理器，极大地简化了 Windows、Linux 和 macOS 上第三方库的购置与安装。如果项目要使用第三方库，建议通过 vcpkg 来安装它们。 第三方库 skynet 一个基于C跟lua的开源服务端并发框架，这个框架是单进程多线程模型 boost Boost 库通过加入一些在实践中非常有用的函数对 C++ 标准进行了补充。 Boost C++ 库-在线教程 网络库 libevent boost 的 asio 一个很强大的实现socket通讯方式的跨平台（windows、linux、solaris、mac os x）解决方案，能同时支持数千个并发的连接。 Boost.Asio的使用技巧 | blog | 逍遥郡 (jqian.net) 关于 Boost.Asio 的多线程模型： 浅谈 Boost.Asio 的多线程模型 - Boblim - 博客园 (cnblogs.com) zeromq 七大消息模式： 重头戏！带你全览ZeroMQ的七大消息模式_董哥的黑板报的博客-CSDN博客 主要API接口： 消息队列库——ZeroMQ - 如果的事 - 博客园 (cnblogs.com) 指南： 介绍 | ZMQ 指南 (gitbooks.io) 云风的 BLOG: ZeroMQ 的模式 (codingnow.com) 引用： 基于定义好的模型，我们可以看到，api 可以实现的非常简单易用。我们不再需要 bind/listen/accept 来架设服务器，因为这个模型天然是 1:N 而不是 1:1 的，不需要为每个通道保留一个句柄。我们也不必在意 server 是否先启动（bind），而后才能让 client 工作起来（connect）。 全网仅此一篇！万字详解ZeroMQ的zmqmsg_t消息处理、多部分消息、及消息接口董哥的黑板报的博客-CSDN博客 服务发现 etcd Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Base/Python,Go.html":{"url":"Note_Base/Python,Go.html","title":"Python,Go","keywords":"","body":"《Python》 动态语言与动态类型语言 动态语言： 动态语言或动态编程语言，Dynamic programming Language 动态语言是指程序在运行时可以改变其结构，新的函数可以被引进，已有的函数可以被删除等在结构上的变化。 动态类型语言： 动态类型语言是指在运行期间才去做数据类型检查的语言，说的是数据类型，动态语言说的是运行是改变结构，说的是代码结构。 运算符重载 判断两个字典是否相同 一个一个key比较过去？ 可以直接用==进行判断！！！ a = dict(one=1, two=2, three=3) b = {'one': 1, 'two': 2, 'three': 3} c = dict(zip(['one', 'two', 'three'], [1, 2, 3])) d = dict([('two', 2), ('one', 1), ('three', 3)]) e = dict({'three': 3, 'one': 1, 'two': 2}) print(a == b == c == d == e) ​ Python内部对==进行了重载，帮你实现了对key和value进行判断。 怎样在两个字典中寻找相同点（比如相同的键、相同的值等）？ 解决方案 考虑下面两个字典： a = { 'x' : 1, 'y' : 2, 'z' : 3 } b = { 'w' : 10, 'x' : 11, 'y' : 2 } 寻找两个字典的相同点，可以在两字典的 keys()或者 items() 方法返回结果上执行集合操作。例如： # Find keys in common a.keys() & b.keys() # Return { 'x', 'y' } # Find keys in a that are not in b a.keys() - b.keys() # Return { 'z' } # Find (key,value) pairs in common a.items() & b.items() # Return { ('y', 2) } ​ Python中的比较运算符重载： 操作符 表达式 内部 小于（ p1 p1 .__ lt __（p2） 小于等于（ p1 p1 .__ le __（p2） 等于（==） p1 == p2 p1 .__ eq __（p2） 不等于（!=） p1！= p2 p1 .__ ne __（p2） 大于（>） p1> p2 p1 .__ gt __（p2） 大于等于（>=） p1> = p2 p1 .__ ge __（p2） Cython 与 CPython CPython是用C语言实现的Python解释器，也是官方的并且是最广泛使用的Python解释器。 关于 Cython，我们必须要清楚两件事： 1）Cython 是一门编程语言，它将 C 和 C++ 的静态类型系统融合在了 Python 身上。Cython 源文件的后缀是 .pyx，它是 Python 的一个超集，语法是 Python 语法和 C 语法的混血。当然我们说它是 Python 的一个超集，因此你写纯 Python 代码也是可以的。 2）当我们编写完 Cython 代码时，需要先将 Cython 代码翻译成高效的 C 代码，然后再将 C 代码编译成 Python 的扩展模块。 Cython 是什么？为什么会有 Cython？_Python猫的博客-CSDN博客 GIL GIL并不是Python的特性，它是在实现Python解析器(CPython)时所引入的一个概念。 玩转python中的GIL前世今生与核心用法剖析 鸭子类型（duck typing） 在鸭子类型中，关注点在于对象的行为，能作什么；而不是关注对象所属的类型。 举个栗子： # 鸭子类 class Duck: def quack(self): print(\"这鸭子正在嘎嘎叫\") def feathers(self): print(\"这鸭子拥有白色和灰色的羽毛\") # 人类 class Person: def quack(self): print(\"这人正在模仿鸭子\") def feathers(self): print(\"这人在地上拿起1根羽毛然后给其他人看\") # 函数/接口 def in_the_forest(duck): duck.quack() duck.feathers() if __name__ == '__main__': donald = Duck() # 创建一个Duck类的实例 john = Person() # 创建一个Person类的实例 in_the_forest(donald) # 调用函数，传入Duck的实例 in_the_forest(john) # 调用函数，传入Person的实例 代码运行后输出： 这鸭子正在嘎嘎叫 这鸭子拥有白色和灰色的羽毛 这人正在模仿鸭子 这人在地上拿起1根羽毛然后给其他人看 《Go》 Go语言的特色： 没有继承多态的面向对象 强一致类型 interface不需要显式声明(Duck Typing) 没有异常处理(Error is value) 基于首字母的可访问特性 不用的import或者变量引起编译错误 完整而卓越的标准库包 Go内置runtime（作用是性能监控、垃圾回收等） 协程 协程（Coroutines）是一种比线程更加轻量级的存在。协程完全由程序所控制（在用户态执行），带来的好处是性能大幅度的提升。 一个操作系统中可以有多个进程；一个进程可以有多个线程；同理，一个线程可以有多个协程。 协程是一个特殊的函数，这个函数可以在某个地方挂起，并且可以重新在挂起处继续运行。 一个线程内的多个协程的运行是串行的，这点和多进程（多线程）在多核CPU上执行时是不同的。 多进程（多线程）在多核CPU上是可以并行的。当线程内的某一个协程运行时，其它协程必须挂起。 协程切换 由于协程切换是在线程内完成的，涉及到的资源比较少。不像内核级线程（进程）切换那样，上下文的内容比较多，切换代价较大。协程本身是非常轻巧的，可以简单理解为只是切换了寄存器和协程栈的内容。这样代价就非常小。 Go并发模型 Go实现了两种并发形式。第一种是大家普遍认知的：多线程共享内存。其实就是Java或者C++等语言中的多线程开发。另外一种是Go语言特有的，也是Go语言推荐的：CSP（communicating sequential processes）并发模型。 CSP讲究的是“以通信的方式来共享内存”。 Go的CSP并发模型，是通过goroutine和channel来实现的。 实现原理 Go goroutine理解 - 知乎 (zhihu.com) 为什么要使用 Go 语言？Go 语言的优势在哪里？ - 知乎 (zhihu.com) ​ 线程模型的实现，可以分为以下几种方式： 用户级线程模型（M：1） 内核级线程模型（1：1） 两级线程模型（M：N） M个用户线程对应N个系统线程，缺点增加了调度器的实现难度。 Go语言的线程模型就是一种特殊的两级线程模型（GPM调度模型）。 Go线程实现模型MPG M 指的是 Machine，一个M直接关联了一个内核线程。由操作系统管理。 P 指的是 processor，代表了M所需的上下文环境，也是处理用户级代码逻辑的处理器。它负责衔接M和G的调度上下文，将等待执行的G与M对接。 G 指的是 Goroutine，其实本质上也是一种轻量级的线程。包括了调用栈，重要的调度信息，例如channel等。 Goroutine优缺点 优点： 1、开销小 POSIX的thread API虽然能够提供丰富的API，例如配置自己的CPU亲和性，申请资源等等，线程在得到了很多与进程相同的控制权的同时，开销也非常的大，在Goroutine中则不需这些额外的开销，所以一个Golang的程序中可以支持10w级别的Goroutine。 每个 goroutine (协程) 默认占用内存远比 Java 、C 的线程少（goroutine：2KB ，线程：8MB） 2、调度性能好 在Golang的程序中，操作系统级别的线程调度，通常不会做出合适的调度决策。例如在GC时，内存必须要达到一个一致的状态。在Goroutine机制里，Golang可以控制Goroutine的调度，从而在一个合适的时间进行GC。 在应用层模拟的线程，它避免了上下文切换的额外耗费，兼顾了多线程的优点。简化了高并发程序的复杂度。 缺点： 协程调度机制无法实现公平调度。 JVM中的线程模型是用户级的吗 在JVM规范里是没有规定的——具体实现用1:1（内核线程）、N:1（用户态线程）、M:N（混合）模型的任何一种都完全OK。Java并不暴露出不同线程模型的区别，上层应用是感知不到差异的（只是性能特性会不太一样…） Java SE最常用的JVM是Oracle/Sun研发的HotSpot VM。在这个JVM的较新版本所支持的所有平台上，它都是使用1:1线程模型的——除了Solaris之外，它是个特例。 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Base/后端技术.html":{"url":"Note_Base/后端技术.html","title":"后端（服务器）","keywords":"","body":"《后端技术（服务器）》 框架 基础工具库 Apache commons Commons IO FileAlterationMonitor和FileAlterationObserver（Alyx 曾发现这里每隔 10 秒会涨 10M 内存，待研究） Commons Lang3 等 Google Guava Google Guava 是 Google 公司内部 Java 开发工具库的开源版本。Google 内部的很多 Java 项目都在使用它。它提供了一些 JDK 没有提供的功能，以及对 JDK 已有功能的增强功能。 主要包括了： 集合（Collections） 缓存（Caching） 原生类型支持（Primitives Support） 并发库（Concurrency Libraries） 通用注解（Common Annotation） 字符串处理（Strings Processing） 数学计算（Math） I/O 事件 总线（EventBus） 一些有用的小工具： BloomFilter布隆过滤器的实现 Ordering排序器 源码分析：https://ifeve.com/google-guava Json 关于 Gson 的几个坑 Spring Spring 最好能抽空看看源码，最起码 bean 的生命周期，如何解决循环依赖，父子容器，还有 boot 的启动流程，事务实现原理，动态代理原理等，你知道越多越好。 Spring 源码浅析 IOC 依赖注入，控制反转 Spring IOC 容器源码分析_Javadoop 循环依赖及三级缓存 Spring 循环依赖及三级缓存 弄清楚： 三级缓存是分别是什么，分别是什么时候起作用？ 为何需要三级缓存，二级缓存不行吗？ Spring 对 groovy 的生成的 bean 为何解决不了循环依赖？ 这里主要是： bean 生成的时机是 postProcessBeforeInstantiation，没有走到 doCreateBean，而 addSingletonFactory 是在 doCreateBean 调用的 protected void addSingletonFactory(String beanName, ObjectFactory singletonFactory) { Assert.notNull(singletonFactory, \"Singleton factory must not be null\"); synchronized (this.singletonObjects) { if (!this.singletonObjects.containsKey(beanName)) { this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); } } } bean 是由 ScriptFactoryPostProcessor#scriptBeanFactory 生成的，这个 scriptBeanFactory 是一个全新的，然后 copyConfigurationFrom 了一次 parent 的属性 @Configuration @Configuration注解的类为什么被CGLIB增强？ @Configuration这注解为什么可以不加？加了和不加的区别，底层为什么使用cglib - 简书 (jianshu.com) Spring AOP AOP 原理，ProxyFactory AOP 中 Pointcut，Advice 和 Advisor 三个概念 还有 Advised Advised 在 Spring 中创建了 AOP 代理之后，就能够使用 org.springframework.aop.framework.Advised 接口对它们进行管理。 任何 AOP 代理都能够被转型为这个接口，不论它实现了哪些其它接口 Advisor 类似使用 Aspect 的@Aspect 注解的类 Advice @Before、@After、@AfterReturning、@AfterThrowing、@Around Pointcut @Pointcut Spring tx 的解析过程 @Transactional 代理过程，用的什么代理，怎么代理 这里有一点需要注意的地方，由于 SpringAOP 的原因，@Transactional 注解只能用到 public 方法上，如果用到 private 方法上，将会被忽略，这也是面试经常问的考点之一。 组件整合 Spring Cache 介绍 Spring Webflux （reactive web 框架，与前端 Flux 架构名字相同） 命令式编程 VS 响应式编程 Spring Data Spring Data JPA 简单查询--接口方法 - 如莲家园 - 博客园 JPA的查询语言—使用原生SQL_ChenAllen1025的专栏-CSDN博客 与其他构架的整合 企业大型互联网分布式架构 {Java 分布式架构 dubbo+springmvc+mybatis+ehcach+redis }-IT 未来-ITPUB 博客 手把手教你从最基本的 Java 工程搭建 SpringMVC+SpringDataJPA+Hibernate(含源码下载) - anxpp 的博客 - CSDN 博客 SpringBoot SpringBoot 自动配置机制 SpringBoot 启动过程 SpringBootStarter 依赖 简易教程 Spring Boot教程™ (yiibai.com) SpringCloud 核心子项目： Spring Cloud Netflix：核心组件，可以对多个 Netflix OSS 开源套件进行整合，包括以下几个组件： Eureka：服务治理组件，包含服务注册与发现 Hystrix：容错管理组件，实现了熔断器 Ribbon：客户端负载均衡的服务调用组件 Feign：基于 Ribbon 和 Hystrix 的声明式服务调用组件 Zuul：网关组件，提供智能路由、访问过滤等功能 Archaius：外部化配置组件 Spring Cloud Config：配置管理工具，实现应用配置的外部化存储，支持客户端配置信息刷新、加密/解密配置内容等。 Spring Cloud Bus：事件、消息总线，用于传播集群中的状态变化或事件，以及触发后续的处理 Spring Cloud Security：基于 spring security 的安全工具包，为我们的应用程序添加安全控制 Spring Cloud Consul：封装了 Consul 操作，Consul 是一个服务发现与配置工具（与 Eureka 作用类似），与 Docker 容器可以无缝集成 简易教程： Spring Cloud 微服务架构学习笔记与示例 - EdisonZhou - 博客园 (cnblogs.com) ASM 神器 spring-core 自带有 asm，org.ow2.asm 也是一个轻量级的 jar 还有 byte buddy 库，javassist 库 JAX-RS 全称：Java API for RESTful Web Services，是一套用 java 实现 REST 服务的规范，提供了一些标注将一个资源类，一个 POJOJava 类，封装为 Web 资源。 包括： @Path，标注资源类或方法的相对路径 @GET，@PUT，@POST，@DELETE，标注方法是用的 HTTP 请求的类型 @Produces，标注返回的 MIME 媒体类型 @Consumes，标注可接受请求的MIME 媒体类型 @PathParam，@QueryParam，@HeaderParam，@CookieParam，@MatrixParam，@FormParam，分别标注方法的参数来自于 HTTP 请求的不同位置，例如@PathParam 来自于 URL 的路径，@QueryParam 来自于 URL 的查询参数，@HeaderParam 来自于 HTTP 请求的头信息，@CookieParam 来自于 HTTP 请求的 Cookie Eureka的ApplicationResource有用到 缓存 Guava 的缓存 Guava Cache 说简单点就是一个支持LRU的 ConcurrentHashMap 简析 guava cache 线程安全设计哲学 - 简书 (jianshu.com) Caffeine 来自未来的缓存 Caffeine 是基于 JAVA 1.8 Version 的高性能缓存库。Caffeine 提供的内存缓存使用参考 Google guava 的 API。Caffeine 是基于 Google Guava Cache 设计经验上改进的成果。 日志 区分commons-logging，slf4j，log4j，logback Java日志，需要知道的几件事(commons-logging,log4j,slf4j,logback)_kobejayandy的专栏-CSDN博客 了解jcl-over-slf4j，jul-to-slf4j这些 jar 的作用 了解log4j和log4j2的区别，lmax disruptor应用场景 log4j log4j是如何拖慢你的系统的_veZunShao的专栏-CSDN博客 Flume 日志采集系统，一般用于日志聚合 ORM 库 hibernate 查询：HQL 查询，QBC 查询，SQL 查询 级联查询：一对一，一对多（多对一），多对多；懒加载，1+n 问题 其他： session.get(): 非懒加载方法 session.load(): 默认就是是懒加载 抓取策略（fetch）和 懒加载（lazy） mybatis mybatis 3.x源码深度解析与最佳实践（最完整原创） - zhjh256 - 博客园 (cnblogs.com) Netty 概述 Netty 的线程模型 通过Reactor 模型基于多路复用器接收并处理用户请求，内部实现了两个线程池，boss 线程池和 work 线程池，其中 boss 线程池的线程负责处理请求的 accept 事件，当接收到 accept 事件的请求时，把对应的 socket 封装到一个 NioSocketChannel 中，并交给 work 线程池，其中 work 线程池负责请求的 read 和 write 事件 NioEventLoop 设计原理 定时任务的原理 netty 对象池使用与回收 时间轮算法 HashedWheelTimer hashWheel 定时器和 Quartz 的区别：1）Quartz 将定时任务分为任务和触发器，而 hashWheel 只有任务的概念 2）Quartz 通过一个 TreeSet 对所有的触发器进行管理，而 hashWheel 通过一个 hash 轮来对所有的任务进行管理 3）Quartz 能够非常方便的删除定时任务，而 netty 的 hashWheel 暂时没有删除任务的接口（除非自己实现一个 hashWheel 定时器） 4）Quartz 有一个专门的调度线程对任务进行管理，任务执行有另外专门的线程池，而 hashWheel 用一个线程实现对任务的管理和任务的执行。 5）Quartz 能够通过序列化，将定时任务保存在数据库，而 hashWheel 不能 总的来说，Quartz 的功能相对强大，而 hashWheel 相对要轻量级一点。 附： 个人认为 netty 对用户来说是异步，但是实际底层 IO 是 IO 多路复用模型，本质上还是一种同步非阻塞（是的，个人认为 IO 多路复用模型还是同步非阻塞，并且真正的 IO 操作都将阻塞应用线程），他只是多了一个 Selector（需要底层操作系统支持），如此一个线程就可以控制大量的通信（相比传统 IO，不管他是不是非阻塞）。 另看 IO#IO 概念，这里也收录了一些理解 面试 阿里大牛总结的Netty最全常见面试题，面试再也不怕被问Netty了 - 知乎 (zhihu.com) Disruptor Disruptor 是一个无锁、有界的队列框架，它的性能非常高。 背景 锁的缺点 - Disruptor 入门 并发中的伪共享问题 代码的并发执行大约是两件事：互斥和变化的可见性。 互斥是关于管理某些资源的竞争更新。 变化的可见性是关于控制何时使这些更改对其他线程可见。 设计上的优势 内部数据存储使用环形缓冲（Ring Buffer），这样分配支持了CPU 缓存位置预测，GC 的压力更小 尽量使用无锁设计，合理使用 CAS 优化数据结构（填充缓存行），解决伪共享问题 合理位运算（如 2 次方幂求模），合理使用 Unsafe 策略 WaitStrategy可以选择YieldingWaitStrategy（无锁） 参考博客 解读 Disruptor 系列，这个系列挺好的，他每篇文章后面都有份参考资料，也可以认真看看 扩展 AtomicXXX.lazySet 这个方法的作用（Sequence#set 相当于 AtomicLong#lazySet） Unsafe 类的作用？为什么要用这个类？除了 JDK，在 Netty、Spring、Kafka、Storm 等非常多的流行开源项目中都使用了 Unsafe 原子类型集合库 避免开销很大的装箱/拆箱操作，节省了原始类型装箱消耗的内存 Koloboke 生成高性能的 JAVA 基本类型 map/set Eclipse Collections Fastutil 时间库 joda 对时间的操作 Quartz 定时任务 RxJava ➮详细 \" a library for composing asynchronous and event-based programs using observable sequences for the Java VM \" （一个在 Java VM 上使用可观测的序列来组成异步的、基于事件的程序的库） 工具 构建工具 Maven Gradle 十分钟理解 Gradle - Bonker - 博客园 慕课实战：Gradle3.0 自动化项目构建技术精讲+实战 Gradle Distributions 版本管理工具 Git 持续集成部署 Jenkins 单元测试 玩转单元测试之 DBUnit - WadeXu - 博客园 逆向工程 Java 代码生成利器之 rapid-generate 应用 Web容器 tomcat 中间件 Zookeeper 场景 ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。 使用分布式系统就无法避免对节点管理的问题（需要实时感知节点的状态、对节点进行统一管理等等），而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper 作为一个能够通用解决这些问题的中间件就应运而生了。 原理 Zookeeper 的功能以及工作原理 Leader 选举-选举过程介绍比较清晰 ZAB 协议理解 Dubbo Dubbo是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。 消息队列 主要使用场景： 异步、削峰、解耦 带来问题： 系统复杂性 消息重复消费、消息丢失、消息的顺序消费等等 数据一致性 其他服务失败导致数据不一致？需要分布式事务？ 可用性 MQ挂了咋办？ 主流： Kafka 和 RocketMQ Kafka 场景 想要保证消息（数据）是有序的，怎么做？ Kafka会将数据写到 partition，单个 partition 的写入是有顺序的。如果要保证全局有序，那只能写入一个 partition 中。如果要消费也有序，消费者也只能有一个。 Kafka 性能优化： 零拷贝网络和磁盘 优秀的网络模型，基于 Java NIO 高效的文件数据结构设计 Parition 并行和可扩展 数据批量传输 数据压缩 顺序读写磁盘 无锁轻量级 offset 参考 Kafka性能篇：为何Kafka这么\"快\"？ RocketMQ TODO RabbitMQ 了解其 Exchange (交换器)，常用的有四种：direct、topic、fanout、headers MySQL sharding-jdbc 支持数据分片，分布式事务，数据库治理 连接池 目的：解决建立数据库连接耗费资源和时间很多的问题，提高性能。 自定义数据库连接池要实现 javax.sql.DataSource 接口，一般都叫数据源。 常用的数据源： DBCP：Apache推出的Database Connection Pool C3P0：开源的 JDBC 连接池 其他 apache DBUtils DBUtils简化了JDBC的开发步骤，使得我们可以用更少量的代码实现连接数据库的功能。 TDDL、cobar 等 搜索引擎 Elasticsearch Elasticsearch 基础教程 - CSDN 博客 倒排索引 和 传统关系型数据库 的对比 Relational DB Databases Tables Rows Columns 关系型数据库 数据库 表 行 列 Elasticsearch Indices Types Documents Fields 搜索引擎 索引 类型 文档 域（字段） 使用 Spring Data ElasticSearch_liuxigiant的专栏-CSDN博客 基于注解的配置 - Spring-Data-Elasticsearch Logstash Logstash：收集、解析和转换日志 | Elastic Kibana ELK：ELK 技术栈（ElasticSearch, Logstash, Kibana）搭建实时日志分析平台，将日志保存到 Elasticsearch 中，通过 Logstash 进行分析，并使用 Kibana 来展示和查询。 Lucene、Solr TODO SOFAStack 项目 · SOFAStack，是一套用于快速构建金融级云原生架构的中间件，也是在金融场景里锤炼出来的最佳实践。 SOFAJRaft SOFAJRaft 是一个基于 RAFT 一致性算法的生产级高性能 Java 实现，支持 MULTI-RAFT-GROUP，适用于高负载低延迟的场景。 分布式 理论基石 CAP 原理： C - Consistent ，一致性 A - Availability ，可用性 P - Partition tolerance ，分区容忍性 分布式系统中网络分区不可避免，一致性和可用性水火不容。 Redis的一致性与可用性： Redis的主从数据是异步同步的，分布式的Redis并不满足一致性要求。 即使在主从网络断开的情况下，主节点依旧可以正常对外提供服务，满足可用性。 但Redis保证最终一致性，从节点会采用多种策略追赶，尽力保持和主节点一致。 主要算法 一致性 Hash redis 分片 分布式集群中，生成全局唯一的ID UUID String uuid = UUID.randomUUID().toString() 虽然可以保证全局唯一，但占用32位太长，而且无序，入库时性能比较差。 为什么无序的UUID会导致入库性能变差呢？ 这就涉及到 B+树索引的分裂：关系型数据库的索引大都是B+树的结构，拿ID字段来举例，索引树的每一个节点都存储着若干个ID。如果我们的ID按递增的顺序来插入，比如陆续插入8，9，10，新的ID都只会插入到最后一个节点当中。当最后一个节点满了，会裂变出新的节点。这样的插入是性能比较高的插入，因为这样节点的分裂次数最少，而且充分利用了每一个节点的空间。但是，如果我们的插入完全无序，不但会导致一些中间节点产生分裂，也会白白创造出很多不饱和的节点，这样大大降低了数据库插入的性能。 数据库自增主键 为了提高性能，在分布式系统中可以用DB proxy请求不同的分库，每个分库设置不同的初始值，步长和分库数量相等 这样一来，DB1生成的ID是1,4,7,10,13....，DB2生成的ID是2,5,8,11,14..... 但这样也不是很好。ID的生成对数据库严重依赖，影响性能，一旦数据库挂掉，服务将变得不可用。 SnowFlake 漫画：什么是SnowFlake算法？ 网络通信 RPC RPC 涉及：通讯，序列化，超时，重发（重复），消息顺序，负载 等等。（个人理解） 协议：thrift、gRPC 等等 JavaRMI 深究 Java 中的 RMI 底层原理 HSF 阿里巴巴集团内部使用的分布式服务框架 High Speed Framework Dubbo 一致性 分布式锁 分布式锁一般有三种实现方式： 数据库乐观锁； 基于 Redis 的分布式锁；（看数据库/Redis篇） 基于 ZooKeeper 的分布式锁 分布式事务 和分布式锁的区别 要捋清一些概念： 分布式事务指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。 简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。 本质上来说，分布式事务就是为了保证不同数据库的数据一致性。 共识算法 Paxos、Raft、Zab： 分布式事务与一致性算法 Paxos & raft & zab 分布式事务一致性的常见解决方案 2PC，3PC XA 消息中间件最终一致性 参考： 分布式一致性算法2PC和3PC_fcj的技术博客_51CTO博客 Java 分布式事务规范 JTA / XA JTA 是 Java 的事务管理器规范 XA 是工业标准的 X/Open CAE 规范，可被两阶段提交及回滚的事务资源定义 参考： atomikos:4.0 atomikos JTA/XA 全局事务 xaresource 分布式事务 分布式事务系列（2.1）分布式事务的概念 分布式 session 一致性 session 复制，对 web 服务器 (例如 Tomcat) 进行搭建集群 session 绑定，使用 nginx ip-hash 策略，无论客户端发送多少次请求都被同一个服务器处理 基于 redis 存储，spring 为我们封装好了 spring-session，直接引入依赖即可 高可用 缓存、降级、限流 服务器端如何处理超大量合法请求？ 服务器架构层面，做负载均衡，将请求分发给其它服务器处理。 软件服务架构层面，做请求队列，将 1w 个请求放入队列，业务处理完的请求再返回。 代码层面，优化业务处理，把单机请求做到支持 1w 并发。 容量设计 互联网架构，如何进行容量设计？_w3cschool 架构演进 从All in one 到微服务 架构师之路_w3cschool 文件系统 FastDFS FastDFS 是一个开源的高性能分布式文件系统（DFS）。 它的主要功能包括：文件存储，文件同步和文件访问，以及高容量和负载平衡。主要解决了海量数据存储问题，特别适合以中小文件（建议范围：4KB 用FastDFS一步步搭建文件管理系统 - bojiangzhou - 博客园 (cnblogs.com) happyfish100/fastdfs-client-java: FastDFS java client SDK (github.com) 大文件传输 大文件上传技术： 在Java中，处理大文件上传的一种常见的方式是使用分片上传。分片上传将大文件切割成一系列的小文件块，然后分别上传这些块。在上传完成后，服务器端会将这些块重新合并成原始文件。 大文件下载技术： 可以使用Java的 RandomAccessFile 类来实现断点续传和并发下载。 将文件分成几块，每块用不同的线程进行下载。 另一种是使用 MappedByteBuffer，MappedByteBuffer是Java提供的基于操作系统虚拟内存映射（MMAP）技术的文件读写API，底层不再通过read、write、seek等系统调用实现文件的读写。 大文件上传时如何做到秒传？ | 二哥的Java进阶之路 (javabetter.cn) Java文件的简单读写、随机读写、NIO读写与使用MappedByteBuffer读写-腾讯云开发者社区-腾讯云 (tencent.com) 防止文件被篡改 信息摘要算法，md5和sha256等 前沿技术 网络协议 RSocket RSocket是一种二进制的点对点通信协议，是一种新的网络通信第七层协议。旨在用于分布式应用程序中。从这个意义上讲，RSocket是HTTP等其他协议的替代方案。它是一种基于Reactive Streams规范具有异步，背压的双向，多路复用，断线重连，基于消息等特性。它由Facebook，Netifi和Pivotal等工程师开发，提供Java，JavaScript，C ++和Kotlin等实现。 入门使用： RSocket协议初识-Java中使用（二）_后厂村老司机的博客-CSDN博客 容器化 Docker 大家需要注意，Docker本身并不是容器，它是创建容器的工具，是应用容器引擎。 想要搞懂Docker，其实看它的两句口号就行。 第一句，是“Build, Ship and Run”。也就是，“搭建、发送、运行”，三板斧。 第二句口号就是：“Build once，Run anywhere（搭建一次，到处能用）”。 K8S 就在Docker容器技术被炒得热火朝天之时，大家发现，如果想要将Docker应用于具体的业务实现，是存在困难的——编排、管理和调度等各个方面，都不容易。于是，人们迫切需要一套管理系统，对Docker及容器进行更高级更灵活的管理。 就在这个时候，K8S出现了。 K8S，就是基于容器的集群管理平台，它的全称，是kubernetes。 ServiceMesh ServiceMesh，也叫服务网格，是一种概念。 一言以蔽之：Service Mesh 是微服务时代的 TCP/IP 协议。 中台 构建中台的目的 中台的目的是构建企业级统一的服务接口，不只是数据，包括技术、业务、组织架构等，其实质是整合企业内的软硬件资源，包括人力资源。传统单体系统，一个系统一套软硬件开发和运维人员，这些系统所采用的厂商、技术、开发语言、技术架构、数据库等可能各不相同。随着信息化系统越来越多，系统间面临着数据共享的要求。所以系统集成技术就应运而生。 什么是中台？为什么需要中台？ - 知乎 (zhihu.com) 思想 Reative 编程 Reactive 响应式 (反应式) 编程 是一种新的编程风格，其特点是异步或并发、事件驱动、推送 PUSH 机制以及观察者模式的衍生。 JVM 应用：RxJava、Akka、Actors 模型、Vert.x、Webflux 领域驱动设计 他是综合软件系统分析和设计的面向对象建模方法，如今已经发展为一种针对大型复杂系统的领域建模与分析方法。 将要解决的业务概念和业务规则转换为软件系统中的类型及类型的属性与行为，通过合理运用面向对象的封装、继承、多态等设计要素，降低或隐藏整个系统的业务复杂性，并使得系统具有更好的扩展性，应对纷繁多变的现实业务问题。 ——抄录于《高可用可伸缩微服务架构：基于 Dubbo、Spring Cloud 和 Service Mesh》2.1 节 领域驱动设计在互联网业务开发中的实践 美团 DDD 实践 示例项目 代码评审 基本（规范，模块化，逻辑） 安全（表单校验，防攻击SQL注入，线程安全） 数据库（事务，sql优化） 性能 性能优化 CPU 伪共享问题 问题：二维数组按行和按列遍历效率（Java章节中有说明） 应用：netty 中的 FastThreadLocal 中 InternalThreadLocalMap（Java章节中有说明）；lmax disruptor 等 对象池 安全 鉴权 鉴权接口 Java 反序列化 java反序列化漏洞的一些gadget log4j CVE-2019-17571：log4j CVE-2021-44228： (环境搭建+复现) CVE-2021-44228 Apache Log4j 远程代码执行漏洞 安全漏洞之Log4j2漏洞复现绕过分析 dubbo 反序列化漏洞攻击原理(Dubbo反序列化漏洞剖析) Gadgetinspector 一款针对Java应用程序/库的字节码分析工具，它可以帮助研究人员寻找和分析Java应用程序中的反序列化小工具链（Gadget Chain） https://github.com/JackOfMostTrades/gadgetinspector Java 反序列化工具 gadgetinspector 初窥 源码学习 这些框架的源码都值得一看： spring dubbo zookeeper tomcat 书单 Spring 《Spring 源码深度解析 第二版》《Spring 实战》 《Spring Boot 编程思想（核心篇）》 《Spring Boot 实战》 《Spring 微服务实战》 MySQL 《高性能 MySQL》 Netty 《Netty 权威指南》 Tomcat 《Tomcat 架构解析 （刘光瑞）》 其他 《架构探险分布式服务框架 （李业兵）》 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Base/前端技术.html":{"url":"Note_Base/前端技术.html","title":"前端（Web）","keywords":"","body":"《前端技术（Web）》 HTML/CSS/JS HTML/CSS Flex 布局教程：语法篇 - 阮一峰的网络日志 (ruanyifeng.com) JavaScript ECMAScript 阿里巴巴的这道题为什么选A？为什么new main()输出的都是undefined？ - SegmentFault 思否 前端框架 Bootstrap 教程 - 菜鸟教程 Moment.js 中文网 (momentjs.cn) Vue 双向数据绑定与单向数据绑定 Vuex，Weex vue 常用组件库_zhouzhiwengang的专栏-CSDN博客_vue组件库 React React 入门实例教程 Flux 架构 Flux 架构入门教程 状态管理 聊一聊主流前端框架的状态管理 前端状态管理请三思 其他 给 2019 前端的 5 个建议 浏览器原理系列 10 篇正式完结 Weex 前言 移动端跨平台 UI 框架 Weex基础 Weex-初次见到你-阿里云开发者社区 (aliyun.com) weex社区 - 专题 - 简书 (jianshu.com) 没有死！阿里公开Weex技术架构，还开源了一大波组件_我只是一个小小的搬运工的博客-CSDN博客 （总结）Weex若干特性总结分析 - 大球和二憨 - 博客园 (cnblogs.com) Weex Android SDK源码分析之Module（modal）_王永迪的专栏-CSDN博客 Weex Android交互篇_hzh839900的专栏-CSDN博客 Weex Ui Weex Ui (apache.github.io) Eros bmfe/eros: 📱 一套 Vue 代码，两端原生应用 ，或许可以叫我 weex-native。 (github.com) EROS (bmfe.github.io) Nat natjs/nat: A powerful kit for adding native functionalities to your weex app. (github.com) EMAS组件 待补充 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Base/操作系统.html":{"url":"Note_Base/操作系统.html","title":"操作系统","keywords":"","body":"《操作系统》 Linux 文件 Linux中“一切皆文件”是什么意思？ 说一下个人理解。 一切皆文件是某些操作系统对资源的抽象，把资源都抽象成“文件”这么一个对象，然后就可以对这个对象做同一种操作。统一了对它们的操作方法，使得Linux具有了很高的灵活性和可扩展性。 比如对于普通文本文件来讲，可以通过 open/read/write/close 来打开/读取/写入/关闭。 比如对于 Socket 对象来讲，也可以通过 open/read/write/close 来打开/读取/写入/关闭。 比如，ls 是显示目录或者文件基本信息的，但是把进程信息抽象成文件之后，我们就可以使用 ls /proc/xxx 查看进程信息了，把 cpu 的信息抽象成文件用 cat /proc/cpuinfo 就可以查看 cpu 信息了，当然这个只能读不能改变。 再比如对于一些硬件设备比如蓝牙，摄像头等，都能通过 open/read/write/close 来打开/读取/写入/关闭。 也就是说像 Linux 这种奉行“一切皆文件”思想的操作系统，可以对所有资源都使用同一套 api 接口。 ​ 下面的视频内容就讲到“蓝牙手柄就是个文件”，通过 /dev/input/event20 就可以获取手柄的输入： Linux中“一切皆文件”是什么意思？ - 知乎 (zhihu.com) ​ 优点： 统一的文件操作接口 方便的文本处理和系统管理 方便的设备管理 安全性 为什么说：Linux中一切皆文件？-腾讯云开发者社区-腾讯云 (tencent.com) ​ 缺点： 和 Windows 系统不同，Linux 系统没有盘。不利之处在于，使用任何硬件设备都必须与根目录下某一目录执行挂载操作，否则无法使用。 硬链接和软链接 硬链接创建的是文件内容的多个名称，而软链接创建的是指向另一个文件的路径。 使用 ln 命令可以方便地创建硬链接和软链接。对于硬链接，不需要任何特殊选项；而对于软链接，则需要加上 -s 选项。 进程管理 进程和线程 进程间通信 管道，消息队列，共享内存 死锁 进程调度算法 什么时候会发生 CPU 调度 当进程从运行状态转到等待状态； 当进程从运行状态转到就绪状态； 当进程从等待状态转到就绪状态； 当进程从运行状态转到终止状态； 其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。 非抢占式 当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。 抢占式调度 顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。 ​ 常见的调度算法 先来先服务调度算法 最短作业优先调度算法 高响应比优先调度算法 时间片轮转调度算法 最高优先级调度算法 多级反馈队列调度算法 Linux系统采用了完全公平调度算法（CFS）作为默认的进程调度算法。CFS的设计目标是为了确保系统中所有运行的进程都获得公平的CPU时间份额。它使用红黑树（一种自平衡二叉查找树）来维护所有可运行进程的排序，确保调度的公平性。CFS不关注进程的实时性，更注重任务的整体平均运行时间，意图让每个进程都能得到合理的CPU时间比例。 内存管理 一文带你了解，虚拟内存、内存分页、分段、段页式内存管理 - 知乎 (zhihu.com) 操作系统就用一张大表管理内存？ (qq.com) 内存分段 程序是由若干个逻辑分段组成的，可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。 分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处： 第一个就是内存碎片的问题。 第二个就是内存交换的效率低的问题。 内存碎片的问题 这里的内存碎片的问题共有两处地方： 外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载； 内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费； 解决外部内存碎片的问题就是内存交换。 可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的时间 256MB 空间，于是新的 200MB 程序就可以装载进来。 这个内存交换空间，在 Linux 系统里，也就是我们经常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换 内存分页 让需要交换的写入或者从磁盘装载的数据更少一点，能少出现一些内存碎片。这个办法，也就是内存分页（Paging）。 ​ 页、块、页表 将虚拟地址空间以512Byte ~ 8K，作为一个单位，称为页，并从0开始依次对每一个页编号。在 Linux 下，每一页的大小为 4KB。 将物理地址按照同样的大小，作为一个单位，称为框或者块，也从0开始依次对每一个框编号。 操作系统通过维护一张表，这张表上记录了每一对页和框的映射关系，这张表，称为页表。 页表实际上存储在 CPU 的内存管理单元 （MMU） 中，于是 CPU 就可以直接通过 MMU，找出要实际要访问的物理内存地址。 ​ 访问 当CPU要访问一个虚拟地址空间对应的物理内存地址时，先将具体的虚拟地址A/页面大小4K，结果的商作为页表号，结果的余作为业内地址偏移。 ​ 内存页面置换算法 缺页中断 当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存 页面置换算法 最佳页面置换算法（OPT） 先进先出置换算法（FIFO） 最近最久未使用的置换算法（LRU） 时钟页面置换算法（Lock） 最不常用置换算法（LFU） Linux内核现在使用的页面置换算法是两级的软件LRU，也就是分为active和inactive类型的两个链表，并实现软件LRU（NFU）算法 让我们一起聊聊如何改进 LRU 算法-改进leach算法 (51cto.com) 其他 Out of memory: Kill process Linux有一个特性：OOM Killer，一个保护机制，用于避免在内存不足的时候不至于出现严重问题，把一些无关的进程优先杀掉，即在内存严重不足时，系统为了继续运转，内核会挑选一个进程，将其杀掉，以释放内存，缓解内存不足情况，不过这种保护是有限的，不能完全的保护进程的运行。 [689379.844719] Out of memory: Kill process 421 (java) score 1949 or sacrifice child [689379.846596] Killed process 421 (java) total-vm:513937072kB, anon-rss:1299716kB, file-rss:30739736kB dmesg dmesg命令显示linux内核的环形缓冲区信息，我们可以从中获得诸如系统架构、cpu、挂载的硬件，RAM等多个运行级别的大量的系统信息。 如上面的Out of memory: Kill process就是这里发现的 sawp 开启/禁用：swapon和swapoff 虚拟内存和 swap 分区 磁盘 磁盘寻道算法 先来先服务算法 最短寻道时间优先算法 扫描算法 循环扫描算法 LOOK 与 C-LOOK 算法 磁盘预读 预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。 设备 设备管理 内核态与用户态 操作系统根据资源访问权限的不同，体系架构可分为用户空间和内核空间；内核空间主要操作访问CPU资源、I/O资源、内存资源等硬件资源，为上层应用程序提供最基本的基础资源，用户空间呢就是上层应用程序的固定活动空间，用户空间不可以直接访问资源，必须通过“系统调用”、“库函数”或“Shell脚本”来调用内核空间提供的资源。 操作硬盘等资源属于敏感操作，为了内核安全，用户线程不能直接调用。而是采用了操作系统内核提供了系统调用接口，用户线程通过系统调用来实现文件读写。所以直接与硬盘打交道的是操作系统内核。 操作系统将内存按1：3的比例分为了内核空间和用户空间，用户态的运行栈信息保存在用户空间中，内核态的运行栈信息保存在内核空间中。运行栈中保存了当前线程的运行信息，比如执行到了哪些方法，局部变量等。 当发生用户态和内核态之间的切换的时候，运行栈的信息发生了变化，对应的CPU中的寄存器信息也要发生变换。但是用户线程完成系统调用的时候，还是要切换回用户态，继续执行代码的。所以要将发生系统调用之前的用户栈的信息保存起来，也就是将寄存器中的数据保存到线程所属的某块内存区域。这就涉及到了数据的拷贝，同时用户态切换到内核态还需要安全验证等操作。所以用户态和内核态之间的切换是十分耗费资源的。 系统监控 sysstat性能监控工具 sysstat提供了Linux性能监控工具集，包括sar、sadf、mpstat、iostat、pidstat、vmstat等，用于监控Linux系统性能和使用情况。 系统负载 定位性能问题常用方法：系统负载，CPU与进程_懒惰的劳模的博客-CSDN博客 《Linux小白入门之性能优化》 - 知乎 (zhihu.com) 该系列的替代版：Linux性能优化.md (lianglianglee.com) 计算密集型与IO密集型 计算密集型与IO密集型这个概念，在面试的时候可能会被问到，主要是在多线程环境中，如何设置线程数，让CPU充分利用，跑出最高效率。 计算密集型：这一类主要是在线程中，按照数学公式，大量求和、求平均、求平方等等操作，这样的任务，大部分需要依赖CPU的计算能力来处理，我们设置线程数一般是：计算机核数n+1。 IO密集型：这一类任务，大部分操作耗时在网络传输、磁盘读写上面，而CPU并未跑满，这类应用比如web服务器，不管是同步阻塞，还是异步非阻塞，他对CPU的利用非常低，耗时操作在IO。为了合理利用CPU，设置线程数一般是：计算机核数n*2。 在设置线程数上，一个是n+1，一个是2n。 Command nohup nohup 命令运行由 Command参数和任何相关的 Arg参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 & （ 表示“and”的符号）到命令的尾部。 nohup 是 no hang up 的缩写，就是不挂断的意思。 案例： nohup command > myout.file 2>&1 & 在上面的例子中，0 – stdin (standard input)，1 – stdout (standard output)，2 – stderr (standard error) ； 2>&1是将标准错误（2）重定向到标准输出（&1），标准输出（&1）再被重定向输入到myout.file文件中。 0 22 * * * /usr/bin/python /home/pu/download_pdf/download_dfcf_pdf_to_oss.py > /home/pu/download_pdf/download_dfcf_pdf_to_oss.log 2>&1 这是放在crontab中的定时任务，晚上22点时候怕这个任务，启动这个python的脚本，并把日志写在download_dfcf_pdf_to_oss.log文件中 nohup和&的区别 & ： 指在后台运行 nohup ： 不挂断的运行，注意并没有后台运行的功能，就是指，用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系，例如我们断开SSH连接都不会影响他的运行，注意了nohup没有后台运行的意思；&才是后台运行 多路复用 具体来说，多路复用可以实现以下几个方面的功能： 单个进程或线程能够同时处理多个 I/O 操作，而不必为每个 I/O 操作创建一个新的线程，从而节省系统资源。 通过多路复用，可以实现非阻塞 I/O，即当没有数据到达时，进程不会被阻塞，而是可以继续处理其他事务。 在实际编程中，常见的多路复用机制包括 select、poll、epoll（在 Linux 中）。这些机制允许程序监视多个文件描述符，并在一个或多个文件描述符准备好进行 I/O 操作时得到通知，从而实现高效的 I/O 处理。 同步阻塞概念 同步、异步： 概念：消息的通知机制 解释：涉及到 IO 通知机制；所谓同步，就是发起调用后，被调用者处理消息，必须等处理完才直接返回结果，没处理完之前是不返回的，调用者主动等待结果；所谓异步，就是发起调用后，被调用者直接返回，但是并没有返回结果，等处理完消息后，通过状态、通知或者回调函数来通知调用者，调用者被动接收结果。 阻塞、非阻塞： 概念：程序等待调用结果时的状态 解释：涉及到 CPU 线程调度；所谓阻塞，就是调用结果返回之前，该执行线程会被挂起，不释放 CPU 执行权，线程不能做其它事情，只能等待，只有等到调用结果返回了，才能接着往下执行；所谓非阻塞，就是在没有获取调用结果时，不是一直等待，线程可以往下执行，如果是同步的，通过轮询的方式检查有没有调用结果返回，如果是异步的，会通知回调。 I/O 模型 阻塞式 I/O 非阻塞式 I/O I/O 复用 信号驱动 I/O 异步 I/O 五大 I/O 模型比较 参考链接： IO 复用,AIO,BIO,NIO,同步，异步，阻塞和非阻塞 区别 网络 IO 中的同步、异步、阻塞和非阻塞 迄今为止把同步/异步/阻塞/非阻塞/BIO/NIO/AIO 讲的最清楚的好文章 《Netty Zookeeper Redis 高并发实战》2.2 节 9.3 高性能网络模式：Reactor 和 Proactor | 小林coding (xiaolincoding.com) Socket 在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列： 一个是「还没完全建立」连接的队列，称为 TCP 半连接队列，这个队列都是没有完成三次握手的连接，此时服务端处于 syn_rcvd 的状态； 一个是「已经建立」连接的队列，称为 TCP 全连接队列，这个队列都是完成了三次握手的连接，此时服务端处于 established 状态； 当 TCP 全连接队列不为空后，服务端的 accept() 函数，就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket。 注意，监听的 Socket 和真正用来传数据的 Socket 是两个： 一个叫作监听 Socket； 一个叫作已连接 Socket； select/poll/epoll 9.2 I/O 多路复用：select/poll/epoll | 小林coding (xiaolincoding.com) epoll 使用示例 - 知乎 (zhihu.com) linux内核Epoll 实现原理 - jame_xhs's blog (jxhs.me) ​ select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。 所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。 poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。 但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。 Select的缺陷 每次调用select，都需要把fd集合从用户态拷贝到内核态，fd越多开销则越大； 每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 select支持的文件描述符数量有限，默认是1024。参见/usr/include/linux/posix_types.h中的定义： # define __FD_SETSIZE 1024 ​ epoll 通过两个方面，很好解决了 select/poll 的问题。 第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。而 select/poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。 第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。 ​ epoll的工作机制更为复杂，我们就解释一下，它是如何解决Select机制的三大缺陷的。 对于第一个缺点，epoll的解决方案是：它的fd是共享在用户态和内核态之间的，所以可以不必进行从用户态到内核态的一个拷贝，大大节约系统资源。至于如何做到用户态和内核态，大家可以查一下“mmap”，它是一种内存映射的方法。 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把当前线程轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把当前线程挂一遍（这一遍必不可少），并为每个fd指定一个回调函数。当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表。那么当我们调用epoll_wait时，epoll_wait只需要检查链表中是否有存在就绪的fd即可，效率非常可观。 对于第三个缺点，fd数量的限制，也只有Select存在，Poll和Epoll都不存在。由于Epoll机制中只关心就绪的fd，它相较于Poll需要关心所有fd，在连接较多的场景下，效率更高。在1GB内存的机器上大约是10万左右，一般来说这个数目和系统内存关系很大。 epoll 边缘触发和水平触发 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完； 使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取； Reactor 模式 Netty的架构模式是在此基础上演变而来的 个人认为 netty 对用户来说是异步，但是实际底层 IO 是 IO 多路复用模型，本质上还是一种同步非阻塞（是的，个人认为 IO 多路复用模型还是同步非阻塞，并且真正的 IO 操作都将阻塞应用线程），他只是多了一个 Selector（需要底层操作系统支持），如此一个线程就可以控制大量的通信（相比传统 IO，不管他是不是非阻塞）。 真正的 IO 操作都将阻塞应用线程 因为在 read 调用时，内核将数据从内核空间拷贝到用户空间的过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。 IO 操作的真正耗时 我们开始以为 write 操作是要等到对方收到消息才会返回，但实际上不是这样的。write 操作只负责将数据写到本地操作系统内核的发送缓冲然后就返回了。剩下的事交给操作系统内核异步将数据送到目标机器。但是如果发送缓冲满了，那么就需要等待缓冲空出空闲空间来，这个就是写操作 IO 操作的真正耗时。 我们开始以为 read 操作是从目标机器拉取数据，但实际上不是这样的。read 操作只负责将数据从本地操作系统内核的接收缓冲中取出来就了事了。但是如果缓冲是空的，那么就需要等待数据到来，这个就是读操作 IO 操作的真正耗时。 这里可以配合《Netty、Redis、Zookeeper 高并发实战》2.2 节四种主要的 IO 模型来看一下。 Proactor 模式 Boost.Asio用的是Proactor模式（看C++/boost/asio）。 Proactor/Reactor模式也是否相像，二者都靠消息来驱动，都有回调函数，Proactor中，系统为你做了更多，告诉你结果，Reactor中，只是告诉你有事情发生了，可以做点什么了。 需要说明的是，并不是所有场合非阻塞异步方式的性能都最高，其实活还是那么多，系统帮你多做了些而已。如果只有少数几个连接，多线程+同步方式也许更适合。 惊群效应 多个进程或者线程在等待同一个事件，当事件发生时，所有进程或者线程都会被内核唤醒。然后，通常只有一个进程获得了该事件，并进行处理；其他进程在发现获取事件失败后，又继续进入了等待状态。这在一定程度上降低了系统性能。 具体来说，惊群通常发生在服务器的监听等待调用上。服务器创建监听socket，然后fork多个进程，在每个进程中调用accept或者epoll_wait等待终端的连接。 在高并发（多线程/多进程/多连接）中，会产生惊群的情况有： accept惊群 epoll惊群 nginx惊群 线程池惊群 “惊群效应\"是什么？高并发中的几种惊群效应简介 - 知乎 (zhihu.com) 什么是惊群效应 - 脉脉 (maimai.cn) 零拷贝 Java 中的零拷贝 这篇文章耐心看完，他讲的是真透彻，他从概念上区分了广义和狭义零拷贝，讲解了系统底层层面上的，JDK NIO 层面上的，Kafka、Netty 层面上的。 零拷贝 敖丙 DMA 技术 DMA 是一种允许外围设备（硬件子系统）直接访问系统主内存的机制。也就是说，基于 DMA 访问方式，系统主内存于硬盘或网卡之间的数据传输可以绕开 CPU 的调度。 参考：DMA 技术是什么，在哪里用？看完绝对有收获 - 简书 (jianshu.com) Linux 支持的 (常见) 零拷贝 mmap 内存映射，sendfile（linux 2.1 支持），Sendfile With DMA Scatter/Gather Copy（可以看作是 sendfile 的增强版，批量 sendfile），splice（linux 2.6.17 支持）。 Linux 零拷贝机制对比：无论是传统 IO 方式，还是引入零拷贝之后，2 次 DMA copy 是都少不了的。因为两次 DMA 都是依赖硬件完成的。 PageCache 磁盘高速缓存 主要是两个优点：缓存最近被访问的数据，预读功能 但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DRM 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能 大文件传输 「异步 I/O + 直接 I/O」来替代零拷贝技术 直接 I/O Liunx 提供了对这种需求的支持，即在 open() 系统调用中增加参数选项 O_DIRECT， 用它打开的文件便可以绕过内核缓冲区的直接访问，这样便有效避免了 CPU 和内存的多余时间开销。 Java本身并不支持直接IO。 Java NIO Java NIO 引入了用于通道的缓冲区的 ByteBuffer。 ByteBuffer 有三个主要的实现： HeapByteBuffer，DirectByteBuffer，MappedByteBuffer Netty 中的零拷贝 Netty 中的 Zero-copy 与上面我们所提到到 OS 层面上的 Zero-copy 不太一样, Netty 的 Zero-copy 完全是在用户态 (Java 层面) 的，它的 Zero-copy 的更多的是偏向于优化数据操作这样的概念。 Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝。 通过 wrap 操作，我们可以将 byte[] 数组、ByteBuf、 ByteBuffer 等包装成一个 Netty ByteBuf 对象，进而避免了拷贝操作。 ByteBuf 支持 slice 操作，因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝。 通过 FileRegion 包装的 FileChannel.tranferTo 实现文件传输，可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环 write 方式导致的内存拷贝问题。 前三个都是 广义零拷贝，都是减少不必要数据 copy；偏向于应用层数据优化的操作。 Windows hiberfil.sys 和 pagefile.sys 占用系统空间，其分别是休眠空间和虚拟内存。 模拟 linux 环境 wsl2（Windows Subsystem for Linux，Windows下的Linux子系统） cygwin64 虚拟机 VMware VirtualBox Linux 常用服务搭建 （Nginx，Shadowsocks，Ngrok...） CentOS7 Linux 如何查看端口状态_百度经验 Linux Yum 命令使用举例_Linux 教程_Linux 公社-Linux 系统门户网站 CentOS7 使用 firewalld 打开关闭防火墙与端口 - 莫小安 - 博客园 MySql CentOS 下的 Mysql 的安装和使用 - suxiaoman - 博客园 Jetty Centos6.8 Jetty 安装配置 - 那个汪 - 博客园 Nginx Nginx 的一些基本功能 - CSDN 博客 Shadowsocks 记一次搭建 SS 服务器，完整的过程。，搭建 ss_Linux 教程 · 帮客之家 Centos 7 下搭建 SS - CSDN 博客 Shadowsocks - Clients 锐速 ServerSpeeder 无限带宽破解版一键安装包 (2017.6.23 更新 )-蜗牛 789 Ngrok CentOS7.3 编译安装 go1.8.1 - Aliang Log CentOS 下部署 Ngrok 服务器 - YE_NICKNAME - CSDN 博客 Centos 下自己架设 ngrok 服务器（内网测试神器） - 个人文章 - SegmentFault 必备软件 系统镜像 https://msdn.itellyou.cn/ everything wox（window 快速搜索文件启动程序软件） HTTP 接口测试工具 Postman Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Base/数据库.html":{"url":"Note_Base/数据库.html","title":"数据库","keywords":"","body":"《数据库》 MySQL 数据类型 MySQL 中的 int(M)，int(M) 里的 M 表示最大显示宽度，当加上 zerofill 才会表现出效果来。 unsigned 编码 utf8_general_ci、utf8_unicode_ci 和 utf8_bin 的区别 彻底解决 mysql 中文乱码 - CSDN 博客 SQL 语句 select select: 即最常用的查询，是不加任何锁的 select ... lock in share mode: 会加共享锁 (Shared Locks) select ... for update: 会加排它锁 联接子句 union，join 范式 第一范式：1NF是对属性的原子性约束，要求属性具有原子性，不可再分解； 第二范式：2NF是对记录的惟一性约束，要求记录有惟一标识，即实体的惟一性； 第三范式：3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。 没有冗余的数据库设计可以做到。但是，没有冗余的数据库未必是最好的数据库，有时为了提高运行效率，就必须降低范式标准，适当保留冗余数据。具体做法是：在概念数据模型设计时遵守第三范式，降低范式标准的工作放到物理数据模型设计时考虑。降低范式就是增加字段，允许冗余。 锁 前言： 表锁，页面锁，行锁，共享锁，排它锁，意向锁，记录锁，间隙锁，临键锁......这些都是什么鬼？？？ MySQL 有哪些锁 据加锁的范围，可以分为全局锁、表级锁和行锁三类。 全局锁 flush tables with read lock unlock tables 应用场景：全库逻辑备份 但在支持「可重复读隔离级别的事务」的存储引擎中，可避免使用全局锁备份： InnoDB 存储引擎，在使用 mysqldump 时加上 –single-transaction 参数的时候，就会在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。 表级锁 表锁； //表级别的共享锁，也就是读锁； lock tables t_student read; //表级别的独占锁，也就是写锁； lock tables t_stuent write; 尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁。 元数据锁（MDL）; 对一张表进行 CRUD 操作时，加的是 MDL 读锁； 对一张表做结构变更操作的时候，加的是 MDL 写锁； 意向锁； 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」； 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」； 意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables ... read）和独占表锁（lock tables ... write）发生冲突。 意向锁的目的是为了快速判断表里是否有记录被加锁。 AUTO-INC 锁； 在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过 AUTO-INC 锁实现的。 行级锁 InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。 前面也提到，普通的 select 语句是不会对记录加锁的，因为它属于快照读。如果要在查询时对记录加行锁，可以使用下面这两个方式，这种查询会加锁的语句称为锁定读。 //对读取的记录加共享锁 select ... lock in share mode; //对读取的记录加独占锁 select ... for update; 上面这两条语句必须在一个事务中，因为当事务提交了，锁就会被释放，所以在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit = 0。 共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。 行级锁的类型主要有三类： Record Lock，记录锁，也就是仅仅把一条记录锁上； Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身； Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。 Record Lock Record Lock 称为记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的： 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）; 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。 Gap Lock Gap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。 间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。 Next-Key Lock next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。 插入意向锁 一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。 如果有的话，插入操作就会发生阻塞，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。 插入意向锁名字虽然有意向锁，但是它并不是意向锁，它是一种特殊的间隙锁，属于行级别锁。 加锁方式 MySQL 不同的存储引擎支持不同的锁机制 表锁：开销小，加锁快；不会出现死锁 行锁：开销大，加锁慢；会出现死锁 默认情况下，表锁和行锁都是自动获得的，不需要额外的命令。 什么 SQL 语句会加行级锁？ 普通的 select 语句是不会对记录加锁的（除了串行化隔离级别），因为它属于快照读，是通过 MVCC（多版本并发控制）实现的。 如果要在查询时对记录加行级锁，可以使用下面这两个方式，这两种查询会加锁的语句称为锁定读。 //对读取的记录加共享锁(S型锁) select ... lock in share mode; //对读取的记录加独占锁(X型锁) select ... for update; 上面这两条语句必须在一个事务中，因为当事务提交了，锁就会被释放，所以在使用这两条语句的时候，要加上 begin 或者 start transaction 开启事务的语句。 除了上面这两条锁定读语句会加行级锁之外，update 和 delete 操作都会加行级锁，且锁的类型都是独占锁(X型锁)。 //对操作的记录加独占锁(X型锁) update table .... where id = 1; //对操作的记录加独占锁(X型锁) delete from table where id = 1; MySQL 是怎么加行级锁的？ 加锁的对象是索引，加锁的基本单位是 next-key lock，它是由记录锁和间隙锁组合而成的，next-key lock 是前开后闭区间，而间隙锁是前开后开区间。 但是，next-key lock 在一些场景下会退化成记录锁或间隙锁。 总结一句，在能使用记录锁或者间隙锁就能避免幻读现象的场景下， next-key lock 就会退化成记录锁或间隙锁。 ​ 查询： 唯一索引等值查询 唯一索引范围查询 非唯一索引等值查询 非唯一索引范围查询 没有加索引的查询 ​ 总结下， MySQL 行级锁的加锁规则。 唯一索引等值查询： 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」。 非唯一索引等值查询： 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。 当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。 非唯一索引和主键索引的范围查询的加锁规则不同之处在于： 唯一索引在满足一些条件的时候，索引的 next-key lock 退化为间隙锁或者记录锁。 非唯一索引范围查询，索引的 next-key lock 不会退化为间隙锁和记录锁。 其实理解 MySQL 为什么要这样加锁，主要要以避免幻读角度去分析，这样就很容易理解这些加锁的规则了。 还有一件很重要的事情，在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。 锁释放 锁只有在执行 commit 或者 rollback 的时候才会释放，并且所有的锁都是在同一时刻被释放。 死锁 产生：两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。 死锁产生 普通的 select 语句是不会对记录加锁的，因为它是通过 MVCC 的机制实现的快照读，如果要在查询时对记录加行锁，可以使用下面这两个方式： begin; //对读取的记录加共享锁 select ... lock in share mode; commit; //锁释放 begin; //对读取的记录加排他锁 select ... for update; commit; //锁释放 行锁的释放时机是在事务提交（commit）后，锁就会被释放，并不是一条语句执行完就释放行锁。 执行以下插入语句时，会在插入间隙上获取插入意向锁，而插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以所以两个事务中 select ... for update 语句并不会相互影响。 间隙锁的意义只在于阻止区间被插入，因此是可以共存的。 但是有一点要注意，next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。 如何避免死锁 死锁的四个必要条件：互斥、占有且等待、不可强占用、循环等待。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。 在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态： 设置事务等待锁的超时时间。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的，默认值时 50 秒。 开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，默认就开启。 上面这个两种策略是「当有死锁发生时」的避免方式。 参考链接 MySQL 锁总结 MySQL 有哪些锁？ | 小林coding (xiaolincoding.com) MySQL 是怎么加锁的？ | 小林coding (xiaolincoding.com) 事务 事务特性，ACID 的含义 原子性 a. 事务是一个原子操作单元 b. 要么都做，要么都不做，没有第三种情况 c. 原子性仅能够保证单个事务的一致性! 一致性 a. 事务操作前和操作后都必须满足业务规则约束 b. 比如资源数量一致：A 向 B 转账，转账前和转账后 AB 两个账户的总金额必须是一致的 c. 一致性是最基本的属性，其它的三个属性都为了保证一致性而存在的。为了保证并发情况下的一致性，引入了隔离性，即保证每一个事务能够看到的数据总是一致的，就好象其它并发事务并不存在一样。 隔离性 a. 多个并发事务同时对数据进行读写的能力 b. 隔离性可以防止事务并发执行时由于交叉执行导致数据不一致的问题 持久性 a. 对数据的修改是永久的 b. 即使出现系统故障也不会丢失 InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？ 持久性是通过 redo log （重做日志）来保证的； 原子性是通过 undo log（回滚日志） 来保证的； 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的； 一致性则是通过持久性+原子性+隔离性来保证； 并发问题 脏读 一个事务正在对一条记录做修改，在这个事务提交之前，别的事务读取到了这个事务修改之后的数据，也就是说，一个事务读取到了其他事务还没有提交的数据，就叫做脏读。 不可重复读（第一类不可重复读） 一个事务读某条数据读两遍，读到的是不一样的数据，也就是说，一个事务在进行中读取到了其他事务对旧数据的修改结果。（比如说 我开一个事务 修改某条数据 先查后改 执行修改动作的时候发现这条数据已经被别的事务删掉了） 幻读（第二类不可重复读） 一个事务中，读取到了其他事务新增的数据，仿佛出现了幻象。（幻读与不可重复读类似，不可重复读是读到了其他事务 update/delete 的结果，幻读是读到了其他事务 insert 的结果） 隔离级别 读未提交（read-uncommitted） 在一个事务中，可以读取到其他事务未提交的数据变化，这种读取其他会话还没提交的事务，叫做脏读现象，在生产环境中切勿使用。 读已提交（read-committed） Sql Server,Oracle 默认 在一个事务中，可以读取到其他事务已经提交的数据变化，这种读取也就叫做不可重复读，因为两次同样的查询可能会得到不一样的结果。 可重复读（repetable-read） MySQL 默认 在一个事务中，直到事务结束前，都可以反复读取到事务刚开始时看到的数据，并一直不会发生变化，避免了脏读、不可重复读现象，但是在 SQL 标准中它还是无法解决幻读问题。 可串行化（serializable） 这是最高的隔离级别，它强制事务串行执行，避免了前面说的幻读现象，简单来说，它会在读取的每一行数据上都加锁，所以可能会导致大量的超时和锁争用问题。 ​ 隔离级别 读数据一致性 脏读 不可重复读 幻读 读未提交 最低级别，只保证不读取物理上损坏的数据 有 有 有 读已提交 语句级 无 有 有 可重复读 事务级 无 无 可能有 可串行化 最高级别，事务级 无 无 无 快照读 快照读（普通读）：snapshot read，通过 MVCC 机制读取历史数据的方式 select * from table .... 当前读：current read ，读取数据库最新版本数据的方式 insert、update、delete、select for update、select lock in share mode Read View 在 MVCC 里如何工作 两个知识： Read View 中四个字段作用； 聚簇索引记录中两个跟事务有关的隐藏列； Read View： Read View 有四个重要的字段： m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。 min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。 max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1； creator_trx_id ：指的是创建该 Read View 的事务的事务 id。 了解聚簇索引记录中的两个隐藏列。 假设在账户余额表插入一条小林余额为 100 万的记录，然后我把这两个隐藏列也画出来，该记录的整个示意图如下： 对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列： trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里； roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。 在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况： 一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况： 如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。 如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中： 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。 这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。 可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。 读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View。 完全解决幻读了吗？ MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了），解决的方案有两种： 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。 针对当前读（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。 这两个解决方案是很大程度上解决了幻读现象，但是还是有个别的情况造成的幻读现象是无法解决的。 ​ 第一个例子：对于快照读， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。 第二个例子：对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。 ​ 所以，MySQL 可重复读隔离级别并没有彻底解决幻读，只是很大程度上避免了幻读现象的发生。 要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。 ​ 注意： RR 级别下隐藏着一个操作，就是在事务 A 提交前，事务 B 已经进行过一次查询，否则，事务 B 会读取最新的数据。原文 为什么很多文章都产生误传，说是可重复读可以解决幻读问题！原因出自官网的一句话 (地址是:https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html#innodb-record-locks)，原文内容如下 By default, InnoDB operates in REPEATABLE READ transaction isolation level. In this case, InnoDB uses next-key locks for searches and index scans, which prevents phantom rows (see Section 14.7.4, “Phantom Rows”). 按照原本这句话的意思，应该是 InnoDB 默认用了 REPEATABLE READ。在这种情况下，使用 next-key locks 解决幻读问题！ 结果估计，某个国内翻译人员翻着翻着变成了 InnoDB 默认用了 REPEATABLE READ。在这种情况下，可以解决幻读问题！ 然后大家继续你抄我，我抄你，结果你懂的！ 显然，漏了\"使用了 next-key locks！\"这个条件后，意思完全改变，我们在该隔离级别下执行语句 select * from tx_tb where pId >= 1; 是快照读，是不加任何锁的，根本不能解决幻读问题，除非你用 select * from tx_tb where pId >= 1 lock in share mode; 这样，你就用上了 next-key locks，解决了幻读问题！ 其实幻读很多时候是我们完全可以接受的 ​ 参考链接： 深入理解 mysql 的事务隔离级别和底层实现原理 Mysql 中 select 的正确姿势，新说 Mysql 事务隔离级别，他的“数据库系列”都挺不错的 MySQL 可重复读隔离级别，完全解决幻读了吗？ | 小林coding (xiaolincoding.com) 事务传播 其实这个是Spring的概念，Spring 它对 JDBC 的隔离级别作出了补充和扩展，其提供了 7 种事务传播行为 PROPAGATION_REQUIRED：默认事务类型，如果没有，就新建一个事务；如果有，就加入当前事务。适合绝大多数情况。 PROPAGATION_REQUIRES_NEW：如果没有，就新建一个事务；如果有，就将当前事务挂起。 PROPAGATION_NESTED：如果没有，就新建一个事务；如果有，就在当前事务中嵌套其他事务。 PROPAGATION_SUPPORTS：如果没有，就以非事务方式执行；如果有，就使用当前事务。 PROPAGATION_NOT_SUPPORTED：如果没有，就以非事务方式执行；如果有，就将当前事务挂起。即无论如何不支持事务。 PROPAGATION_NEVER：如果没有，就以非事务方式执行；如果有，就抛出异常。 PROPAGATION_MANDATORY：如果没有，就抛出异常；如果有，就使用当前事务。 索引 索引分类 按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。 按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）。 按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。 按「字段个数」分类：单列索引、联合索引。 B Tree 查找算法：首先在根节点进行二分查找，如果找到则返回对应节点的 data，否则在相应区间的指针指向的节点递归进行查找。 B+Tree 相比 B-Tree： 内节点不存储 data，只存储 key； 叶子节点不存储指针。 一般在数据库系统或文件系统中使用的 B+Tree 结构都在经典 B+Tree 基础上进行了优化，在叶子节点增加了顺序访问指针，做这个优化的目的是为了提高区间访问的性能。 利用计算机预读特性 操作系统一般将内存和磁盘分割成固态大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点，并且可以利用预读特性，相邻的节点也能够被预先载入。 B+Tree vs B Tree B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。 另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。 全文索引 全文索引有自己的语法格式，使用 match 和 against 关键字，比如 select * from fulltext_test where match(content,tag) against('xxx xxx'); 前缀索引 前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。 聚簇索引 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里； 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。 如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是覆盖索引。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表。 联合索引 通过将多个字段组合成一个索引，该索引就被称为联合索引。 使用联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。在使用联合索引进行查询的时候，如果不遵循「最左匹配原则」，联合索引会失效，这样就无法利用到索引快速查询的特性了。 ​ 最左前缀匹配原则 mysql联合索引 - 沧海一滴 - 博客园 mysql 会一直向右匹配直到遇到范围查询 (>、 3 and d = 4 如果建立 (a,b,c,d) 顺序的索引，d 是用不到索引的，如果建立 (a,b,d,c) 的索引则都可以用到，a,b,d 的顺序可以任意调整。 ​ 特殊情况：范围查询。 联合索引的最左匹配原则会一直向右匹配直到遇到「范围查询」就会停止匹配。也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。 Q1: select * from t_table where a > 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？ Q1 这条查询语句只有 a 字段用到了联合索引进行索引查询，而 b 字段并没有使用到联合索引。 Q2: select * from t_table where a >= 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？ 但是对于符合 a = 1 的二级索引记录的范围里，b 字段的值是「有序」的 所以，Q2 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。 索引下推 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 当你的查询语句的执行计划里，出现了 Extra 为 Using index condition，那么说明使用了索引下推的优化。 什么时候需要 / 不需要创建索引？ 什么时候适用索引？ 字段有唯一性限制的，比如商品编码； 经常用于 WHERE 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。 经常用于 GROUP BY 和 ORDER BY 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。 什么时候不需要创建索引？ WHERE 条件，GROUP BY，ORDER BY 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。 字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。 表数据太少的时候，不需要创建索引； 经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。 优化索引 前缀索引优化； 覆盖索引优化； 主键索引最好是自增的； 防止索引失效； 索引失效 当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效； 当我们在查询条件中对索引列使用函数，就会导致索引失效。 当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。 MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。 MYSQL 如何挑选索引？ 执行计划 要想知道优化器选择了哪个索引，我们可以在查询语句最前面加个 explain 命令，这样就会输出这条 SQL 语句的执行计划。 对于执行计划，参数有： possible_keys 字段表示可能用到的索引； key 字段表示实际用的索引，如果这一项为 NULL，说明没有使用索引； key_len 表示索引的长度； rows 表示扫描的数据行数。 type 表示数据扫描类型，我们需要重点看这个。 ​ type 字段就是描述了找到所需数据时使用的扫描方式是什么，常见扫描类型的执行效率从低到高的顺序为： All（全表扫描）； index（全索引扫描）； range（索引范围扫描）； ref（非唯一索引扫描）； eq_ref（唯一索引扫描）； const（结果只有一条的主键或唯一索引扫描）。 ​ 除了关注 type，我们也要关注 extra 显示的结果。 这里说几个重要的参考指标： Using filesort ：当查询语句中包含 group by 操作，而且无法利用索引完成排序操作的时候， 这时不得不选择相应的排序算法进行，甚至可能会通过文件排序，效率是很低的，所以要避免这种问题的出现。 Using temporary：使了用临时表保存中间结果，MySQL 在对查询结果排序时使用临时表，常见于排序 order by 和分组查询 group by。效率低，要避免这种问题的出现。 Using index：所需数据只需在索引即可全部获得，不须要再到表中取数据，也就是使用了覆盖索引，避免了回表操作，效率不错。 索引使用场景 索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效。 对于中到大型的表，索引就非常有效。 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。 是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，可以通过 explain 检查 SQL 的执行计划，比如上面第一种情况，它就不会使用索引 索引缺点 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加 索引需要占用物理空间，除了数据表占用数据空间之外，每一个索引还要占一定的物理空间，如果建立聚簇索引，那么需要的空间就会更大 当对表中的数据进行增加、删除和修改的时候，索引也需要维护，降低数据维护的速度 参考链接 我以为我对Mysql索引很了解，直到我遇到了阿里的面试官_HollisChuang's Blog-CSDN博客 数据库索引是如何工作的？ - 程序员和软件面试问题和答案 (programmerinterview.com) 一通骚操作，我把SQL执行效率提高了10000000倍！ - 知乎 MySQL进阶之（二）索引的数据结构_mysql数据结构-CSDN博客 索引常见面试题 | 小林coding (xiaolincoding.com) 存储引擎 MyISAM 事务：不支持 锁：表级锁 应用场景： MyISAM适合：(1)做很多count 的计算；(2)插入不频繁，查询非常频繁；(3)没有事务。 InnoDB适合：(1)可靠性要求比较高，或者要求事务；(2)表更新和查询都相当的频繁，并且行锁定的机会比较大的情况。 InnoDB MySQL默认采用的是InnoDB。 了解他和 MyISAM 的主要区别。 页结构 页是 InnoDB 管理存储空间的基本单位，一个页的大小一般是 16kb。 数据页可以大致划分为 7 个部分： 字段名 中文名 大小 简单描述 File Header 文件头部 38 字节 页的一些通用信息 Page Header 页面头部 56 字节 数据页专有的一些信息 Infimum + Supremum 最小记录和最大记录 26 字节 两个虚拟的行记录 User Records 用户记录 不确定 实际存储的行记录内容（大小不确定） Free Space 空闲空间 不确定 页中尚未使用的空间 Page Directory 页面目录 不确定 页中的某些记录的相对位置 File Trailer 文件尾部 8 字节 校验页是否完整 当涉及到数据库读写的时候，规定数据库每次读写都是以16k为单位的，一次最少从磁盘中读取16KB的内容到内存中，一次最少把内存中的16KB内容刷新到磁盘中。 ​ 为什么默认为16kb？ 在操作系统的文件管理系统中进行一次io读写，默认读取的大小为4kb（一页）。又因为局部性原理，操作系统会将命中的页周围的三块页一同加载进innodb的缓存池中，因此innnodb缓存池中页的大小为16kb。 ​ 一颗B+tree存储多少行数据？ B+tree树高为2，即存在一个根节点和若干个叶子节点，那这棵树存放总记录数为：根节点指针树*单个叶子节点的记录行数。 说明： 单个叶子节点（页）中的记录数=16K（一页16KB）/1K（假设一行1KB）=16。（这里假设一行记录的数据大小为1k） 计算非叶子节点能存放多少指针？假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即 16KB（16*1024=16384 byte）16384/14=1170（索引个数）；可以算出一颗高度为2的B+tree，能存放 1170*16=18720条 数据记录。 根据同样的原理计算B+tree树高为3，可以存放 1170（索引个数）*1170（索引个数）*16（每页行数）=21902400（2千万）条 这样的记录 总结：InnoDB中B+tree树的高度为1-3层，就能满足千万级的数据存储，在查找数据时一次页的查找就代表一次IO，所以通过主键索引查询通常只需要1-3次IO操作即可查找数据 ​ User Records (用户记录，即行记录) 对于InnoDB存储引擎而言，常见的行格式类型有Compact、Redundant、Dynamic和Compressed（细节没了解） ​ Page Directory（页目录） 在一个数据页查找指定主键值的记录的过程分为两步： 1、通过二分法确定该记录所在的槽 2、通过该记录的next_record属性遍历该槽所在的组中的各个记录 ​ File Trailer 页结构中的File Trailer的作用： 页中的数据在内存中被修改了，那么在修改后的某个时间需要把数据同步到磁盘中。但是在同步了一半的时候中断电了咋办，这不是莫名尴尬么？为了检测一个页是否完整（也就是在同步的时候有没有发生只同步一半的尴尬情况），设计InnoDB的大叔们在每个页的尾部都加了一个File Trailer部分，这个部分由8个字节组成，可以分成2个小部分： 前4个字节代表页的校验和 这个部分是和File Header中的校验和相对应的。每当一个页面在内存中修改了，在同步之前就要把它的校验和算出来，因为File Header在页面的前边，所以校验和会被首先同步到磁盘，当完全写完时，校验和也会被写到页的尾部，如果完全同步成功，则页的首部和尾部的校验和应该是一致的。如果写了一半儿断电了，那么在File Header中的校验和就代表着已经修改过的页，而在File Trialer中的校验和代表着原先的页，二者不同则意味着同步中间出了错。 后4个字节代表页面被最后修改时对应的日志序列位置（LSN） 这个部分也是为了校验页的完整性的，只不过我们目前还没说LSN是个什么意思，所以大家可以先不用管这个属性。 这个File Trailer与FILE Header类似，都是所有类型的页通用的。 ​ 参考： MySQL架构（二）- InnoDB的存储结构 MySQL架构（三）- 磁盘存储数据页 页的上层结构 在数据库中，还存在着区（Extent）、段（Segment）和表空间（Tablespace）的概念。 区（Extent）：是比页大一级的存储结构，在InnoDB存储引擎中，一个区会分配64 个连续的页。因为InnoDB中的页大小默认是16KB，所以一个区的大小是 64 * 16KB = 1MB 段（Segment）：由一个或多个 区 组成，区在文件系统是一个连续分配的空间（在InnoDB中是连续的 64 个页），不过在段中不要求区与区之间是相邻的。段是数据库中的分配单位，不同类型的数据库对象以不同的段形式存在。当我们创建数据表、索引的时候，就会相应创建对应的段，比如创建一张表时会创建一个表段，创建一个索引时会创建一个索引段 表空间（Tablespace）是一个逻辑容器，表空间存储的对象是段，在一个表空间中可以有一个或多个段，但是一个段只能属于一个表空间。数据库由一个或多个表空间组成，表空间从管理上可以划分为系统表空间、用户表空间、撤销表空间、临时表空间等。 ​ 为什么要有区 1、B+树的每一层中的页都会形成一个双向链表，如果是以页为单位来分配存储空间的话，双向链表相邻的两个页之间的物流位置可能离得非常远。介绍B+树索引的适用场景的时候特别提到范围查询只需要定位到最左边的记录和最右边的记录，然后沿着双向链表一直扫描就可以了，而如果链表中相邻的两个页物理位置离得非常远，就是所谓的随机I/O。再一次强调，磁盘的速度和内存的速度差了好几个数量级，随机I/O是非常慢的，所以我们应该尽量让链表中相邻的页的物流位置也相邻，这样进行范围查询的时候才可以使用所谓的顺序 I/O。 2、引入区的概念，一个区就是在物理位置上连续的64个页。因为 InnoDB 中的页大小默认是 16KB，所以一个区的大小是 64 * 16KB = 1MB。在表中数据最大的时候，为某个索引分配空间的时候就不再按照页为分单位分配了，而是按照区位单位分配，甚至在表中的数据特别多的时候，可以一次性分配多个连续的区。虽然可能造成一点点空间的浪费（数据不足以填充满整个区），但是从性能角度看，可以消除很多的随机I/O，功大于过！！！ ​ 为什么要有段 对于范围查询，其实是对B+树叶子节点中的记录进行顺序扫描，而如果不区分叶子节点和非叶子节点，统统把节点代表的页面放到申请到的区中的话，进行范围扫描的效果就大打折扣了。所以InnoDB对B+树的叶子节点 和 非叶子节点 进行了区别对待，也就是说叶子节点有自己独有的区，非叶子节点也有自己独有的额区。存放叶子节点的区的集合就算是一个 段（Segment），存放非叶子节点的区的集合也算是一个段。也就是说一个索引会生成2个段，一个叶子节点段，一个非叶子节点段。 除了索引的叶子节点段和非叶子节点段之外，InnoDB中还有为存储一些特殊的数据而定义的段，比如回滚段，所以，常见的段有数据段、索引段、回滚段。数据段即为B+树的叶子节点，索引段即为B+树的非叶子节点 在InnoDB存储引擎中，对段的管理都是由引擎自身所完成，DBA不能也没有必要对其进行控制。这从一定程度上简化了DBA对于段的管理。 段其实不对应表空间中某一个连续的物理区域，而是一个逻辑上的概念，由若干个零散的页面以及一些完整的区组成。 ​ 为什么要有碎片区 为了考虑以完整的区为单位分配给某个段对于数据量较小的表太浪费存储空间的这种情况，InnoDB提出了一个碎片（Fragment）区的概念。在一个碎片区中，并不是所有的页都是为了存储同一个段的数据而存在的，而是碎片区中的页可以用于不同的目的，比如有些页用于段A，有些页用于段B，有些页甚至哪个段都不属于。碎片区直属于表空间，并不属于任何一个段。所以以后为某个段分配存储空间的策略如下： 在刚开始想表中插入数据的时候，段是从某个碎片区以单个页面为单位来分配存储空间的 当某个段已经占用了32个碎片区页面之后，就会申请以完整的区为单位来分配存储空间 现在段不能仅定义为是某些区的集合，更精确的应该是 某些零散的页面以及一些完整的区的集合 ​ 参考 一文读懂MySQL-InnoDB的数据库存储结构！ - 知乎 (zhihu.com) 数据页加载方式 对于MySQL存放的数据，逻辑概念上我们称之为表，在磁盘物流层面而言是按数据页形式进行存放的，当起加载到MySQL中我们称之为缓存页。如果缓存池中没有该页数据，那么缓冲池有3种读取数据方式，每种方式的读取效率都是不同的。 内存读取、随机读取、顺序读取 ​ 顺序读取 顺序读取其实是一种批量读取的方式，因为我们请求的数据在磁盘上往往都是相邻存储的，顺序读取可以帮助我们批量读取页面，这样的话，一次性加载到缓冲池中就不需要再对其他页单独进行磁盘I/O操作了。如果一个磁盘的吞吐量是 40MB/S，那么对于一个 16KB大小的页来说，一次可以顺序读取 2560（40MB/16KB）个页，相当于一个页的读取时间为 0.4ms。采用批量读取的方式，即使是从磁盘上进行读取，效率也比从内存中只单独读取一个页的效率要高。 日志 binlog 定义 binlog 是 MySQL 的逻辑日志，也叫二进制日志、归档日志，由 MySQL Server 来记录。 用于记录用户对数据库操作的SQL语句（除了查询语句）信息，以二进制的形式保存在磁盘中。 ​ 记录方式 binlog 通过追加的方式写入的，可通过配置参数 max_binlog_size 设置每个 binlog 文件的大小，当文件大小大于给定值后，日志会发生滚动，之后的日志记录到新的文件上。 ​ 格式 binlog 日志有三种格式，分别为 STATMENT、ROW 和 MIXED。 STATMENT ROW 说明 基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。是bin log的默认格式。 基于行的复制(row-based replication, RBR)：不记录每一条SQL语句的上下文信息，仅保存哪条记录被修改。 优点 不需要记录每一条SQL语句与每行的数据变化，减少了bin log的日志量，节约了磁盘IO，提高性能。 会非常清楚的记录下每一行数据修改的细节，不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。 缺点 在某些情况下会导致master-slave中的数据不一致，如sleep()函数， last_insert_id()，以及user-defined functions(udf)等会出现问题。 会产生大量的日志，尤其是alter table的时候会让日志暴涨。 MIXED模式是基于 STATMENT 和 ROW 两种模式的混合复制(mixed-based replication, MBR)，一般的复制使用STATEMENT模式保存 binlog，对于 STATEMENT 模式无法复制的操作使用ROW模式保存 binlog，MySQL 会根据执行的 SQL 语句选择日志保存方式。 redo log 定义 redo log 是 MySQL 的物理日志，也叫重做日志，记录存储引擎 InnoDB 的事务日志。 MySQL 每执行一条 SQL 更新语句，不是每次数据更改都立刻写到磁盘，而是先将记录写到 redo log 里面，并更新内存（这时内存与磁盘的数据不一致，将这种有差异的数据称为脏页），一段时间后，再一次性将多个操作记录写到到磁盘上，这样可以减少磁盘 io 成本，提高操作速度。先写日志，再写磁盘，这就是 MySQL 里经常说到的 WAL 技术，即 Write-Ahead Logging，又叫预写日志。MySQL 通过 WAL 技术保证事务的持久性。 ​ 记录方式 InnoDB 的 redo log 大小是固定的，采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。 ​ Crash Safe（宕机重启） 有了 redo log，当数据库发生宕机重启后，可通过 redo log 将未落盘的数据（check point 之后的数据）恢复，保证已经提交的事务记录不会丢失，这种能力称为 crash-safe。 两阶段提交 有了 redo log，为什么还需要 binlog 呢？先来看看 binlog 和 redo log 的区别： redo log binlog 文件大小 redo log 的大小是固定的。 binlog 可通过配置参数 max_binlog_size 设置每个 binlog 文件的大小。 实现方式 redo log 是 InnoDB 引擎层实现的，并不是所有引擎都有。 binlog 是 Server 层实现的，所有引擎都可以使用 binlog 日志。 记录方式 redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。日志上的记录修改落盘后，日志会被覆盖掉，无法用于数据回滚/数据恢复等操作。 binlog 通过追加的方式记录，当文件大小大于给定值后，日志会发生滚动，之后的日志记录到新的文件上，不会覆盖以前的记录。 由 binlog 和 redo log 的区别可知：binlog 日志只用于归档，只依靠 binlog 是没有 crash-safe 能力的。但只有 redo log 也不行，因为 redo log 是 InnoDB 特有的，且日志上的记录落盘后会被覆盖掉。因此需要 binlog 和 redo log 二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。 ​ 当执行一条 SQL 更新语句时，过程如下： 可以看到，在“两阶段提交”阶段，将 redo log 的写入分成了两步：prepare 和 commit。在 redo log 状态为 prepare 时记录 binlog 可以保证两个日志的记录一致。 如何执行数据恢复? DB宕机后重启，InnoDB 会首先去查看数据页中的LSN的数值。这个值代表数据页被刷新回磁盘的 LSN 的大小。然后再去查看 redo log 的 LSN 的大小。 如果数据页中的 LSN 值大说明数据页领先于 redo log 刷新回磁盘，不需要进行恢复。反之需要从redo log中恢复数据。 注：LSN 是 日志序列号， 为 log sequence number 的缩写，主要用于发生 crash 时对数据进行 recovery。LSN是一个一直递增的整型数字，表示事务写入到日志的字节总量。 LSN 不仅只存在于重做日志中，在每个数据页头部也会有对应的 LSN 号，该 LSN 记录当前页最后一次修改的 LSN 号，用于在 recovery 时对比重做日志 LSN 号决定是否对该页进行恢复数据。 前面说的check point也是由 LSN 号记录的，LSN 号串联起一个事务开始到恢复的过程。 ​ 在宕机后，重启 MySQL 时，InnoDB 会自动恢复 redo log 中 checkpoint_lsn 后的，且处于 commit 状态的事务。如果 redo log 中事务的状态为 prepare，则需要先查看 binlog 中该事务是否存在，是的话就恢复，否则就通过 undo log 回滚。 ​ 如果将 innodb_flush_log_at_trx_commit 和 sync_binlog 参数设置成 1，前者表示每次事务的 redo log 都直接持久化到磁盘，后者表示每次事务的 binlog 都直接持久化到磁盘，可以双重保证 MySQL 异常重启之后的数据不会丢失。 undo log 在MySQL中，事务的回滚主要依赖于undo log（回滚日志），而不是redo log（重做日志）。当一个事务需要被回滚时，MySQL会根据undo log中的信息，将事务的所有修改逐一回滚，从而将数据恢复到事务开始前的状态。 undo log只能用于回滚单个事务的修改，而不能用于恢复数据库宕机后的数据。如果数据库宕机，MySQL会依赖于redo log来恢复数据。 ​ 参考 MySQL 的日志系统 Crash Safe 和 Binlog 的关系 MySQL事务日志--redo, undo详解_mysql redo undo-CSDN博客 Redo Log 那些事儿！Redo Log 如何保证数据库不丢数据的？（MySQL两阶段提交详解） - 掘金 (juejin.cn) 备份与恢复 冷备份，热备份 cp，mysqldump，lvm2 快照，xtrabackup mysql 误删数据快速恢复 高级 explain explain 显示了 mysql 如何使用索引来处理 select 语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句。 如何快速的删除一张大（TB 级别）表？ 区分 drop，truncate，delete 数据恢复方面：delete 可以恢复删除的数据，而 truncate 和 drop 不能恢复删除的数据。 执行速度方面：drop > truncate > delete。 删除数据方面：drop 是删除整张表，包含行数据和字段、索引等数据，而 truncate 和 drop 只删除了行数据。 添加条件方面：delete 可以使用 where 表达式添加查询条件，而 truncate 和 drop 不能添加 where 查询条件。 重置自增列方面：在 InnoDB 引擎中，truncate 可以重置自增列，而 delete 不能重置自增列。 利用 linux 中硬链接 慢日志 可以设置一个时间，那么所有执行时间超过这个时间的 SQL 都会被记录下来。这样就可以通过慢日志快速的找到网站中 SQL 的瓶颈来进行优化。 冷热数据分离 顾名思义就是分成两个库，一个是冷库一个是热库，几个月之前不常用的数据放到冷库中，最新的数据比较新的数据放到热库中。 分布式 主从复制，分库分表 分布式锁 参数优化 innodb_buffer_pool_size InnoDB buffer pool 里包含什么？ 数据缓存 InnoDB数据页面 索引缓存 索引数据 缓冲数据 脏页（在内存中修改尚未刷新(写入)到磁盘的数据） 内部结构 如自适应哈希索引，行锁等。 如何设置innodb_buffer_pool_size? innodb_buffer_pool_size默认大小为128M。最大值取决于CPU的架构。在32-bit平台上，最大值为2^32 -1,在64-bit平台上最大值为2^64-1。当缓冲池大小大于1G时，将innodb_buffer_pool_instances设置大于1的值可以提高服务器的可扩展性。 大的缓冲池可以减小多次磁盘I/O访问相同的表数据。在专用数据库服务器上，可以将缓冲池大小设置为服务器物理内存的80%。 Redis 概述 Redis 是一种基于键值对 (Key-Value) 的 NoSQL 数据库，Redis 的 Value 的基础数据结构有 string、list、hash、set、zset； 有 Bitmaps，HyperLoglog，Geographic 等多种高级数据结构和算法 Redis 还提供了键过期，发布订阅，事务，Lua 脚本，哨兵，Cluster 等功能 Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能 数据类型 string、list、hash、set、zset 选择 选择 hash 还是 string 存储数据？ 编码 encoding 记录了对象所保存的值的编码 下图展示了 redisObject 、Redis 所有数据类型、以及 Redis 所有编码方式（底层实现）三者之间的关系： 数据结构 字典 dictht 跳跃表，是有序集合的底层实现之一 5.0新数据结构Stream 过期 Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。 对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。 淘汰 可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。 LRU 算法和 LFU 算法，redis 对 LRU 的改进 让我们一起聊聊如何改进 LRU 算法-改进leach算法 (51cto.com) 高可用 主从复制 Sentinel，Codis，Cluster Redis 数据倾斜问题 集群模式 redis集群 数据一致性 Redis主从集群切换数据丢失问题如何应对？ 数据一致性 产生原因 并发的场景下，导致读取老的 DB 数据，更新到缓存中。 缓存和 DB 的操作，不在一个事务中，可能只有一个操作成功，而另一个操作失败，导致不一致。 更新缓存的设计模式 Cache Aside Pattern（旁路缓存，常用） 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从cache中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 Read/Write Through Pattern 把更新数据库的操作由缓存自己代理了，但Cache自己更新数据库是一个同步操作 Write Behind Caching Pattern（游戏开发会常用） Write Behind 又叫 Write Back。Write Behind 就是 Linux 文件系统的 Page Cache 算法。 Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。 这个设计的好处就是让数据的 I/O 操作飞快无比（因为直接操作内存嘛），因为异步，write backg 还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。 数据库与缓存双写问题 思考 按照Cache Aside Pattern的更新，这种方式真的没问题吗？ 最终一致性的解决方案 从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。 这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。 不依赖于给缓存设置过期时间的方案： 先更新数据库，再更新缓存 会有冷数据（多写少读） 先删除缓存，再更新数据库 A线程删缓存但未更新DB，B线程读并写入缓存导致脏数据。解决方案是使用延迟双删（第二次删除失败怎么办?） 先更新数据库，再删除缓存 缓存刚好失效，A线程读并写入缓存，过程中穿插了B线程的更新DB删除缓存。概率极小，该方案可满足大部分的应用场景。 （为什么没有先更新缓存，再更新数据库这种策略？若先更新缓存，缓存更新成功，但是更新数据库时发生异常导致回滚，那么缓存中的数据无法回滚，导致数据不一致。看产生原因的第二点） 删除缓存失败： 解决方案是消息队列或者其他 binlog 同步，引入消息队列会带来更多的问题，并不推荐直接使用。 参考： 缓存的双写一致性解决方案 解决redis与mysql数据一致性 看不懂的你来打我~_kingtok的博客 一致性恢复方案 TODO 如果出现了问题，怎么解决？ 主从DB与cache一致性 TODO 回顾一下分布式事务一致性，别混淆 应用场景 分布式锁、延时队列、位图、HyperLogLog、布隆过滤器、简单限流（zset）、漏斗限流、GeoHash（地理位置） 限流 Redis应用-限流 - 掘金 (juejin.cn) 分布式锁 单实例中实现分布式锁： setnx（注意删除时最好使用 Lua 脚本删除，逻辑是先获取 key，如果存在并且值是自己设置的就删除此 key，否则就跳过） set key value px milliseconds nx（使用 set 代替 setnx，相当于 setnx + expire 实现了原子性，不必担心 setnx 成功，expire 失败的问题） 多节点 redis 实现的分布式锁 RedLock 可以看看 redission 的实现 参考： redis分布式锁深度剖析(超时情况) Redlock：Redis分布式锁最牛逼的实现 Redlock（redis分布式锁）原理分析 - RGC 缓存穿透解决方案 增加校验，缓存，布隆过滤器（Bloom Filter），hyperloglog 持久化 RDB 持久化 将某个时间点的所有数据都存放到硬盘上 AOF 持久化 将写命令添加到 AOF 文件（Append Only File）的末尾 技术 使用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久化 bgsave 做全量持久化到 RDB 二进制文件中，aof 做增量持久化，存储的是文本协议数据 额外的知识点 Redis 的线程模型：单线程，IO 多路复用 客户端与服务器的通信协议 管道，事务 注意 redis 事务不保证原子性，不支持回滚。他总结来说：就是一次性、顺序性、排他性的执行一个队列中的一系列命令。其他客户端提交的命令请求不会插入到事务执行命令序列中。 思考一下，为什么这样设计？ Info 指令 源码 带有详细注释的 Redis 3.0 代码 jemalloc，Redis 默认使用 jemalloc(facebook) 库来管理内存 一些面试题 《吊打面试官》系列-缓存雪崩、击穿、穿透 Java 的 Redis 客户端：Jedis，Redisson Redisson 不仅封装了 redis ，还封装了对更多数据结构的支持，以及锁等功能，相比于 Jedis 更加大。 Redisson 的加锁/释放锁都是用 Lua 脚本，相比于 setnx 就能实现，为何多此一举？仔细看 Lua 脚本就会发现考虑得非常全面，其中包括锁的重入性。 但 Jedis 相比于 Redisson 更原生一些，更灵活。 Redis模块 ReJSON模块 ReJSON 是一个Redis Module，它实现了ECMA-404 The JSON Data Interchange Standard作为本地数据类型，它允许从Redis Keys（documents）中存储，更新和获取 JSON 值 主要特性： 完全支持JSON标准 对于在文档内选择元素类似 JSONPath 语法 文档作为二进制数据被存储在一个树形结构中，允许快速访问子元素 对所有 JSON 数据类型按照原子操作进行分类 ReJSON 是由 Redis Labs 开发的，源码下载地址是 https://github.com/RedisLabsModules/ReJSON 书单 《redis 设计与实现 (第二版)》 《Redis 深度历险:核心原理与应用实践》 Memcache Redis 之与 Memcached 的比较 MongoDB 为什么 Mongodb 索引用 B 树，而 Mysql 用 B+树? Oracle 冷备份 正常关闭数据库 备份所有重要的文件到备份目录（数据文件、控制文件、重做日志文件等） 完成备份后启动数据库 热备份 数据恢复 几种oracle数据库恢复的练习示例 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Base/网络.html":{"url":"Note_Base/网络.html","title":"网络","keywords":"","body":"《网络》 TCP/IP 四层（参考）模型 OSI 七层模型与 TCP/IP 四层（参考）模型 底层网络协议 ARP，ICMP（网际控制信息协议），路由选择，DHCP，NAT IPv6 网络编程懒人入门(十一)：一文读懂什么是IPv6-网络编程 TCP/IP TCP三次握手和四次挥手 三次握手： 四次挥手： 为什么TCP握手，客户端最后还要发送一次确认呢？ 这主要是为了防止已失效的连接请求报文段突然又传到了 TCP 服务器，避免产生错误。 两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。 如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。 为什么TCP挥手，客户端最后还要等待2MSL？ 第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。 第二，同时在这段时间内，该链接在对话期间于网际路由上产生的残留报文(因为路径过于崎岖，数据报文走的时间太长，重传的报文都收到了，原始报文还在路上)传过来时，都会被立即丢弃掉。4分钟的时间足以使得这些残留报文彻底消逝。不然当新的端口被重复利用时，这些残留报文可能会干扰新的链接。 为什么建立连接是三次握手，关闭连接确是四次挥手呢？ 建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。 而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。 如果已经建立了连接，但是客户端突然出现故障了怎么办？ TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 要点 三次挥手是确保双方都能收和发的最少确认次数 四次挥手中间的两步并不总是会合成一步走，因为服务端处于“半关闭状态”，可能还有剩下的消息没发完，客户端此时能收不能发 四次挥手的 time_wait 状态，2MSL(MSL 为报文最大生存时间，一般 2 分钟，可更改)，作用是重传最后一个 ack 报文 参考 跟着动画来学习 TCP 三次握手和四次挥手 两张动图，彻底明白TCP的三次握手与四次挥手 - 墨天轮 (modb.pro) 重传机制 超时重传，RTT（Round-Trip Time 往返时延），超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。 快速重传，当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。 SACK方法，可以将已收到的数据的信息发送给「发送方」，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。 流量控制 由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议既保证了分组无差错、有序接收，也实现了流量控制。主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。 TCP拥塞算法 慢开始 、 拥塞避免算法 、拥塞发生 和 快速恢复 4.2 TCP 重传、滑动窗口、流量控制、拥塞控制 | 小林coding (xiaolincoding.com) ​ 拥塞发生 当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种： 超时重传 快速重传 当发生了「超时重传」，则就会使用拥塞发生算法。 ​ 快速恢复算法如下 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）； 重传丢失的数据包； 如果再收到重复的 ACK，那么 cwnd 增加 1； 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态； ​ 拥塞控制和流量控制的区别？ 两者的区别：流量控制是为了预防拥塞。如：在马路上行车，交警跟红绿灯是流量控制。当发生拥塞时，如何进行疏散，是拥塞控制。流量控制指点对点通信量的控制。而拥塞控制是全局性的，涉及到所有的主机和降低网络性能的因素。 TCP 和 UDP 的区别 TCP/IP 协议是一个协议簇。里面包括很多协议的。UDP 只是其中的一个。之所以命名为 TCP/IP 协议，因为 TCP,IP 协议是两个很重要的协议，就用他两命名了。原文 网络编程懒人入门(四)：快速理解TCP和UDP的差异 一台服务器最大并发 TCP 连接数多少 系统用一个4四元组来唯一标识一个TCP连接：{localip, localport,remoteip,remoteport} 理论： 一个 client 对同一个 remoteip,remoteport 最大tcp连接数为65535； server 端 tcp 连接4元组中只有 remoteip（也就是clientip）和 remote port（客户端port）是可变的，因此最大tcp 连接为客户端 ip 数 × 客户端 port 数，对IPV4，不考虑ip地址分类等因素，最大 tcp 连接数约为 2 的 32 次方（ip数）×2 的 16 次方（port数），也就是 server 端单机最大 tcp 连接数约为2的48次方。 实际：事实上，真正影响TCP连接数量的，是服务器的内存以及允许单一进程同时打开文件的数量，因为每创建一个TCP连接都要创建一个socket句柄，每个socket句柄都占用一部分系统内存，当系统内存被占用殆尽，允许的TCP并发连接数也就到了上限。一般来讲，通过增加服务器内存、修改最大文件描述符个数等，可以做到单台服务器支持10万+的TCP并发。 参考： 一台服务器最大并发 TCP 连接数多少 - 网安 (wangan.com) 一台主机最多能创建多少个 TCP 连接？-腾讯云开发者社区-腾讯云 (tencent.com) 注意： 一个进程默认打开文件的个数 1024，可修改。 其他问题 “一个tcp服务端和一个tcp客户端，客户端和服务端建立连接后，服务端一直sleep，然后客户端一直发送数据会是什么现象” 【底层原理】一道高频腾讯面试题:tcp数据发送问题 (qq.com) 没有accept，能建立TCP连接吗？ 动图图解！没有accept，能建立TCP连接吗？ (qq.com) UDP KCP （可以和QUIC一起比较下） kcp是由韦一笑开发的一个开源项目 KCP是一个快速可靠协议，能以比 TCP 浪费 10%-20% 的带宽的代价，换取平均延迟降低 30%-40%，且最大延迟降低三倍的传输效果。纯算法实现，并不负责底层协议（如UDP）的收发，需要使用者自己定义下层数据包的发送方式，以 callback的方式提供给 KCP。 连时钟都需要外部传递进来，内部不会有任何一次系统调用。 fec功能： FEC：Forward Error Correction，前向纠错 FEC 是一种通过在网络传输中增加数据包的冗余信息，使得接收端能够在网络发生丢包后利用这些冗余信息直接恢复出丢失的数据包的一种方法。 后端 - KCP中使用FEC纠错 - 开发日记 - SegmentFault 思否 谈谈网络通信中的 FEC 基础 - 知乎 (zhihu.com) HTTP HTTP1.0, 1.1, 2.0的区别 HTTP/1.0 默认短连接（一次请求建议一次TCP连接，请求完就断开），但是增加了keep-alive关键字来由短链接变成长连接，就是请求报文里的字段指定Connection:keep-alive； 支持GET、POST、 HEAD请求。 HTTP/1.1 默认长连接（一次TCP连接可以多次请求） 需要注意的是，服务器必须按照客户端请求的先后顺序依次回送相应的结果，以保证客户端能够区分出每次请求的响应内容。 HTTP/2 多路复用，避免了”队头堵塞” 二进制分帧，采用二进制格式传输数据，而非 HTTP 1.x的文本格式，解析起来更高效 首部压缩，对于相同的数据，不再通过每次请求和响应发送 服务器推送，免得客户端再次创建连接发送请求到服务器端获取 其中，1.0和1.1最常用，0.9几乎不用（旧），2.0比较少用（更新代价大） Java库 彻底掌握网络通信 (httpclien，asynchttpclient，HttpURLConnection，OkHttp3) HTTPS HTTPS的请求流程 客户端向服务器发起 HTTPS 请求，连接到服务器的 443 端口； 服务器端有一个密钥对，即公钥和私钥，是用来进行非对称加密使用的，服务器端保存着私钥，不能将其泄露，公钥可以发送给任何人； 服务器将自己的公钥包含在权威机构发布的证书中发送给客户端； 客户端收到服务器端的证书之后，会对证书进行检查，验证其合法性，如果发现发现证书有问题，那么HTTPS传输就无法继续。严格的说，这里应该是验证服务器发送的数字证书的合法性，关于客户端如何验证数字证书的合法性。如果公钥合格，那么客户端会生成一个随机值，这个随机值就是用于进行对称加密的密钥，我们将该密钥称之为client key，即客户端密钥，这样在概念上和服务器端的密钥容易进行区分。然后用服务器的公钥对客户端密钥进行非对称加密，这样客户端密钥就变成密文了，至此，HTTPS中的第一次HTTP请求结束； 客户端会发起 HTTPS 中的第二个 HTTP 请求，将被公钥所加密之后的客户端密钥发送给服务器； 服务器接收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密，解密之后的明文就是客户端密钥，然后用客户端密钥对数据进行对称加密，这样数据就变成了密文。 然后服务器用对称加密的密钥（即客户端密钥）对报文进行加密，并将加密后的报文发送给客户端； 客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据。这样 HTTPS 中的第二个 HTTP 请求结束，整个 HTTPS 传输完成。 【TCP/IP】HTTP协议与HTTPS的加密流程 - 周二鸭 - 博客园 (cnblogs.com) SSL/TLS 一篇文章让你彻底弄懂SSL/TLS协议 - 知乎 (zhihu.com) HTTP3.0 HTTP3.0，也称作HTTP over QUIC。 传统的HTTP协议是基于传输层TCP的协议，而QUIC是基于传输层UDP上的协议，可以定义成:HTTP3.0基于UDP的安全可靠的HTTP2.0协议。 了解 HTTP3.0 吗？简要说一下 HTTP 的一个发展历程？_qq60e425252e771的技术博客_51CTO博客 QUIC QUIC协议有以下特点： 基于UDP的传输层协议：减少三次握手的时间延迟。 可靠性：虽然UDP是不可靠传输协议，但是QUIC在UDP的基础上做了些改造，使得他提供了和TCP类似的可靠性。它提供了数据包重传、拥塞控制、调整传输节奏以及其他一些TCP中存在的特性。 实现了无序、并发字节流：QUIC的单个数据流可以保证有序交付，但多个数据流之间可能乱序，这意味着单个数据流的传输是按序的，但是多个数据流中接收方收到的顺序可能与发送方的发送顺序不同！ 快速握手：QUIC提供0-RTT和1-RTT的连接建立 使用TLS 1.3传输层安全协议：与更早的TLS版本相比，TLS 1.3有着很多优点，但使用它的最主要原因是其握手所花费的往返次数更低，从而能降低协议的延迟。 Websocket 背景： 因为 HTTP 协议有一个缺陷：通信只能由客户端发起 我们都知道轮询的效率低，非常浪费资源（因为必须不停连接，或者 HTTP 连接始终打开）, 因此websocket应运而生。 WebSocket用于在Web浏览器和服务器之间进行任意的双向数据传输的一种技术。 Ping 的实现 首先查本地 arp cache 信息，看是否有对方的 mac 地址和 IP 地址映射条目记录 如果没有，则发起一个 arp 请求广播包，等待对方告知具体的 mac 地址 收到 arp 响应包之后，获得某个 IP 对应的具体 mac 地址，有了物理地址之后才可以开始通信了,同时对 ip-mac 地址做一个本地 cache 发出 icmp echo request 包，收到 icmp echo reply 包 代理 反向代理为何叫反向代理？原文 网络安全 网络攻击 DDoS 攻击 XSS攻击 非对称加密 在非对称加密中使用的主要算法有：RSA、Elgamal、Rabin、D-H（Diffie-Hellman）、ECC（椭圆曲线加密算法）等 https https 客户端无法判断自己收到的服务器的公钥是否是正确的，是否在服务器发送给客户端的过程中被第三方篡改了，所以还需要证明公开密钥正确性的数字证书。 https 可以解决中间人劫持？ ssl/tls 了解他们的握手过程 ssh 数字签名，数字证书 浏览器一般怎样校验证书呢？ 了解几个本质：（原文） 解决内容可能被窃听的问题——非对称加密 解决报文可能遭篡改问题——数字签名 解决通信方身份可能被伪装的问题——认证 oauth协议 如果不理解oauth协议的推荐阅读 阮一峰的 理解OAuth 2.0 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Base/数据结构与算法.html":{"url":"Note_Base/数据结构与算法.html","title":"数据结构与算法","keywords":"","body":"《数据结构与算法》 数据结构 数组 前缀和数组 适用于快速、频繁地计算一个索引区间内的元素之和。 差分数组 适用场景是频繁对原始数组的某个区间的元素进行增减。 哈希表 矩阵 链表 反转 判定环 栈与队列 优先队列：堆的应用之一 树 遍历 前、中、后序 递归遍历，非递归遍历 深度遍历(DFS)，广度遍历(BFS) 二叉树 二叉查找树 也叫二叉搜索树，英文 BST (Binary Sort Tree)，要了解一下他们的查找，插入，删除 二叉查找树不保证平衡 自平衡二叉查找树： AVL树 AVL树是高度平衡的二叉树。它的特点是: AVL树中任何节点的两个子树的高度最大差别为1。 红黑树 红黑树的性质: 红黑树是一棵二叉搜索树，它在每个节点增加了一个存储位记录节点的颜色，可以是RED,也可以是BLACK；通过任意一条从根到叶子简单路径上颜色的约束，红黑树保证最长路径不超过最短路径的二倍，因而近似平衡。 具体性质如下: 每个节点颜色不是黑色，就是红色 根节点是黑色的 如果一个节点是红色，那么它的两个子节点就是黑色的(没有连续的红节点) 对于每个节点，从该节点到其后代叶节点的简单路径上，均包含相同数目的黑色节点 查找（一）史上最简单清晰的红黑树讲解 - CSDN 博客 查找（二）简单清晰的 B 树、Trie 树详解 - CSDN 博客 Treap Treap=Tree+Heap，树堆=树+堆 Treap既是一棵二叉查找树，也是一个二叉堆。但是这两种数据结构貌似还是矛盾的存在，如果是二叉查找树，就不能是一个堆，如果是一个堆，那么必然不是二叉查找树。 所以树堆用了一个很巧妙的方式解决这个问题：给每个键值一个随机附加的优先级，让键值满足二叉查找树的结构，让优先级满足二叉堆的结构。 就像下面这个样子：（图片摘自腾讯云） 完全二叉树 每一层都是紧凑靠左排列的 满二叉树 是一种特殊的完全二叉树，每层都是是满的，像一个稳定的三角形 哈夫曼树 Huffman Tree 带权路径长度最短的二叉树，也称为最优二叉树 哈夫曼编码 多路搜索树 B树，B-树 B-tree树 即 B树，是一种多路搜索树 B 树的两个明显特点： 树内的每个节点都存储数据 叶子节点之间无指针相邻 B+树 B+树的两个明显特点 数据只出现在叶子节点 所有叶子节点增加了一个链指针 B+树相比 B 树的优势 单一节点存储更多的元素，使得查询的 IO 次数更少； 所有查询都要查找到叶子节点，查询性能稳定； 所有叶子节点形成有序链表，便于范围查询。 B*树 是 B+树的变体，在 B+树的非根和非叶子结点再增加指向兄弟的指针 2-3树 与 2-3-4树 2-3树中每一个节点都具有两个孩子（我们称它为2节点）或三个孩子（我们称它为3节点）。 字典树 Trie，又称字典树、单词查找树，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。 堆 本质：一个可以被看做一棵完全二叉树的数组 实现：建堆过程，堆的调整 单推问题： 通过一个堆就可以解决的问题 一般这种问题都具有以下特点：求解第/前 k个最大，最小或是最频繁的元素；都可以使用堆来实现 （而不用通过排序实现） 双堆问题： 通过两个堆相互配合解决问题 特点： 被告知，我们拿到一大把可以分成两队的数字。怎么把数字分成两半？使得：小的数字都放在一起，大的放在另外一半。双堆模式就能高效解决此类问题。然后通过小顶堆寻找最小数据，大顶堆寻找堆中最大数据 图 拓扑排序 二分图 并查集 最小生成树 Kruskal：利用 Union-Find 并查集算法向最小生成树中添加边，配合排序的贪心思路，从而得到一棵权重之和最小的生成树。 Prim：切分定理。 比较：Kruskal 算法是在一开始的时候就把所有的边排序，然后从权重最小的边开始挑选属于最小生成树的边，组建最小生成树。Prim 算法是从一个起点的切分（一组横切边）开始执行类似 BFS 算法的逻辑，借助切分定理和优先级队列动态排序的特性，从这个起点「生长」出一棵最小生成树。 最短路径算法 Dijkstra 算法 Bellman-Ford 算法（可处理负权边） Floyd 算法 SPFA 算法 其他 跳跃表 布隆过滤器，位图，hyperloglog 倒排索引 算法 时间/空间复杂度 算法复杂度 多项式时间 一种是 O(1),O(log(n)),O(n^a) 等，我们把它叫做多项式级的复杂度，因为它的规模 n 出现在底数的位置；另一种是 O(a^n) 和 O(n!) 型复杂度，它是非多项式级的。后者的复杂度无论如何都远远大于前者，其复杂度计算机往往不能承受。原文 这里引出几个问题： NP 问题：就是可以（多知项式时间内）短时间内验证一个答案正确性的问题。 NP 完全问题：第一个条件，可以这么说，就是道你如果能解决 A 问题，则通过 A 问题可以解决 B 问题，那么回 A 问题比 B 问题复杂，当所有的问题都可以通过 A 问题的解决而解决的话，那么 A 问题就可以称为 NP 完全问题，第二个条件，就是答 A 问题属于 NP 问题。 排序 插入排序 插入排序的三种实现：直接插入排序，二分查找插入排序，希尔排序。 （1）直接插入排序 时间复杂度：O(n^2) 直接插入排序耗时的操作有：比较+后移赋值。时间复杂度如下： 1) 最好情况：序列是升序排列，在这种情况下，需要进行的比较操作需（n-1）次。后移赋值操作为0次。即O(n) 2) 最坏情况：序列是降序排列，那么此时需要进行的比较共有n(n-1)/2次。后移赋值操作是比较操作的次数加上 (n-1）次。即O(n^2) 空间复杂度：O(1) 稳定性：直接插入排序是稳定的，不会改变相同元素的相对顺序。 优化改进 1) 二分查找插入排序：因为在一个有序区中查找一个插入位置，所以可使用二分查找，减少元素比较次数提高效率。 2) 希尔排序：如果序列本来就是升序或部分元素升序，那么比较+后移赋值操作次数就会减少。希尔排序正是通过分组的办法让部分元素升序再进行整个序列排序。（原因是，当增量值很大时数据项每一趟排序需要的个数很少，但数据项的距离很长。当增量值减小时每一趟需要和动的数据增多，此时已经接近于它们排序后的最终位置。） （2）二分查找插入 直接插入排序的一个变种，区别是：在有序区中查找新元素插入位置时，为了减少元素比较次数提高效率，采用二分查找算法进行插入位置的确定。 时间复杂度 O(n^2)，稳定的 （3）希尔排序 思想：分治策略 希尔排序是一种分组直接插入排序方法，其原理是：先将整个序列分割成若干小的子序列，再分别对子序列进行直接插入排序，使得原来序列成为基本有序。这样通过对较小的序列进行插入排序，然后对基本有序的数列进行插入排序，能够提高插入排序算法的效率。 希尔排序的时间复杂度与增量的选取有关，但是现今仍然没有人能找出希尔排序的精确下界。 平均时间复杂度 O(nlog2n)，不稳定。 选择排序 （1）简单选择排序 每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的 数据元素排完 。 找出序列中的最小关键字，然后将这个元素与序列首端元素交换位置。 （2）堆排序 如何建堆 和调整堆？ 堆排序 | 数据结构与算法 系列教程（笔记） (zq99299.github.io) 排序 - 堆排序(Heap Sort) | Java 全栈知识体系 (pdai.tech) 交换排序 （1）冒泡 比较两个记录键值的大小，如果这两个记录键值的大小出现逆序，则交换这两个记录 缺点：慢，每次只能移动两个相邻的数据 （2）快排 选择基准的方式：固定位置、随机选取基准、三数取中（三种快排） 快排最好最坏的情况？优化方案？ 优化方式： 优化1：当待排序序列的长度分割到一定大小后，使用插入排序 优化2：在一次分割结束后，可以把与Key相等的元素聚在一起，继续下次分割时，不用再对与key相等元素分割 优化3：优化递归操作 优化4：使用并行或多线程处理子序列（略） （了解三路快排、双基准） 快排是二路划分的算法。如果待排序列中重复元素过多，也会大大影响排序的性能。这时候，如果采用三路划分，则会很好的避免这个问题。 扩展： 算法与数据结构 这里给出了双路快排，三路快排，自底向上的归并排序算法等解析 附：关于他双路快排的实现： while ((i left + 1) && (arr[j] > v)) j--; // 使用索引 j 从右往左遍历直到 arr[j] > v 个人认为还可以优化，把相等的情况考虑进去，如下： while ((i left + 1) && (arr[j] >= v)) j--; // 使用索引 j 从右往左遍历直到 arr[j] > v 归并排序 为什么快速排序是不稳定排序，而归并排序是稳定排序呢？ 非比较排序算法 前述几种排序算法都属于“基于比较的排序算法”，它们通过比较元素间的大小来实现排序。此类排序算法的时间复杂度无法超越O(nlogn)。 还有几种“非比较排序算法”，它们的时间复杂度可以达到线性阶： 桶排序，计数排序，基数排序 排序算法比较 时间、空间、稳定性比较 选择排序和冒泡排序的区别 选择排序每次从未排序的部分选取最小（或最大）的元素，然后与未排序部分的第一个元素交换位置，这样逐步形成有序序列。 冒泡排序则是依次比较相邻的元素，如果顺序不对就交换它们的位置，这样逐步将最大（或最小）的元素“冒泡”到末尾。 总体而言，选择排序在每一轮中找到最小元素只进行一次交换，而冒泡排序可能需要多次交换。因此，选择排序通常在实际应用中略优于冒泡排序。 稳定性： 插入、冒泡、归并、基数 排序算法是稳定的。 常用排序算法稳定性-CSDN博客 Java 中是排序算法 Colletions.sort和Arrays.sort分别用了什么排序算法呢 查找 二分搜索 选取mid时，(r + l) / 2 这里的加法可能回产生整型溢出， 解决办法：l + (r - l) / 2 三分搜索 已知函数 𝑓(𝑥) 在区间 [l,r] 上单峰且连续，求 𝑓(𝑥) 在 [l,r] 上的极值。 每次迭代将当前区间的长度缩小 1/3 。 索引，倒排索引 双指针 KPM 算法 阮一峰 字符串匹配的 KMP 算法 补充：这篇博客的数组并不是 next 数组，而是\"部分匹配值\"数组，就是\"前缀\"和\"后缀\"的最长的共有元素的长度 CSDN KMP 算法—终于全部弄懂了 该博客分析了k = next[k]的问题 kpm 算法 - u012361418 的博客 - CSDN 博客 KMP 算法及优化 - 疯狂的爱因斯坦 - SegmentFault 该博客讲解了 KPM 的优化问题 五大常用算法 贪婪（贪心）算法，动态规划算法，分治算法，回溯算法以及分支限界算法 贪心 基本思想：在对问题求解时，总是做出在当前看来是最好的选择（不从整体最优上考虑，只做出在某种意义上的局部最优解）。 它省去了为找最优解要穷尽所有可能而必须耗费的大量时间，它采用自顶向下，以迭代的方法做出相继的贪心选择，每做一次贪心选择就将所求问题简化为一个规模更小的子问题，通过每一步贪心选择，可得到问题的一个最优解，虽然每一步上都要保证能获得局部最优解，但由此产生的全局解有时不一定是最优的，所以贪心算法不要回溯。 动态规划 基本思想：将待求解的问题分解成若干子问题，先求解子问题，然后从这些子问题中得到原问题的解。用分治法不同的是，适用于动态规划法求解的问题，经分解得到子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。 特征： （1）最优子结构：最优子结构性质是指问题的最优解包含其子问题的最优解。 （2）子问题重叠：子问题重叠是指在求解子问题的过程中，有大量的子问题是重复的。 （3）无后效性：当前阶段的求解只和前面阶段有关，和后续阶段无关，称为“无后效性”。 三要素： 状态转移方程、最优子结构、最优子结构 常见问题： 常见动态规划问题总结 最长公共子序列与最长公共子串 (DP) 最长递增子序列 解法 1：最长公共子序列法 解法 2：动态规划法（时间复杂度 O(N^2)) dp[i] 表示以标识为 i 的元素为递增序列结尾元素的最长递增子序列的长度 解法 3：O(NlgN）算法 b[i] 只是存储的对应长度为 i 的 LIS 的最小末尾 最长公共子序列 用 dp[i][j] 来表示 A 串中的前 i 个字符与 B 串中的前 j 个字符的最长公共子序列长度 最长公共子串 这个问题与上面的问题类似，区别点在于这里是子串，是连续的，令 dp[i][j] 表示 A 串中的以第 i - 1 个字符与 B 串中的以第 j - 1 个字符结尾的最长公共子串的长度 最小编辑代价问题 首先令 dp[i][j] 表示将 A 串中的前 i 个字符转换成 B 串中的前 j 个字符所需要的代价 0-1背包问题 分治 基本思想：与动态规划法类似，将待求解的问题分解成若干子问题，求出子问题的解，合并之后即为原问题的解。不同的是：这些子问题是相互独立的，且与原问题的性质相同。（可用分治法解决的问题常常采用递归的形式求解）。 解题步骤： （1）分解：将要解决的问题分解为若干个规模较小、相互独立、与原问题形式相同的子问题。 （2）治理：求解各个子问题，由于各个子问题与原问题形式相同，只是规模较小而已，而当子问题规划的足够小时，就可以用较简单的方法解决。 （3）合并：按照原问题的要求，将子问题的解合并为原问题的解。 常见问题： 二分搜索 分治法的经典问题——大整数相乘 归并派系 快速排序 回溯 基本思想：回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。当搜索到某一步时发现不满足条件，即进行回溯（退回上一步重新进行选择），直到搜索完整个空间。 简单易懂的回溯算法（Back Tracking) - cometwo的个人空间 - OSCHINA - 中文开源技术交流社区 深度优先搜索算法 八皇后问题 分支限界法 基本思想：求解目标为找出满足约束条件的一个解，或是在满足约束条件的解中找出在某种意义下的最优解，常使用广度优先搜索算法。 常用的两种分支限界法： （1）队列式分支限界法 （2）优先队列式分支限界法 FIFO搜索，LIFO搜索 思想 递归 斐波那契数列，其时间复杂度和空间复杂度 递推 动态规划就是递推的思想 算法洗脑系列（8 篇）——第一篇 递推思想 - 一线码农 - 博客园 启发式算法 遗传算法（GA） A* 算法（可拓展了解下 Navmesh） 算法题 经典题目 经典问题之字符串 Top K 问题 面试必备 | 不可不会的反转链表 最大公共子串 看一遍就理解：动态规划详解 青蛙跳阶问题：递归时的重复计算问题 递增子序列：看一下解题思路：穷举分析，确定边界，找规律，确定状态转移方程 有意思的题目 摩尔投票法 面试题 17.10. 主要元素 求众数 II GCD，它通常表示最大公约数（greatest common divisor） 欧几里德算法又称辗转相除法，是指用于计算两个正整数a，b的最大公约数。应用领域有数学和计算机两个方面。计算公式gcd(a,b) = gcd(b,a mod b)。 海量数据处理 advanced-java/docs/big-data 链接 参考链接 代码随想录 (programmercarl.com) labuladong 的算法笔记 | labuladong 的算法笔记 Hello 算法 (hello-algo.com) 练习平台 CS-Notes 剑指 Offer LeetCode 牛客笔试面试题库 书单 《漫画算法：小灰的算法之旅》 《 算法导论 》 《 算法 ( 第4版 ) 》 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Plus/游戏服务端.html":{"url":"Note_Plus/游戏服务端.html","title":"游戏服务端","keywords":"","body":"《游戏服务端》 服务端底层架构 设计/目标 高性能，高并发 高可用，可扩展，快速伸缩 网络 网络协议 TCP 启用和禁用TCP_NODELAY有什么影响？ UDP 可靠 UDP 的实现： KCP FEC（牺牲带宽换取效率） kcp + fec 自适应模块 丢包探测 grp协议 开关 RS编码，又称里所码，即Reed-solomon codes 协议选择 TCP (传输控制协议) 优点： 可靠性：TCP 通过重传机制和校验机制保证数据传输的可靠性，适用于需要确保数据完整性的场景。 流量控制：TCP 通过流量控制机制可以保证数据传输的平稳性，避免网络拥塞。 缺点： 延迟：TCP 需要建立连接和进行拥塞控制，因此在高延迟的网络环境下可能会导致较大的延迟。 开销：TCP 的头部较大，会增加数据传输的开销。 UDP (用户数据报协议) 优点： 低延迟：UDP 不需要建立连接和进行拥塞控制，因此在高延迟的网络环境下具有较低的延迟。 快速：UDP 的头部较小，传输效率较高。 缺点： 不可靠：UDP 不具备数据重传和校验机制，数据传输不可靠，容易丢包。 拥塞控制：UDP 不具备拥塞控制机制，可能导致网络拥塞。 KCP (可靠UDP协议) 优点： 适应性：KCP 可以根据网络状况自适应调整传输参数，适应不同的网络环境。 快速可靠：KCP 基于UDP，具有快速可靠的传输性能，适用于高延迟、丢包率较高的网络环境。 缺点： 复杂性：KCP 的参数配置和调优相对复杂，需要花费一定的精力进行优化。 在实际应用中，根据游戏的特性和网络环境的不同，选择合适的协议选项至关重要。 TCP 适用于需要可靠性和稳定性的场景，UDP 适用于对实时性要求较高的场景，而 KCP 则适用于高延迟、丢包率较高的网络环境下的场景。 TCP 可调整初始拥塞窗口大小、重传超时时间等参数。 KCP 可调整发送窗口和接收窗口大小、超时重传时间、tick间隔等参数。 需要根据实际情况选取有限的取值范围与分级。 冗余编码 XOR（异或）：异或是一种逻辑运算，用于比较两个数位。在数据编码中，XOR通常用于数据加密、校验和错误检测等。在某些纠错编码方案中也会用到XOR运算。只能产生一份冗余。 DUP（重复编码）：重复编码是一种简单的冗余编码方式，它通过重复发送相同的数据，来增强数据的可靠性。在接收端，多个副本的数据可以用于检测并纠正错误。 RS（Reed-Solomon）：Reed-Solomon编码是一种前向纠错的编码方式，通常用于光盘、磁盘等存储介质中。它具有较强的纠错能力，可以同时纠正多个错误。可以产生任意份冗余。 尝试使用不同的编码，不同的冗余分数。需要根据实际情况选取有限的范围与分级。 信道 丢包率 延时 带宽 单位时间通过的数据量 应用层协议 Json，MessagePack (msgpack) ProtoBuf msgpack的序列化速度比protobuf要快一些，但反序列化要比protobuf要慢一些，但总体都接近 字节压缩 deflate deflate算法就是基于LZ77算法和Huffman编码基础上实现的。 可以指定算法 的压缩级别，这样你可以在压缩时间和输出文件大小上进行平衡。可选的级别有0（不压缩），以及1(快速压缩)到9（慢速压缩）。 deflate是zip压缩文件的默认算法。其实deflate现在不光用在zip文件中，在7z、xz等其他的压缩文件中都用。 gzip 当键入 tar -zcf src.tar.gz src 时，就可以将 src 下的所有文件打包成一个 tar.gz 格式的压缩包。这里的 “tar” 是归档格式，将多个文件组合成一个文件；而 “gz” 指的就是 gzip 压缩格式，使用 deflate 算法压缩得到。 deflate 是最基础的算法，gzip 在 deflate 的 raw data 前增加了 10 个字节的 gzheader，尾部添加了 8 个字节的校验字节（可选 crc32 和 adler32） 和长度标识字节。 Snappy snappy是google基于LZ77的思路编写的快速数据压缩与解压程序库。它的目标并非最大压缩率或与其他压缩程序库的兼容性，而是非常高的速度和合理的压缩率。 负载 性能记录：对各个请求响应时间进行统计记录。如：最大时长、最小时长、平局时长 性能分析 性能优化：分布式、多进程、分离模块 并发 并发异步操作。 问题： 如访问数据库，会有读写数据时序问题。 一次执行一个事务/任务，避免IO读写的交叉使用。 无锁编程 游戏无锁多线程原理 - 知乎 (zhihu.com) 数据库 连接池 MySQL 索引 Redis ORM和SQL 持久化 配表数据 候选架构 Akka Actor 模型 akka 设计模式系列-基础模式 skynet LuaAPI · cloudwu/skynet Wiki (github.com) skynet源码赏析 (manistein.github.io) skynet教程（1）--服务的编写 - 简书 (jianshu.com) Pinus 其他参考 MMORPG服务器架构 - I want to fly higher - BlogJava 高性能分布式游戏服务器框架_剑心！的博客-CSDN 算力分摊 分摊给其他进程、或者客户端（客服端怪、单人副本） Actor 模型 轻量级进程+分布式计算+基于消息 ECS 结构 Entity-Component-System（实体-组件-系统） 压测 robot 游戏服务器压测机器人工具-服务端和客户端实现： zhou-hj/GameServerRobot: 游戏服务器压测机器人工具-服务端和客户端实现 (github.com) 建立基准、监控 服务端源码学习 hstcscolor / awesome-gameserver-cn 中文游戏服务器资源大全 ARPG 永恒之塔开源服务器架构 https://github.com/Aion-server/Aion-unique 天堂 2 l2jserver2 https://github.com/oonym/l2InterludeServer https://github.com/Rogiel/l2jserver2 魔兽世界 server TrinityCore https://github.com/TrinityCore/TrinityCore tinyHeart https://github.com/luckykun/tinyHeart 业务架构 登录服/账号服 登录 支付，支付后通知游戏服发放物资 游戏服 管理玩家角色，处理游戏逻辑 管理服 监控并管理各个服务器，动态扩容、查看状态。 配置服 管理各个服务器的配置 所有服务器从这里获取自己所需的配置 日志服 记录各个服务器上报的日志。 网络同步 关键词：AOI，状态同步，帧同步，混合同步 状态同步 说明： 发指令，收状态 客户端发送指令给服务器，服务器处理后返回结果（状态） 帧同步 驱动帧模式 传统模式，即客户端上传指令，服务端转发后才能生效的模式。此模式主要适用于操作连贯、写实的游戏中，例如足球等。 预测回滚模式，即客户端本地立即执行指令，再上传指令到服务端，发现不同步后再回滚的模式。此模式主要适用于有效输入频率较少、动作可不连贯、不太写实的游戏中，例如拳皇等。 外部输入模式，即驱动帧由外部提供，客户端被动执行的模式。此模式常用在直播需求中，例如足球比赛的全网直播等。 相关算法 帧锁定同步算法 帧锁定同步算法 - Skywind Inside 早期 RTS，XBOX360 LIVE游戏常用同步策略是什么？格斗游戏多人联机如何保证流畅性和一致性？如何才能像单机游戏一样编写网游？ 算法概念 该算法普遍要求网速RTT要在100ms以内，一般人数不超过8人，在这样的情况下，可以像单机游戏一样编写网络游戏。所有客户端任意时刻逻辑都是统一的，缺点是一个人卡机，所有人等待。 客户端定时（比如每五帧）上传控制信息。 服务器收到所有控制信息后广播给所有客户。 客户端用服务器发来的更新消息中的控制信息进行游戏。 如果客户端进行到下一个关键帧（5帧后）时没有收到服务器的更新消息则等待。 如果客户端进行到下一个关键帧时已经接收到了服务器的更新消息，则将上面的数据用于游戏，并采集当前鼠标键盘输入发送给服务器，同时继续进行下去。 服务端采集到所有数据后再次发送下一个关键帧更新消息。 这个等待关键帧更新数据的过程称为“帧锁定” 应用案例：大部分RTS游戏，街霸II(xbox360)，Callus模拟器。 预测回滚的帧同步 简单来介绍下这种同步机制： 假设游戏运行时帧率为 60 帧，每帧用时 16 ms。 每个客户端不阻塞等待远端输入 每一帧在拿到本地输入后，如果远端输入还没有达到本地，则猜测这次的远端输入与上一次一样，用猜测的远端输入+本地输入更新游戏状态，继续进行游戏 当收到某帧的远端收入后，对比历史中对该帧的输入猜测和实际输入是否一样 注意接下来的所有步骤都在一帧的物理时间（16ms）内处理完，下面步骤的帧都是逻辑意义上的帧 不一样的话将本地客户端的游戏状态回滚到输入不一样的帧的上一帧 Frame 1 利用真实的远端输入和本地的历史输入重新追算出来当前帧 Frame N的游戏状态（Frame N 和 Frame 1 之间可能会差几帧，即需要重新计算多个逻辑帧的状态变化） 相当于坐上时光机，重回历史，改变历史，回到新的现在（这一切都是命运石之门的选择） 基于错误的预测输入可能渲染多余的画面/音频，需要把这些清理干净 基于新的游戏状态重新渲染出来正确的游戏画面/音频 问题 一致性保证 解决浮点数计算误差的问题 可使用 fixmath 库，该库使用整数类型代替浮点数（不过使用 Fix16 类型是否会精度不够？扩展为 Fix32?） 解决随机数一致性问题 可使用用基于定点数的 Wichmann Hill 算法 解决物理计算误差问题 可用基于定点数的Box2D 逻辑调用的一致性问题 严格时序，并提供基于帧号的定点数timer，其实现方式类似于时间轮 存在网络延迟时，客户端没收到服务端数据时怎么办 客户端预测、插值、缓存池、不一致回退等方式。 大部分帧同步都不会进行逻辑预测，只会进行表现预测，比如模型先往前走，逻辑位置数据保持原地，网络延迟卡顿会等待帧数据的到来。 如何防作弊 服务端运行和客户端一样或核心逻辑，对于关键数据进行同步验证比对；或是战斗结束后对指令进行快速播放校验。但无法避免客户端利用所有玩家信息的全图挂。 客户端之间的比对校验，环境相同，结果不一样的客户端是异常的。 战局回放和举报机制，帧同步的回放实现很容易，让玩家举报玩家也是一种好办法。 基础 解决快照生成、校验、现场恢复等问题 动态调整帧率和倍速，动态可调节，状态可自动记录。 提供暂停和软暂停功能，适应多种使用场景。 拓展 属性 定期为场景和各个logic_entity的属性生成快照并序列化，然后将快照md5上传至Server进行对比，若发现快照不一致，将使用验证端最新的快照作为标准进行现场恢复。 AI计算分配 对于帧同步的游戏而言，AI的工作通常由各个客户端自己完成行为树，状态机的计算，无需通过服务端计算和命令收发。但如果客户端需要计算的AI比较多，计算复杂度又比较高，这时由客户端完成所有AI的策略计算，AI的开销对于性能不佳的机器而言就是不小的负担了。 在这种情况下，如果在客户端≥2个，就可以对AI的计算工作进行分配，每个客户端负责一定数量的AI计算，并通过帧命令的方式 (与普通玩家操作相似) 确保AI的行为一致。 考虑参数：客户端基数、客户端性能、客户端网络、客户端断线 网络延迟处理 无论是状态同步还是帧同步，由于网络延迟、网络波动，客户端需要对位置数据进行预测，避免移动卡顿。 同步技术 插值，预测，校正 同步内容 物理（位置，旋转，速度），动画，特效，碰撞 案例 移动同步 摇杆同步和坐标同步： 摇杆同步 坐标同步 移动延迟 低 高 消息流程 摇杆移动->服务端收到摇杆信息进行广播->客户端收到摇杆消息开始移动 摇杆移动->服务端收到摇杆信息->服务端对象移动->客户端收到坐标开始移动 网络波动/丢包表现 好，人物可以进行相对流畅的移动表现 差，网络包间隔不均匀会导致人物移动也变得卡顿感很重 位置误差 差，可能会产生累积误差，需要进行额外的校正 基本无误差 做加法？服务端向客户端发送的不在是摇杆信息，而是坐标和摇杆的组合信息。 AOI Area Of Interest，兴趣区域 数据结构和算法： 四叉树、灯塔法、九宫格、十字链表法 AOI分层运算 应用： 玩家交互、动态对象的移动、NPC的行为 AI 状态机 行为树 入门 Java游戏服务器开发之行为树_cmqwan的博客-CSDN zzwzfy/GameAI-BehaviorTree: GameAI-BehaviorTree My Impelement (github.com) 事件行为树 寻路 A* 及其变种算法 路径规划之 A* 算法 - 知乎 (zhihu.com) JPS 参考： 《2018腾讯移动游戏技术评审标准与实践案例》：寻路算法 JPS 优化章节 「游戏」寻路算法之JPS原理和实现_Echo-CSDN博客 JPS（Jump Point Search）寻路及实现代码分析_燕临江下的蛋-CSDN博客 [算法]小学堂：JPS寻路算法浅析 - 知乎 (zhihu.com) NavMesh 介绍： 游戏的寻路导航 1：导航网格 - 简书 (jianshu.com) NavMesh 生成原理： 导航网格的生成会分为下面几个步骤： 场景模型体素化（Voxelization），或者叫“栅格化”（Rasterization） 过滤出可行走面（Walkable Suface） 生成 Region 生成 Contour（边缘） 生成 Poly Mesh 生成 Detailed Mesh Github： recastnavigation/recastnavigation: Industry-standard navigation-mesh toolset for games (github.com) ppiastucki/recast4j: Java Port of Recast & Detour navigation mesh toolset (github.com) 源码解析： recast navigation navmesh 导航网格 寻路算法 源码分析_飞天大蟾蜍的博客-CSDN博客 寻路_长三月的游戏开发-CSDN博客 detour 寻路核心逻辑 CrowdToolState::updateTick dtCrowd::update_只要你在的博客-CSDN博客 参考： 《腾讯游戏开发精粹》：第5章 3D游戏碰撞之体素内存、效率优化 NMGen Study 项目，NMGen研究是Java中 Recast静态网格 功能的改编，用于研究和实验目的。 抗锯齿 A* 上： 延长寻路目标 a* 增加拐角代价函数 物理引擎 碰撞检测 碰撞检测的向量实现 - 掘金 (juejin.cn) (这里面的参考链接也可以看看) 物理引擎 - 知乎 (zhihu.com) 包围盒 BVH（Bounding Volume Hierarchies 层次包围盒） 通常简单的物体比较容易检查相互之间的重叠（也就是碰撞），也常应用于光线跟踪中。 游戏引擎 Unity3d 愤怒的小鸟 https://www.bilibili.com/video/av35565116/ 工具 弱网环境 Clumsy 游戏安全 Limit 限流 RPCLimit 权限 GM权限，分等级，重要等级需要邮箱验证码 参考 游戏安全实验室 “黑客”深度学习之“游戏外挂原理与实现” 游戏门户 GameRes 游资网-游戏开发者门户 游戏学院 - 腾讯大学 思考 你为什么会离开游戏行业？ - Skywind Inside 书单 2018腾讯移动游戏 技术评审标准与实践案例 《腾讯游戏开发精粹》 《腾讯游戏开发精粹Ⅱ》 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Plus/图形学.html":{"url":"Note_Plus/图形学.html","title":"图形学","keywords":"","body":"《图形学》 OpenGL OpenGL学习_AkagiSenpai的博客-CSDN博客 主页 - LearnOpenGL CN (learnopengl-cn.github.io) 图形学 图形学_AkagiSenpai的博客-CSDN博客 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Plus/数学.html":{"url":"Note_Plus/数学.html","title":"数学","keywords":"","body":"《数学》 向量 向量点乘（点积，数量积） 公式： a·b = a.x * b.x + a.y * a.y = |a||b|cosα (以二维向量为例，三维向量公式同理) 也就是说两个向量的点积等同于两个向量的模（向量的长度）相乘，在乘以两个向量的夹角α的cos值（两个向量的夹角永远是最小的那个夹角，即α 当我们要求两个向量的夹角的时候，可以先让向量a，b单位化（即让a，b的长度等于1）则 |a||b|cosα = 1 * 1 * cosα = cosα 然后我们利用反三角函数，即可以求出α（也就是两个向量的夹角） α = arccos(a·b) (注意向量a，b单位化) 向量叉乘（叉积，向量积） 向量的叉乘，即求同时垂直两个向量的向量，即c垂直于a，同时c垂直于b（a与c的夹角为90°，b与c的夹角为90°） c = a×b = (a.y*b.z - b.y*a.z, b.x*a.z - a.x*b.z, a.x*b.y - b.x*a.y) 以上图为例a(1,0,0), b(0,1,0), c=a×b = (0,0,1) 叉乘的几何意义： |c| = |a×b| = |a||b|sinα （α为a，b向量之间的夹角） |c| = a,b向量构成的平行四边形的面积 （如下图所示的平行四边形） 叉乘的拓展： 在一般的常识或者教科书中规定叉乘只有3d才拥有，其实2d也可以拓展出来一个叉乘形式，而且非常有用。 拓展方式：假设有两个2d向量a,b，我们直接把他们视为3d向量，z轴补0，那么这个时候的a，b向量的叉乘结果c： c.x = 0, c.y = 0, c.z = a.x*b.y - b.x*a.y 这个时候可以吧2d的叉乘值定义为得到一个值，而不是得到一个向量，那么这个值k k = c.z = a.x*b.y - b.x*a.y 我们可以通过这个k值得到很多有用的性质 a，b向量构成的平行四边形的面积。 如果 k > 0 时，那么a正旋转到b的角度为180°,如果k=0 那么a，b向量平行。 ps：正旋转的定义参考 数学基础 —— 旋转（2D 正旋转） 参考 keng_s的博客 余弦定理 余弦定理，欧氏平面几何学基本定理。余弦定理是描述三角形中三边长度与一个角的余弦值关係的数学定理，是勾股定理在一般三角形情形下的推广，勾股定理是余弦定理的特例。 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Plus/人工智障.html":{"url":"Note_Plus/人工智障.html","title":"人工智障","keywords":"","body":"《人工智障》 大数据 ODPS离线分析 Hive Spark Hadoop Hbase HDFS 大数据体系 Flink入门教程 深度学习 神经网络 1.1.1 什么是神经网络 - 床长人工智能教程 (captainbed.net) 机器学习与深度学习 tensorflow 区块链 TODO Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Plus/资料收藏.html":{"url":"Note_Plus/资料收藏.html","title":"资料收藏","keywords":"","body":"《资料整理》 收藏从未停止， 学习从未开始。 Github 技术图谱 AobingJava / JavaFamily 【互联网一线大厂面试+学习指南】进阶知识完全扫盲：涵盖高并发、分布式、高可用、微服务等领域知识，作者风格幽默，看起来津津有味，把学习当做一种乐趣，何乐而不为，后端同学必看 附其 CSDN 博客（《吊打面试官》系列）：https://me.csdn.net/qq_35190492 CyC2018 / CS-Notes 144k star！📚 技术面试必备基础知识、Leetcode、计算机操作系统、计算机网络、系统设计 Snailclimb / JavaGuide 115k star！【Java 学习+面试指南】 一份涵盖大部分 Java 程序员所需要掌握的核心知识。 Issue 资料整理 · Issue #18 · wtysos11/blogWiki (github.com) 知识扩展（收藏起来先） jobbole / awesome-java-cn Java 资源大全中文版，包括开发库、开发工具、网站、博客、微信、微博等，由伯乐在线持续更新。 同时他还有 jobbole / awesome-python-cn，jobbole / awesome-cpp-cn xingshaocheng / architect-awesome 后端架构师技术图谱 521xueweihan / HelloGitHub 分享 github 上有趣、入门级的开源项目 doocs / advanced-java 涵盖高并发、分布式、高可用、微服务、海量数据处理等领域知识 github-cn github 中文社区资料推荐，确实是不容错过的好东西。 知识体系 Java： Java 全栈知识体系 (pdai.tech) Java工程师成神之路 (gitee.io) 网络、操作系统、数据库 小林coding (xiaolincoding.com) 算法： labuladong 的算法笔记 代码随想录 (programmercarl.com) 文章摘抄： 技术文章摘抄，以后端技术的广度来说真的是挺夸张的，有很多极客时间的文章。 技术团队 美团技术团队 有赞团队 虫洞栈，京东架构师博客，包括设计模式、Springboot和Netty等源码知识 小米信息部技术团队 博主 阮一峰的网络日志 (ruanyifeng.com) 廖雪峰的官方网站 (liaoxuefeng.com) 漫话编程的博客_CSDN博客-领域博主 Zacard's Notes 克鲁斯卡尔的博客 (novoland.github.io) EnjoyMoving 文章收藏 职场 如何入职心仪的游戏公司？ 游戏策划从入门到入行 这17件小事儿都做好，春招保你拿Offer！ 我的求职经历——遍览国内一流IT企业(转） - lonelycatcher - 博客园 (cnblogs.com) 年度报告 SegmentFault 年度内容盘点 - 2016 其他 究竟怎样写代码才算是好代码 - CSDN 博客 成为 Java 顶尖程序员 ，看这 11 本书就够了 - CSDN 博客 简历 简历模板 - 代码随想录 (programmercarl.com) Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Excerpt/加密算法.html":{"url":"Note_Excerpt/加密算法.html","title":"加密算法","keywords":"","body":"加密算法 说到密码，我们第一个想到的就是登陆账户的密码，但是从密码学的角度来看，这种根本就不算合格的密码。 为什么呢，因为我们的账户密码，是依靠隐蔽性来达到加密作用：密码藏在我心里，你不知道，所以你登不上我的账户。 然而密码技术认为，「保密」信息总有一天会被扒出来，所以加密算法不应该依靠「保密」来保证机密性，而应该做到：即便知道了加密算法，依然无计可施。说的魔幻一点就是，告诉你我的密码，你依然不知道我的密码。 最玄学的就是 Diffie-Hellman 密钥交换算法，我当初就觉得很惊奇，两个人当着你的面互相报几个数字，他们就可以拥有一个共同的秘密，而你却根本不可能算出来这个秘密。下文会着重介绍一下这个算法。 本文讨论的密码技术要解决的主要是信息传输中的加密和解密问题。要假设数据传输过程是不安全的，所有信息都在被窃听的，所以发送端要把信息加密，接收方收到信息之后，肯定得知道如何解密。有意思的是，如果你能够让接收者知道如何解密，那么窃听者不是也能够知道如何解密了吗？ 下面，我们会介绍对称加密算法、密钥交换算法、非对称加密算法、数字签名、公钥证书，看看解决安全传输问题的一路坎坷波折。 一、对称性加密 对称性密码，也叫共享密钥密码，顾名思义，这种加密方式用相同的密钥进行加密和解密。 比如我说一种最简单的对称加密的方法。首先我们知道信息都可以表示成 0/1 比特序列，也知道相同的两个比特序列做异或运算的结果为 0。 那么我们就可以生成一个长度和原始信息一样的随机比特序列作为密钥，然后用它对原始信息做异或运算，就生成了密文。反之，再用该密钥对密文做一次异或运算，就可以恢复原始信息。 这是一个简单例子，不过有些过于简单，有很多问题。比如密钥的长度和原始信息完全一致，如果原始信息很大，密钥也会一样大，而且生成大量真随机比特序列的计算开销也比较大。 当然，有很多更复杂优秀的对称加密算法解决了这些问题，比如 Rijndael 算法、三重 DES 算法等等。它们从算法上是无懈可击的，也就是拥有巨大的密钥空间，基本无法暴力破解，而且加密过程相对快速。 但是，一切对称加密算法的软肋在于密钥的配送。加密和解密用同一个密钥，发送方必须设法把密钥发送给接收方。如果窃听者有能力窃取密文，肯定也可以窃取密钥，那么再无懈可击的算法依然不攻自破。 所以，下面介绍两种解决密钥配送问题最常见的算法，分别是 Diffie-Hellman 密钥交换算法和非对称加密算法。 二、密钥交换算法 我们所说的密钥一般就是一个很大的数字，算法用这个数加密、解密。问题在于，信道是不安全的，所有发出的数据都会被窃取。换句话说，有没有一种办法，能够让两个人在众目睽睽之下，光明正大地交换一个秘密，把对称性密钥安全地送到接收方的手中？ Diffie-Hellman 密钥交换算法可以做到。准确的说，该算法并不是把一个秘密安全地「送给」对方，而是通过一些共享的数字，双方「心中」各自「生成」了一个相同的秘密，而且双方的这个秘密，是第三方窃听者无法生成的。 也许这就是传说中的心有灵犀一点通吧。 这个算法规则不算复杂，你甚至都可以找个朋友尝试一下共享秘密，等会我会简单画出它的基本流程。在此之前，需要明确一个问题：并不是所有运算都有逆运算。 最简单的例子就是我们熟知的单向散列函数，给一个数字 a 和一个散列函数 f，你可以很快计算出 f(a)，但是如果给你 f(a) 和 f，推出 a 是一件基本做不到的事。密钥交换算法之所以看起来如此玄幻，就是利用了这种不可逆的性质。 下面，看下密钥交换算法的流程是什么，按照命名惯例，准备执行密钥交换算法的双方称为 Alice 和 Bob，在网络中企图窃取他俩通信内容的坏人称为 Hack 吧。 首先，Alice 和 Bob 协商出两个数字 N 和 G 作为生成元，当然协商过程可以被窃听者 Hack 窃取，所以我把这两个数画到中间，代表三方都知道： 现在 Alice 和 Bob 心中各自想一个数字出来，分别称为 A 和 B 吧： 现在 Alice 将自己心里的这个数字 A 和 G 通过某些运算得出一个数 AG，然后发给 Bob；Bob 将自己心里的数 B 和 G 通过相同的运算得出一个数 BG，然后发给 Alice： 现在的情况变成这样了： 注意，类似刚才举的散列函数的例子，知道 AG 和 G，并不能反推出 A 是多少，BG 同理。 那么，Alice 可以通过 BG 和自己的 A 通过某些运算得到一个数 ABG，Bob 也可以通过 AG 和自己的 B 通过某些运算得到 ABG，这个数就是 Alice 和 Bob 共有的秘密。 而对于 Hack，可以窃取传输过程中的 G，AG，BG，但是由于计算不可逆，怎么都无法结合出 ABG 这个数字。 以上就是基本流程，至于具体的数字取值是有讲究的，运算方法在百度上很容易找到，限于篇幅我就不具体写了。 该算法可以在第三者窃听的前提下，算出一个别人无法算出的秘密作为对称性加密算法的密钥，开始对称加密的通信。 对于该算法，Hack 又想到一种破解方法，不是窃听 Alice 和 Bob 的通信数据，而是直接同时冒充 Alice 和 Bob 的身份，也就是我们说的「中间人攻击」： 这样，双方根本无法察觉在和 Hack 共享秘密，后果就是 Hack 可以解密甚至修改数据。 可见，密钥交换算法也不算完全解决了密钥配送问题，缺陷在于无法核实对方身份。所以密钥交换算法之前一般要核实对方身份，比如使用数字签名。 三、非对称加密 非对称加密的思路就是，干脆别偷偷摸摸传输密钥了，我把加密密钥和解密密钥分开，公钥用于加密，私钥用于解密。只把公钥传送给对方，然后对方开始给我发送加密的数据，我用私钥就可以解密。至于窃听者，拿到公钥和加密数据也没用，因为只有我手上的私钥才能解密。 可以这样想，私钥是钥匙，而公钥是锁，可以把锁公开出去，让别人把数据锁起来发给我；而钥匙一定要留在自己手里，用于解锁。我们常见的 RSA 算法就是典型的非对称加密算法，具体实现比较复杂，我就不写了，网上很多资料。 在实际应用中，非对称性加密的运算速度要比对称性加密慢很多的，所以传输大量数据时，一般不会用公钥直接加密数据，而是加密对称性加密的密钥，传输给对方，然后双方使用对称性加密算法传输数据。 需要注意的是，类似 Diffie-Hellman 算法，非对称加密算法也无法确定通信双方的身份，依然会遭到中间人攻击。比如 Hack 拦截 Bob 发出的公钥，然后冒充 Bob 的身份给 Alice 发送自己的公钥，那么不知情的 Alice 就会把私密数据用 Hack 的公钥加密，Hack 可以通过私钥解密窃取。 那么，Diffie-Hellman 算法和 RSA 非对称加密算法都可以一定程度上解决密钥配送的问题，也具有相同的缺陷，二者的应用场景有什么区别呢？ 简单来说，根据两种算法的基本原理就可以看出来： 如果双方有一个对称加密方案，希望加密通信，而且不能让别人得到钥匙，那么可以使用 Diffie-Hellman 算法交换密钥。 如果你希望任何人都可以对信息加密，而只有你能够解密，那么就使用 RSA 非对称加密算法，公布公钥。 下面，我们尝试着解决认证发送方身份的问题。 四、数字签名 刚才说非对称加密，把公钥公开用于他人对数据加密然后发给你，只有用你手上对应的私钥才能将密文解密。其实，私钥也可用用来加密数据的，对于 RSA 算法，私钥加密的数据只有公钥才能解开。 数字签名也是利用了非对称性密钥的特性，但是和公钥加密完全颠倒过来：仍然公布公钥，但是用你的私钥加密数据，然后把加密的数据公布出去，这就是数字签名。 你可能问，这有什么用，公钥可以解开私钥加密，我还加密发出去，不是多此一举吗？ 是的，但是数字签名的作用本来就不是保证数据的机密性，而是证明你的身份，证明这些数据确实是由你本人发出的。 你想想，你的私钥加密的数据，只有你的公钥才能解开，那么如果一份加密数据能够被你的公钥解开，不就说明这份数据是你（私钥持有者）本人发布的吗？ 当然，加密数据仅仅是一个签名，签名应该和数据一同发出，具体流程应该是： 1、Bob 生成公钥和私钥，然后把公钥公布出去，私钥自己保留。 2、用私钥加密数据作为签名，然后将数据附带着签名一同发布出去。 3、Alice 收到数据和签名，需要检查此份数据是否是 Bob 所发出，于是用 Bob 之前发出的公钥尝试解密签名，将收到的数据和签名解密后的结果作对比，如果完全相同，说明数据没被篡改，且确实由 Bob 发出。 为什么 Alice 这么肯定呢，毕竟数据和签名是两部分，都可以被掉包呀？原因如下： 1、如果有人修改了数据，那么 Alice 解密签名之后，对比发现二者不一致，察觉出异常。 2、如果有人替换了签名，那么 Alice 用 Bob 的公钥只能解出一串乱码，显然和数据不一致。 3、也许有人企图修改数据，然后将修改之后的数据制成签名，使得 Alice 的对比无法发现不一致；但是一旦解开签名，就不可能再重新生成 Bob 的签名了，因为没有 Bob 的私钥。 综上，数字签名可以一定程度上认证数据的来源。之所以说是一定程度上，是因为这种方式依然可能受到中间人攻击。一旦涉及公钥的发布，接收方就可能收到中间人的假公钥，进行错误的认证，这个问题始终避免不了。 说来可笑，数字签名就是验证对方身份的一种方式，但是前提是对方的身份必须是真的... 这似乎陷入一个先有鸡还是先有蛋的死循环，要想确定对方的身份，必须有一个信任的源头，否则的话，再多的流程也只是在转移问题，而不是真正解决问题。 五、公钥证书 证书其实就是公钥 + 签名，由第三方认证机构颁发。引入可信任的第三方，是终结信任循环的一种可行方案。 证书认证的流程大致如下： 1、Bob 去可信任的认证机构证实本人真实身份，并提供自己的公钥。 2、Alice 想跟 Bob 通信，首先向认证机构请求 Bob 的公钥，认证机构会把一张证书（Bob 的公钥以及自己对其公钥的签名）发送给 Alice。 3、Alice 检查签名，确定该公钥确实由这家认证机构发送，中途未被篡改。 4、Alice 通过这个公钥加密数据，开始和 Bob 通信。 注 以上只是为了说明，证书只需要安装一次，并不需要每次都向认证机构请求；一般是服务器直接给客户端发送证书，而不是认证机构。 也许有人问，Alice 要想通过数字签名确定证书的有效性，前提是要有该机构的（认证）公钥，这不是又回到刚才的死循环了吗？ 我们安装的正规浏览器中都预存了正规认证机构的证书（包含其公钥），用于确认机构身份，所以说证书的认证是可信的。 Bob 向机构提供公钥的过程中，需要提供很多个人信息进行身份验证，比较严格，所以说也算是可靠的。 获得了 Bob 的可信公钥，Alice 和 Bob 之间的通信基于加密算法的保护，是完全无懈可击的。 现在的正规网站，大都使用 HTTPS 协议，就是在 HTTP 协议和 TCP 协议之间加了一个 SSL/TLS 安全层。在你的浏览器和网站服务器完成 TCP 握手后，SSL 协议层也会进行 SSL 握手交换安全参数，其中就包含该网站的证书，以便浏览器验证站点身份。SSL 安全层验证完成之后，上层的 HTTP 协议内容都会被加密，保证数据的安全传输。 这样一来，传统的中间人攻击就几乎没有了生存空间，攻击手段只能由技术缺陷转变为坑蒙拐骗。事实上，这种手段的效果反而更高效，比如我就发现网上不少下载网站发布的浏览器，不仅包含乱七八糟的导航和收藏网址，还包含一些不正规的认证机构证书。任何人都可以申请证书，这些不正规证书很可能造成安全隐患。 六、最后总结 对称性加密算法使用同一个密钥加密和解密，难以破解，加密速度较快，但是存在密钥配送问题。 Diffie-Hellman 密钥交换算法可以让双方「心有灵犀一点通」，一定程度解决密钥配送问题，但是无法验证通信方的身份，所以可能受到中间人攻击。 非对称性加密算法生成一对儿密钥，把加密和解密的工作分开了。 RSA 算法作为经典的非对称加密算法，有两种用途：如果用于加密，可以把公钥发布出去用于加密，只有自己的私钥可以解密，保证了数据的机密性；如果用于数字签名，把公钥发布出去后，用私钥加密数据作为签名，以证明该数据由私钥持有者所发送。但是无论那种用法，涉及公钥的发布，都无法避免中间人攻击。 公钥证书就是公钥 + 签名，由可信任的第三方认证机构颁发。由于正规浏览器都预装了可信的认证机构的公钥，所以可以有效防止中间人攻击。 HTTPS 协议中的 SSL/TLS 安全层会组合使用以上几种加密方式，所以说不要安装非正规的浏览器，不要乱安装未知来源的证书。 密码技术只是安全的一小部分，即便是通过正规机构认证的 HTTPS 站点，也不意味着可信任，只能说明其数据传输是安全的。技术永远不可能真正保护你，最重要的还是得提高个人的安全防范意识，多留心眼儿，谨慎处理敏感数据。 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Excerpt/鉴权接口.html":{"url":"Note_Excerpt/鉴权接口.html","title":"鉴权接口","keywords":"","body":"鉴权接口 认证 鉴权本质上是，用户（user / machine）如何获取权限，及如何鉴别身份去确定能够操作哪些资源。因此鉴权可以分为两部分内容：授权（Authorization）与认证（Authentication），我们先来看看该如何做认证。下面是某个平台的一个接口（非真实url），通过get请求获取信息： response = requests.get(\"http://xxxx/userinfo\") 这个接口调用很简单也很方便，有一种奔放的美，但显而易见和安全两个字完全不沾边，可能我们部门有很多接口都是这么做的。带来的第一个问题是，我们没法监控到是谁调用了这个接口，无法进行身份的认证，很难做进一步的审计。那么一个简单的想法就是给自己的接口加一个参数，用来标明是谁调用的接口，类似这样： params = {\"user\": \"xiaoshuai\"} response = requests.get(\"http://xxxx/userinfo\", params=params) 如此一来，就能知道是调用接口的是小帅，但倘若隔壁老王也假装自己是小帅，传同样的参数进行调用，又该如何应对呢。我们可以改进一下，不要这么直白的用user作为参数，而是创建user/password或者token私发给用户，避免老王伪装成小帅来进行调用，比如这样： params = { \"username\": \"xiaoshuai\", \"password\": \"zhenshuai\" } response = requests.get(\"http://xxxx/userinfo\", params=params) 但get请求参数可能会被网关或其他地方的log直接记录下来，到时候某位同学一打开日志文件可能就发现了所有人的密码或token了。所以最好把这部分内容设置在header上或者干脆改成post请求放到body中。到这一步就很像HTTP Basic方法了，HTTP Basic是一种质询/响应的方法，可以参考一下它的逻辑： client向server发起一个GET请求 server返回一个401告诉client要用Basic认证方式 client把username和password通过冒号连接，合并成一个字符串username:password 进行base64编码 放到header的Authorization字段中，然后向server发起请求 服务端若没有认证通过，返回401；若认证通过，返回200 如： b64_str = base64.b64encode(\"username:password\".encode()).decode() headers = {\"Authorization\": f\"Basic {b64_str}\"} response = requests.get(\"http://xxxx/userinfo\", headers=headers) 但是base64毕竟只是一种编码，和明文传输相比不能说完全没有作用吧，只能说强的有限。在HTTP Basic中采用base64编码更多的是为了确保不出现特殊字符，而不是为了提升多大的安全性。因此如果要使用这种方法的话，必须基于https。既然base64只是编码协议不能保证密码安全，那我们换一种算法对密码进行哈希或者加密不就行了嘛，比如可以使用MD5对密码进行一下hash，然后仅向服务端发送username和经过md5以后的密码： headers = { \"X-Request-User\": \"username\", \"X-Request-Password\": hashlib.md5(\"password\".encode()).hexdigest() } response = requests.get(\"http://xxxx/userinfo\", headers=headers) 但此时依旧存在一些问题，是可以继续优化的。第一个问题是，md5的安全性不能算十分可靠，如果密码较简单，是可以用一些较大的彩虹表撞库撞出来的。第二个问题是，虽然避免了密码明文传输，但这种方式还是无法抵抗重放攻击，攻击者拿到md5后的密码一样可以进行接口调用。针对这些问题，可以从这些方面做优化： MD5产生的是128位输出，SHA1产生160位，而SHA256产生的是256位，因此可以将MD5替换为SHA256来大幅度降低撞库风险 将由用户生成的username/password改为由服务端生成的access_key/access_secret，提高secret的复杂度，避免弱密码 增加nonce，这是一个随机数（或随机字符串），从而防止同个请求重复调用 增加时间戳，当服务端收到请求后判断距离当前时间相差超过阈值（例如60秒），直接拒绝请求 def gen_signature(message: str, nonce: str) -> str: return hmac.new(nonce.encode(), message.encode(), hashlib.sha256).hexdigest() # nonce的生成可以是简单的randint(0, sys.maxsize)，也可以是uuid、objectId等 headers = { \"X-Request-Key\": \"access_key\", \"X-Request-Ts\": timestamp, \"X-Request-Nonce\": nonce, \"X-Request-Signature\": gen_signature(\"&\".join([access_secret, timestamp]), nonce) } response = requests.get(\"http://xxxx/userinfo\", headers=headers) 在接收到请求以后，服务端首先对timestamp进行判断，如果超过设定的阈值则直接拒绝请求。如果时间戳判断通过，则判断nonce是否存在（可以通过缓存），若nonce已经存在，则拒绝请求。timestamp和nonce都检验通过后，服务端使用相同的哈希算法进行一次哈希，并将结果与客户端发送的结果进行比对，如果比对通过则接受请求。 那么现在是否已经足够安全了呢？还有一个风险点，就是如果存在中间人，他依旧可以抓包然后修改请求参数，从而获取到自己想要的信息。要解决这个问题，我们只需要在上面的签名生成函数中，按照规则把参数也加入到哈希中进行校验即可，这也是现在各大API开放平台普遍采用的AK/SK方法。这个具体规则可以由开发者来设立，每个API都可能不一样，有的较为复杂要进行多轮hash，有的较为简单只进行一轮hash。例如我们可以对参数的key进行升序排列后，加入到hash中，也可以把请求的path也加入hash中来： def gen_signature(secret: str, path: str, timestamp: str, nonce: str, params: dict) -> str: hash_list = [timestamp, secret, path] for key in sorted(params.keys()): hash_list.append(f\"{key}={params[key]}\") hash_str = \"&\".join(hash_list) return hmac.new(nonce.encode(), hash_str.encode(), hashlib.sha256).hexdigest() 上述方法的原理就是HMAC（Hash-based message authentication 基于哈希的消息认证)，其核心思想MAC可以用维基百科的这张图来示意： 那么问题又来了，各大开放API平台，他们的接口全都是HTTPS，已经可以做到数据的加密和防篡改，那么为什么还是要将API认证设计成HMAC模式呢？这里可能有以下几点原因： https若想防御中间人攻击，首先client端必须得有完备的证书验证，基本上现代浏览器如chrome、edge、safari等都会基于CA证书进行安全校验，如果发现证书等不匹配将会对用户进行告警和阻拦。但仍有部分浏览器没有做到应尽的责任，比如移动端的360浏览器，使用这类浏览器的用户不能保证https不被中间人劫持。另一方面，如果我们是写程序脚本进行接口调用，可能有的用户也会把证书校验选项给关掉（比如python的requests库的verify=False），一旦关闭以后就无法防范中间人伪造的证书，从而产生安全风险。 在云架构、微服务盛行的现在，https能保证在外部不可信区域的安全，而经过网关进入内部网络后，有可能还是转化为http请求或其他形式调用指向实际的业务端。那么在内部网络里如果出现“内鬼”，他就可以在网关到业务端之间做手脚，获取到自己想要的信息。 除了认证、防篡改的功能以外，HMAC请求还能保证通过校验的请求是合法的，即不是随便乱填参数请求的。如果验签不通过，那么业务端就认为这一次请求不合法，接下去的业务逻辑也没必要进行下去了。这样一来可以加强业务接口的稳定性，减少不合法请求对业务系统的压力。 HMAC就是最好的方式了吗？HMAC的签名方式毕竟还是比较复杂的，对于开发者和用户来说都不太友好，会增加理解成本和开发量。那么还有什么方式呢？我把目光投向了OAuth 2的其中一个flow，这个flow其实就非常契合我们的使用场景： OAuth 2.0的Client Credentials Grant Flow一般用于https的server-to-server场景中，这种方式在部分API平台中也有运用，例如微信公众号开发者平台。基于这个流程我们设计一下权限2.0的API鉴权流程，如下所示： 在上述流程中，接口请求方（用户）需要提前来权限平台申请生成自己的app_id和app_secret，并进行对应接口（域）的授权申请。授权通过后，用app_id和app_secret向鉴权服务发起请求，交换得到access_token。这个access_token具有有效期（一般为1~2小时）。随后，用户向目标接口服务发起接口请求，并携带access_token信息，目标服务将该信息转发至鉴权服务，此时可以选择附带上path信息，判断用户是否具有某个具体接口的权限，也可以不携带仅进行用户身份认证（目标服务可自行进行path或scope的控制），在完成身份认证后进行业务逻辑处理，并最终返回数据。在这个流程中，token采用的是全局唯一随机字符串，而不是JWT等包含具体认证信息的字符串，主要是为了将权限控制全都放在鉴权服务后端，能够及时响应撤销授权。 授权 前面主要解释了一下认证相关流程，在整个鉴权流程中，授权也是十分关键的一部分。 生成专属于个人的app_id和app_secret，用户可以选择刷新secret，刷新后将会立即删除当前生效的access_token；管理员也可以选择撤回某个已生效的授权，撤回后也将立即更新信息阻止后续的访问。 使用缓存 既然我们的目标是能向其他工具平台提供鉴权服务，那么高并发是必须要考虑的点。以鉴权流程中的第一步获取access_token为例，其基本逻辑是： 从数据库中找到app_id对应的app_secret 将数据库中的值与接口传参的app_secret做校验 若校验通过则生成token 一些日志记录、数据库记录以及其他可能的操作，然后返回token 很明显，数据库操作容易成为并发瓶颈，我们可以引入缓存层来提高并发能力，例如redis。第一个可以被优化的就是数据库中的secret获取，我们把它改为从缓存中获取，一个最直接的思路就是先判断缓存中是否存在，若存在则直接返回，若不存在则从数据库中获取值、设置到缓存中然后返回： def get_secret_from_cache(app_id): key = f\"some_prefix_{app_id}\" cached_secret = redis.get(key) if cached_secret: return cached_secret secret = get_secret_from_db(app_id) if secret: redis.setex(key, expire, secret) return secret 通过上面的缓存操作，我们保证了某个app_id仅在第一次请求时进行数据库查询，随后的请求都会从缓存中查询，从而大幅度提高QPS。但当我们开发此类对外暴露的接口时，一定要牢记鲁迅先生的教导：”我向来不惮以最坏的恶意揣测接口调用者 :)“，我们设想以下几种情形： 假若用户大量传入非法的，不存在的app_id，那么就会发生缓存穿透。在这种情况下我们发现，每一次调用都会请求数据库，而又因为数据库中实际上找不到对应的secret，导致缓存不会被设置上，缓存层形同虚设，数据库面临巨大的压力。 假设某个app_id缓存的值已经过期删除了，此时有用户以非常高的并发请求该app_id，那么就会发生缓存击穿。在第一个请求还未能设置上缓存的时候，大量的请求已经开始访问数据库，数据库又面临了巨大的压力 对于第一种缓存穿透的情况，第一步肯定是先做好参数校验，尽量先提前排除掉一些不符合规则的参数情况。接下来，一种较为简单的做法是如果数据库中不存在对应值，我们也还是进行缓存的设置，只是设置成空值，那么后续的访问将直接从缓存层中获得空值并进行返回。但是调用者的恶意难道就止步于此了吗？倘若直接一个for循环生成大量不同的不存在的app_id，那么redis里面就会被插入大量无效的key，浪费我们的内存，是可忍孰不可忍？假如我们数据库中的数据量不可预估，那么此时可以考虑用布隆过滤器来帮助我们挡一波空值请求。但回看我们的应用场景，app_id信息的数量其实是在一个可控的范围内的，我们可以保守估计其数据基本也就是在几千，至多一两万的量级。因此我们可以起一个定时器把所有数据都刷到缓存里，一旦发现缓存里不存在该key，就可以认为是无效的app_id。通过这种做法，我们还顺便解决了第二个缓存击穿的问题。于是我们将代码的逻辑改成这样： def update_cache_schedule(): # 从数据库中获取到access_list for access_info in access_list: # 从access_info中获取到key和value，假设expire为3600秒 redis.setex(key, expire, value) def get_secret_from_cache(app_id): key = f\"some_prefix_{app_id}\" cached_secret = redis.get(key) # 如果缓存中不存在key对应的值，直接返回None return cached_secret 但是这样做会带来数据一致性的问题，我们后文再谈。在用定时器刷新所有数据到缓存中的时候，要注意定时器执行间隔一定要小于缓存过期时间（视具体应用场景也可以考虑不设置过期时间），不然还是可能会发生缓存击穿或者缓存雪崩的问题。另一方面，在大批量设置过期时间的时候，建议可以适当加一些随机量，错开缓存过期的时间，降低redis卡顿的风险。除此之外还要注意一点，假如发生较为极端的情况导致redis内存占用满了，没有过期时间的key也可能被redis清理出去，那么对于较重要的这批缓存，我们可以缩短定时器执行间隔，或者另外起一个更频繁的定时器来检测缓存是否还有效。 再回头看上面的代码，还有可优化的地方吗？我们一直说，不要在for循环里面直接做数据库操作，会导致出现性能问题，这对redis其实也是一样的。当我们的数据量较小，比如几百、几千的时候，可能还感觉不出来影响，但当数据量扩大到几万、几十万甚至更大的时候，在for循环里进行redis.set操作将会十分耗时。这时候建议使用mset来操作，将代码改为： def update_cache_schedule(): data_dict = {} for access_info in access_list: # 从access_info中获取到key和value data_dict[key] = value redis.mset(data_dict) 在我们的redis测试集群上测试一下耗时对比，得到如下数据： 插入1000条数据耗时 10000条耗时10000条耗时 100000条耗时100000条耗时 set放 0.63秒 7.11秒 82.75秒 mset设定值 0.009秒 0.037秒 0.35秒 可以看到随着数量级的提升，mset的性能对比set具有非常显著的优势。但是mset并不能像setex那样直接把过期时间也给设置上，我们需要在mset完以后额外调用expire操作，比如： def update_cache_schedule(): # 假设已经设置好了data_dict redis.mset(data_dict) for key in data_dict.keys(): redis.expire(key, 60) 啊？在for循环里一个个expire，那我们不是白用mset了，这不就又回去了吗？别急，此时我们可以利用redis的管道来进行优化，直接用setex来做： def update_cache_schedule(): # 假设已经设置好了data_dict pipeline = redis.pipeline() for key, value in data_dict.items(): pipeline.setex(key, 60, value) pipeline.execute() 同样进行耗时测试，可以得到使用pipeline相比for循环expire具有明显的性能优势： 插入1000条数据耗时 10000条耗时10000条耗时 100000条耗时100000条耗时 mset（不进行expire） 0.009秒 0.037秒 0.35秒 mset + for循环expire 0.79秒 7.8秒 73.17秒 pipeline进行mset然后expire 0.021秒 0.106秒 1.06秒 pipeline进行setex 0.014秒 0.093秒 0.90秒 在优化完定时器逻辑后，还有一个问题，我们希望当管理员通过一个授权申请，或者撤销一个授权以后，能尽快生效，而不是要等待定时器下一次刷新缓存才生效。也就是说，希望能尽可能保证数据一致性。按照上面的定时器刷新缓存的做法，不足以保证数据一致性，因此就需要在每次做数据库更新的时候，同时去“更新”缓存。这里的“更新”缓存一般而言有两种做法： 真的做一次更新操作 不做更新，而是做删除缓存的操作，当查询操作发现没有命中缓存的时候去设置缓存。这一步如果放到业务层面做，就是Cache Aside的设计模式，如果把它抽象出来单独做一个Provider，就是Read-Through模式 一般而言，主流的做法都是采用删除缓存而不是更新缓存，理由是大多数系统中，对一个key的更新概率可能大于它实际被使用到的概率。假设一个小时内我们可能会更新1000个key，但实际被使用到的key可能只有100个，因此如果频繁做更新缓存的操作，其实是对资源的浪费。另一方面，在高并发的情况下做更新而不是做删除操作，有更大可能性产生脏数据。而除了上述更新缓存的设计模式，其实还有其他的模式，例如结合消息队列来进行异步更新，或者是利用数据库log来回放操作更新缓存等等。但这些方法虽然在一些场景下有其优点，但也会提升系统复杂度，增加了出现异常的可能性。前文中采用的是定时器刷新数据进缓存，并且查询时不设置缓存的方式，如果这样的话那么就只能选择方案1，在数据被更新时去做一次更新缓存的操作。但是在综合考虑安全、成本、效率等因素后，我还是选择了定时器刷数据+查询为空设置缓存+数据库操作删除缓存的cache aside模式。 要注意的是，此时应当先进行数据库操作，然后再进行缓存的删除，如果反过来先删除缓存，再进行数据库操作的话，有更高的概率产生数据不一致问题。设想下面这种情况： 假如我们先删缓存再写入数据库，在写入数据库完成之前恰巧有另一个线程读取该缓存，就会发现缓存为空并读取数据库并把旧值更新到缓存中，这样就会导致直到该缓存下一次被删除之前，保存的都是旧值，产生数据不一致问题。而如果反过来，就是这种情况： 在这种情况下，最坏的情况是线程1从数据库写入新值到删除缓存的这个过程中，其他线程访问缓存会获取到旧值，但完成缓存删除后，后续的线程将得到新值，这一个时间段一般仅仅在几十毫秒到几百毫秒之间，是可以接受的，这种做法对我们目前的各个工具平台来说基本是足够了。但如果考虑更极端一点的情况，还是有可能会出现这样的情形： 在上面这种情况下，线程1完成了数据库写入并删除了缓存，线程2也开始写入数据库（但还未写入完成），与此同时线程3来读取数据发现缓存为空，去读取了数据库中的值A，并准备写入缓存。在线程3写入缓存之前，线程2完成了数据库的写入并删除了缓存，然后线程3把读出来的值A写入了缓存，于是数据不一致的情况又出现了。要解决这种情况，一个比较简单的做法是延迟双删，分为三步：1. 删除缓存；2. 写入数据库；3. 延时一段时间后再次删除缓存。那么上面这种情况就会变成： 延迟删除缓存最最重要的点在于对业务操作时间的预估，需要统计业务逻辑执行读数据库和写缓存的操作时间，在此基础上再增加几百毫秒到几秒左右的时间，来确保缓存被正确删除。打个比方，假如估算出来在这个业务流程中，读数据库+写入缓存最多耗时2秒，那就可以在此基础上再加1秒，也就是3秒作为延迟时间。如果为了进一步确保缓存被成功删除，在这里还可以结合消息队列，当发现删除失败的时候重试删除操作。 压测验证 前面说了这么多关于缓存的使用方法，核心目的就是为了提高接口性能。在面对类似的接口性能优化需求时，我们可以在优化完代码后先自己压测一波看看结果，这样调试起来效率会比较高。免费的压测工具目前用的比较多的有jmeter等，jmeter具有图形化界面，且支持插件扩展，也支持分布式压测。不过这里我推荐另外一款压测工具给我们组里的同学：locust，官网是：https://locust.io/。推荐locust的理由主要有以下几点： jmeter并发基于java线程，而locust并发基于python或go的协程，在我们资源有限的台式机上可以获得更高的并发量 对于熟悉python或go语言的同学来说，上手locust几乎没有学习成本 locust同样具有图形化数据展示、图表统计等，丰富程度虽然比不上jmeter，但也足够使用 部署分布式发压端非常简单，仅需加一个命令行参数 安装locust非常简单，只需要有python3环境，然后执行pip install locust即可。接下来有两种选择，选择python作为发压端，或者选择go作为发压端，一般而言我们选择python作为发压端就已经能满足需求。如果选择python的话，就需要编写一个压测脚本，例如写一个test.py脚本： import json from locust import task, FastHttpUser class User(FastHttpUser): @task def task1(self): response = self.client.post(self.url, json=self.payloads) def on_start(self): with open(\"config.json\", \"r\") as f: json_data = json.load(f) self.payloads = json_data[\"payloads\"] self.url = json_data[\"url\"] 这样就完成了一个压测脚本的编写，由于python存在GIL锁的限制，要利用全部机器性能，我们需要在同一台机器上跑多个worker。先来启动一下master进程： locust -f test.py --master 然后启动多个worker进程，worker可以进行分布式部署，部署在任意一台linux或者windows机器上，只要告诉它master的地址就可以： locust -f test.py --worker --master-host=xxx.xxx.xxx.xxx master进程默认启动在8089端口，我们打开浏览器访问8089端口就可以看到locust的界面，输入并发数、压测目标host地址等就可以开始压测。在主频2.20Ghz，8核CPU的机器下，可以达到1000并发、27000+QPS的压力，或者5000并发、24000+QPS的压力。 这个发压端的能力对于我们大多数接口来说应当是能够满足需求了，但如果仍不满足，这时候我们可以将发压端切换为用go语言编写的boomer，首先需要在worker所在机器上安装golang，安装完毕之后找个目录安装boomer： go mod init your_project_name go get github.com/myzhan/boomer@master 然后编写一个main.go脚本（不需要原来的test.py脚本了），例如： package main import ( \"net\" \"net/http\" \"io\" \"io/ioutil\" \"log\" \"time\" \"github.com/myzhan/boomer\" ) var ( Client *http.Client ) func fun1() { start := time.Now() path := \"/test\" host := \"http://your_service_address\" url := host + path resp, err := Client.Get(url) if err != nil { log.Println(err) boomer.RecordFailure(\"Get\", path, 0.0, err.Error()) return } else { io.Copy(ioutil.Discard, resp.Body) boomer.RecordSuccess(\"Get\", path, time.Now().Sub(start).Milliseconds(), resp.ContentLength) err = resp.Body.Close() if err != nil { return } } } func main() { tr := &http.Transport{ DialContext: (&net.Dialer{ Timeout: 10 * time.Second, //拨号等待连接完成的最大时间 KeepAlive: 30 * time.Second, //保持网络连接活跃keep-alive探测间隔时间。 }).DialContext, MaxIdleConns: 10000, // 设置连接池最大10000个连接数 IdleConnTimeout: 300 * time.Second, MaxIdleConnsPerHost: 10000, } Client = &http.Client{ Transport: tr, Timeout: 30 * time.Second, //设置超时，包含connection时间、任意重定向时间、读取response body时间 } task := &boomer.Task{ Name: \"fun1\", Weight: 10, Fn: fun1, } boomer.Run(task) } 然后编译go脚本，在windows上得到main.exe，在linux得到main可执行文件。编译完成后运行可执行文件，由于go的协程可以直接利用多核CPU性能，所以同一台机器上只需要启动一个worker进程，指定一下master-host即可 go build main.go ./main.exe --master-host=xxx.xxx.xxx.xxx 接下来同样是在master的网页端发起压测，可以看到boomer的发压能力是非常强大的，在上述同样的机器条件下可以做到2000并发、110000+QPS的发压能力。 可以说，这个发压能力对于我们来说是妥妥的足够了，如果还不满意，可以将上面用到的go自带的http库替换为fasthttp库，发压能力还能继续提升，如果有更多机器资源做分布式发压的话，可以达到百万级QPS压测能力。 结语 其实像HMAC、AK/SK、延迟双删等方法，大家可能都有了解或者已经在使用了。不过也许有的小伙伴还不太清楚“为什么要这么做”，所以这篇文章花了较多篇幅讲“为什么”，希望能抛砖引玉，给大家带来一点思考和讨论。 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Recording/零散记录.html":{"url":"Note_Recording/零散记录.html","title":"零散记录","keywords":"","body":"《零散记录》 以往的 Blog 记录 Java happen-before原则 - 一只白羊座的傻猫 | Ariescat Blog 单例与线程安全 - 一只白羊座的傻猫 | Ariescat Blog Java内存可见性问题 - 一只白羊座的傻猫 | Ariescat Blog Thread中stop(),suspend(),resume()为什么不安全 - 一只白羊座的傻猫 | Ariescat Blog List#subList和Spring#split的使用陷阱 - 一只白羊座的傻猫 | Ariescat Blog Java安全管理器SecurityManager - 一只白羊座的傻猫 | Ariescat Blog Spring Spring之properties解析 - 一只白羊座的傻猫 | Ariescat Blog Spring之AOP使用 - 一只白羊座的傻猫 | Ariescat Blog Spring对Groovy的支持 - 一只白羊座的傻猫 | Ariescat Blog (转载)Spring的BeanFactoryPostProcessor和BeanPostProcessor区别 - 一只白羊座的傻猫 | Ariescat Blog 库 关于Gson的几个坑 - 一只白羊座的傻猫 | Ariescat Blog Java集合框架Koloboke - 一只白羊座的傻猫 | Ariescat Blog Joda--对时间的操作 - 一只白羊座的傻猫 | Ariescat Blog Netty之心跳与重连 - 一只白羊座的傻猫 | Ariescat Blog 事件驱动编程RxJava - 一只白羊座的傻猫 | Ariescat Blog 动态，敏捷的Groovy - 一只白羊座的傻猫 | Ariescat Blog Guava使开发更简单之RangeMap - 一只白羊座的傻猫 | Ariescat Blog 网络 WebSocket、Socket、TCP、HTTP区别 - 一只白羊座的傻猫 | Ariescat Blog 网络IO中的同步、异步、阻塞和非阻塞 - 一只白羊座的傻猫 | Ariescat Blog 操作系统 (转)操作系统就是一个“死循环”！ - 一只白羊座的傻猫 | Ariescat Blog Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Reading/公众号.html":{"url":"Note_Reading/公众号.html","title":"公众号.md","keywords":"","body":"《公众号》 码农的荒岛求生 #高并发&高性能 (qq.com) 看完这篇还不懂高并发中的线程与线程池你来打我(内含20张图) CPU 空闲时在干嘛？ 码农翻身 操作系统就是一个“死循环”！ 阿里技术 #问题排查 (qq.com) 线上故障如何快速排查？来看这套技巧大全 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Reading/《Effective Java》.html":{"url":"Note_Reading/《Effective Java》.html","title":"《Effective Java》","keywords":"","body":"Effective Java 第四章 类和接口 第 17 条：使可变性最小化 不可变对象本质上是线程安全的，它们不要求同步。 BigInteger 和 BitSet BigInteger 和 BigDecimal：BigInteger 实现了任意精度的整数运算，BigDecimal 实现了任意精度的浮点数运算。 第 18 条：复合优先于继承 只有当两者之间确实存在“ is-a ”关系的时候，类 B 才应该扩展类 A，否则 B 应该包含 A 的一个私有实例，并且暴露一个较小的、较简单的 API。 JDK 中如Stack extends Vector，Properties extends Hashtable都违反该原则，采用复合更优。 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "},"Note_Reading/《设计模式之美》.html":{"url":"Note_Reading/《设计模式之美》.html","title":"《设计模式之美》","keywords":"","body":"设计模式之美 01 为什么要尽早地学习并掌握设计模式相关知识 我理解的设计模式主要功能是：解耦和扩展 02 从哪些维度评判代码质量的好坏？如何具备写出高质量代码的能力？ 思从深而行从简，真正的高手能云淡风轻地用最简单的方法解决最复杂的问题。这也是一个编程老手跟编程新手的本质区别之一。 03 面向对象、设计原则、设计模式、编程规范、重构，这五者有何关系？ 贫血模型和充血模型 08 | 理论五：接口 vs 抽象类的区别？如何用普通的类模拟抽象类和接口？ 抽象：表示一种 is-a 的关系，为了解决代码复用问题；这是一种自下而上的设计思路，现有子类代码重复复，再提取； 接口：表示一种 has-a 的关系，为了解决抽象而非代码复用问题；这是一种自上而下的设计思路，先设计接口，再去考虑具体的实现； 10 | 理论七：为何说要多用组合少用继承？如何决定该用组合还是继承？ 继承最大问题： 继承层次过深，继承关系过于复杂带来的代码可读性和可维护性。 比如“鸟”：会不会飞，会不会叫，会不会下蛋 但：组合并不是完美的，继承也并非一无是处 12 | 实战一（下）：如何利用基于充血模型的 DDD 开发一个虚拟钱包系统？ Repository 的 Entity，即便它被设计成贫血模型，违反面向对象编程的封装特性，但 Entity 的生命周期是有限的。一般，它传递到 Service 后，就会转化成 Bo 或者 Domain 来继续后面的业务逻辑。其生命周期到此就结束了，并不会被到处任意修改。Controller 层的 Vo 单纯作为一种 DTO，亦是如此。 13 | 实战二（上）：如何对接口鉴权这样一个功能开发做面向对象分析？ OAuth：调用方将接口的 URL 和 Apple、密码拼接在一起，然后进行加密，生成一个 token。 OAuth2？ 17 | 理论三：里式替换（LSP）跟多态有何区别？哪些代码违背了 LSP？ 里式替换原则（design by contract，按照协议来设计）：父类定义了函数的“约定（或协议）”，子类可以改变函数的实现逻辑，但不能改变函数原有的“约定”。如对函数输入、输出、异常的约定，注释中所罗列的特殊说明等。 Copyright © Ariescat all right reserved，powered by Gitbook最后修改时间： 2024-05-07 17:20 "}}