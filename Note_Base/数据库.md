# 《数据库》



## MySQL

### 数据类型

- MySQL 中的 int(M)，int(M) 里的 M 表示最大显示宽度，当加上 zerofill 才会表现出效果来。

- unsigned

- 编码
  - utf8_general_ci、utf8_unicode_ci 和 utf8_bin 的区别
  - [彻底解决 mysql 中文乱码 - CSDN 博客](https://blog.csdn.net/u012410733/article/details/61619656)



### SQL 语句

- select

  > select: 即最常用的查询，是不加任何锁的
  >
  > select ... lock in share mode: 会加共享锁 (Shared Locks)
  >
  > select ... for update: 会加排它锁

- 联接子句 union，join



### 范式

第一范式：1NF是对属性的原子性约束，要求属性具有原子性，不可再分解；

第二范式：2NF是对记录的惟一性约束，要求记录有惟一标识，即实体的惟一性；

第三范式：3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。

没有冗余的数据库设计可以做到。但是，没有冗余的数据库未必是最好的数据库，有时为了提高运行效率，就必须降低范式标准，适当保留冗余数据。具体做法是：在概念数据模型设计时遵守第三范式，降低范式标准的工作放到物理数据模型设计时考虑。降低范式就是增加字段，允许冗余。



### 锁

- 前言

  表锁，页面锁，行锁，共享锁，排它锁，意向锁，记录锁，间隙锁，临键锁......这些都是什么鬼？？？

- 机制

  - 共享锁（读锁，S 锁）

    又称读锁，若事务 T 对数据对象 A 加上 S 锁，则事务 T 可以读 A 但不能修改 A，**其他事务只能再对 A 加 S 锁，而不能加 X 锁**，直到 T 释放 A 上的 S 锁。

    这保证了其他事务可以读 A，但在 T 释放 A 上的 S 锁之前不能对 A 做任何修改。

  - 排他锁（写锁，X 锁）
    又称写锁。若事务 T 对数据对象 A 加上 X 锁，事务 T 可以读 A 也可以修改 A，**其他事务不能再对 A 加任何锁**，直到 T 释放 A 上的锁。

    这保证了其他事务在 T 释放 A 上的锁之前不能再读取和修改 A。

- 粒度

  MySQL 不同的存储引擎支持不同的锁机制

  表锁：开销小，加锁快；不会出现死锁

  行锁：开销大，加锁慢；会出现死锁

  页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁

  默认情况下，表锁和行锁都是自动获得的，不需要额外的命令。

- InnoDB 行级锁和表级锁

  InnoDB 存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。

  为了允许**行锁和表锁共存**，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是**表锁**：

  - 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
  - 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。

- InnoDB 加锁方法

  - **意向锁是 InnoDB 自动加的**， 不需用户干预。

  - 对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB 会自动给涉及数据集加排他锁（X)；

  - 对于普通 SELECT 语句，InnoDB 不会加任何锁；
    事务可以通过以下语句**显式**给记录集加共享锁或排他锁：
    - 共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。
    - 排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁

  锁只有在执行 commit 或者 rollback 的时候才会释放，并且所有的锁都是在**同一时刻**被释放。

- InnoDB 行锁实现方式

  InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，**否则，InnoDB 将使用表锁！**

- InnoDB 的间隙锁

  当我们用**范围条件**而不是相等条件检索数据，并请求共享或排他锁时，InnoDB 会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB 也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key 锁）。

  > MySQL 默认事务隔离级别是可重复读，这个隔离级别为了避免幻读现象，引入了这个间隙锁，对索引项之间的间隙上锁。
  >
  > SELECT * FROM t_url_mapping WHERE id>3 LOCK IN SHARE MODE;（SELECT 语句默认不上锁，需显示加锁，该语句加的就是间隙锁）

  个人理解：

  记录锁（Record Locks）：封锁记录，记录锁也叫**行锁**；例如：

  SELECT * FROM `test` WHERE `id`=1 FOR UPDATE;

  间隙锁（Gap Lock）：锁在**索引**之间或者第一个索引前面或者最后一个索引后面。是一种概念，InnoDB 的算法实现是 Next-key lock，也属于间隙锁，但他相当于记录锁+间隙锁。

  临键锁（Next-key lock）：使用索引进行**范围查询**，**左开右闭**区间，**目的是为了解决幻读的问题**。

- 注意死锁

  产生：两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。如：

  当前事务获得 S 锁，但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。

  更新操作必须等待先执行的事务 commit 后才能执行，如果同时并发太大的时候很容易造成死锁。（搜索`mysql in share mode 死锁`）

  **检测死锁**：数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB 存储引擎能检测到死锁的循环依赖并立即返回一个错误。

  **死锁恢复：**死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB 目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。

- 参考链接

  [MySQL 锁总结](https://zhuanlan.zhihu.com/p/29150809/)

  [意向锁间隙锁 - Google 搜索](https://www.google.com/search?q=意向锁间隙锁)



### 事务

- 事务特性，ACID 的含义

  1. 原子性

     a. 事务是一个原子操作单元

     b. 要么都做，要么都不做，没有第三种情况

     c. 原子性仅能够保证单个事务的一致性!

  2. 一致性

     a. 事务操作前和操作后都必须满足业务规则约束

     b. 比如资源数量一致：A 向 B 转账，转账前和转账后 AB 两个账户的总金额必须是一致的

     c. **一致性是最基本的属性**，其它的三个属性都为了保证一致性而存在的。为了保证**并发情况下**的一致性，引入了**隔离性**，即保证每一个事务能够看到的数据总是一致的，就好象其它并发事务并不存在一样。

  3. 隔离性

     a. 多个并发事务同时对数据进行读写的能力

     b. 隔离性可以防止事务并发执行时由于交叉执行导致数据不一致的问题

  4. 持久性

     a. 对数据的修改是永久的

     b. 即使出现系统故障也不会丢失

- 并发问题：

  1. 脏读

     一个事务正在对一条记录做修改，在这个事务提交之前，别的事务读取到了这个事务修改之后的数据，也就是说，一个事务读取到了其他事务还没有提交的数据，就叫做脏读。

  2. 不可重复读（第一类不可重复读）

     一个事务读某条数据读两遍，读到的是不一样的数据，也就是说，一个事务在进行中读取到了其他事务对旧数据的修改结果。（比如说 我开一个事务 修改某条数据 先查后改 执行修改动作的时候发现这条数据已经被别的事务删掉了）

  3. 幻读（第二类不可重复读）

     一个事务中，读取到了其他事务新增的数据，仿佛出现了幻象。（幻读与不可重复读类似，不可重复读是读到了其他事务 update/delete 的结果，幻读是读到了其他事务 insert 的结果）

  隔离级别：

  1. 读未提交（read-uncommitted）

     在一个事务中，可以读取到其他事务未提交的数据变化，这种读取其他会话还没提交的事务，叫做脏读现象，在生产环境中切勿使用。

  2. 读已提交（read-committed）

     Sql Server,Oracle 默认

     在一个事务中，可以读取到其他事务已经提交的数据变化，这种读取也就叫做不可重复读，因为两次同样的查询可能会得到不一样的结果。

  3. 可重复读（repetable-read）

     MySQL 默认

     在一个事务中，直到事务结束前，都可以反复读取到事务刚开始时看到的数据，并一直不会发生变化，避免了脏读、不可重复读现象，但是**在 SQL 标准中**它还是无法解决幻读问题。

  4. 可串行化（serializable）

     这是最高的隔离级别，它强制事务串行执行，避免了前面说的幻读现象，简单来说，它会在读取的每一行数据上都加锁，所以可能会导致大量的超时和锁争用问题。

  几个概念：

  1. 锁：Shared Locks(共享锁/S 锁)、Exclusive Locks(排它锁/X 锁)、Record Locks(行锁)、Gap Locks(间隙锁)、Next-Key Locks(间隙锁)

     > Record Locks 是加在索引行 (对！是索引行！不是数据行！)，Gap Locks 和 Next-Key Locks 都属于索引锁

  2. 快照读（普通读）：snapshot read，通过 MVCC 机制读取历史数据的方式

     > select * from table ....

  3. 当前读：current read ，读取数据库最新版本数据的方式

     > insert、update、delete、select for update、select lock in share mode

  4. 意向锁：表级别锁

  **隔离性**底层实现原理：

  - MVCC(多版本并发控制) 和锁

  - 读已提交和可重复读区别主要在于**MVCC 版本的生成时机**

    RC 是是**每次**`select`时，RR 是**第一次**`select`时生成版本

  - 可串行化级别下，会自动将所有普通`select`转化为`select ... lock in share mode`执行，即针对同一数据的所有读写都变成互斥的了，可靠性大大提高，并发性大大降低。

  注意：

  1. 间隙锁锁住的是索引的间隙，可以理解为范围，如（2，5]，(5，7]

  2. 我们通过`update`、`delete`等语句加上的锁都是行级别的锁。只有`LOCK TABLE … READ`和`LOCK TABLE … WRITE`才能申请表级别的锁。

  3. RR 级别下隐藏着一个操作，就是在事务 A 提交前，事务 B 已经进行过一次查询，否则，事务 B 会读取最新的数据。[原文](https://blog.csdn.net/thekenofdis/article/details/80736401)

  4. 为什么很多文章都产生误传，说是可重复读可以解决幻读问题！原因出自官网的一句话 (地址是:`https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html#innodb-record-locks`)，原文内容如下

     > By default, InnoDB operates in REPEATABLE READ transaction isolation level. In this case, InnoDB uses next-key locks for searches and index scans, which prevents phantom rows (see Section 14.7.4, “Phantom Rows”).

     按照原本这句话的意思，应该是

     **InnoDB 默认用了 REPEATABLE READ。在这种情况下，使用 next-key locks 解决幻读问题！**

     结果估计，某个国内翻译人员翻着翻着变成了

     **InnoDB 默认用了 REPEATABLE READ。在这种情况下，可以解决幻读问题！**

     然后大家继续你抄我，我抄你，结果你懂的！

     显然，漏了"使用了 next-key locks！"这个条件后，意思完全改变，我们在该隔离级别下执行语句

     ```sql
     select *  from tx_tb where pId >= 1;
     ```

     是快照读，是不加任何锁的，根本不能解决幻读问题，除非你用

     ```sql
     select *  from tx_tb where pId >= 1 lock in share mode;
     ```

     这样，你就用上了 next-key locks，解决了幻读问题！

  5. 其实幻读很多时候是我们完全可以接受的

  总结：

  <table>
     <tr>
        <th> 隔离级别 </th>
        <th> 读数据一致性 </th>
        <th> 脏读 </th>
        <th> 不可重复读 </th>
        <th> 幻读 </th>
     </tr>
     <tr>
        <td> 读未提交 </td>
        <td> 最低级别，只保证不读取物理上损坏的数据 </td>
        <td> 有 </td>
        <td> 有 </td>
        <td> 有 </td>
     </tr>
     <tr>
        <td> 读已提交 </td>
        <td> 语句级 </td>
        <td> 无 </td>
        <td> 有 </td>
        <td> 有 </td>
     </tr>
     <tr>
        <td> 可重复读 </td>
        <td> 事务级 </td>
        <td> 无 </td>
        <td> 无 </td>
        <td> 可能有 </td>
     </tr>
     <tr>
        <td> 可串行化 </td>
        <td> 最高级别，事务级 </td>
        <td> 无 </td>
        <td> 无 </td>
        <td> 无 </td>
     </tr>
  </table>


  参考链接：

  1. [深入理解 mysql 的事务隔离级别和底层实现原理](https://blog.csdn.net/suifeng629/article/details/99412343)
  2. [Mysql 中 select 的正确姿势](https://www.cnblogs.com/rjzheng/p/9902911.html)，[新说 Mysql 事务隔离级别](https://www.cnblogs.com/rjzheng/p/9955395.html)，他的“[数据库系列](https://www.cnblogs.com/rjzheng/category/1281020.html)”都挺不错的

- 事务传播（其实这个是`Spring`的概念，Spring 它对 JDBC 的隔离级别作出了补充和扩展，其提供了 7 种事务传播行为）

  1. **PROPAGATION_REQUIRED：默认事务类型，如果没有，就新建一个事务；如果有，就加入当前事务。适合绝大多数情况。**
  2. PROPAGATION_REQUIRES_NEW：如果没有，就新建一个事务；如果有，就将当前事务挂起。
  3. PROPAGATION_NESTED：如果没有，就新建一个事务；如果有，就在当前事务中嵌套其他事务。
  4. PROPAGATION_SUPPORTS：如果没有，就以非事务方式执行；如果有，就使用当前事务。
  5. PROPAGATION_NOT_SUPPORTED：如果没有，就以非事务方式执行；如果有，就将当前事务挂起。即无论如何不支持事务。
  6. PROPAGATION_NEVER：如果没有，就以非事务方式执行；如果有，就抛出异常。
  7. PROPAGATION_MANDATORY：如果没有，就抛出异常；如果有，就使用当前事务。



### 索引

- 使用场景

  索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。

  1. 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效。
  2. 对于中到大型的表，索引就非常有效。
  3. 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。

  是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，可以通过 explain 检查 SQL 的执行计划，比如上面第一种情况，它就不会使用索引

- B-Tree

  ![img](https://pic4.zhimg.com/80/v2-56b33bdb51f338d70a7082a3bc6628bf_720w.jpg)

  查找算法：首先在根节点进行二分查找，如果找到则返回对应节点的 data，否则在相应区间的指针指向的节点递归进行查找。

- B+Tree

  ![img](https://pic3.zhimg.com/80/v2-24a5d6423c1faf8d07c12881ca26b6d6_720w.jpg)

  相比 B-Tree：

  - 内节点不存储 data，只存储 key；
  - 叶子节点不存储指针。

  一般在数据库系统或文件系统中使用的 B+Tree 结构都在经典 B+Tree 基础上进行了优化，在叶子节点增加了顺序访问指针，做这个优化的目的是为了提高区间访问的性能。

  ![img](https://pic1.zhimg.com/80/v2-7caf83645d4ec6aaba2fefbd91c19038_720w.jpg)

  **利用计算机预读特性**

  操作系统一般将内存和磁盘分割成固态大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。**数据库系统将索引的一个节点的大小设置为页的大小**，使得一次 I/O 就能完全载入一个节点，并且可以利用预读特性，相邻的节点也能够被预先载入。

- B+Tree 索引

  InnoDB 的 B+Tree 索引分为**主索引**和**辅助索引**。

  主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为**聚簇索引**。因为无法把数据行存放在两个不同的地方，所以**一个表只能有一个聚簇索引**。

  辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。

- MySQL 索引类型

  唯一索引，主键（聚簇）索引，非聚簇索引，全文索引

  其实按照定义，除了聚集索引以外的索引都是非聚集索引，只是人们想细分一下非聚集索引，分成普通索引，唯一索引，全文索引。

  全文索引有自己的语法格式，使用 match 和 against 关键字，比如

  ```sql
  select * from fulltext_test 
      where match(content,tag) against('xxx xxx');
  ```

- 缺点

  - 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加
  - 索引需要占用物理空间，除了数据表占用数据空间之外，每一个索引还要占一定的物理空间，如果建立聚簇索引，那么需要的空间就会更大
  - 当对表中的数据进行增加、删除和修改的时候，索引也需要维护，降低数据维护的速度

- 索引失效

  - 如果条件中有 or，即使其中有条件带索引也不会使用 (这就是问什么尽量少使用 or 的原因)
  - 对于多列索引，不是使用的第一部分，则不会使用索引
  - like 查询是以%开头
  - 如果列类型是字符串，那一定要在条件中使用引号引起来，否则不会使用索引
  - 如果 MySQL 估计使用全表扫秒比使用索引快，则不适用索引。

- 在什么情况下适合建立索引

  order by、group by、distinct

  union

  where、join

- 联合索引

  最左前缀匹配原则

  [mysql联合索引 - 沧海一滴 - 博客园](https://www.cnblogs.com/softidea/p/5977860.html)

  > mysql 会一直向右匹配直到遇到范围查询 (>、<、between、like) 就停止匹配，比如 a = 1 and b = 2 and c > 3 and d = 4 如果建立 (a,b,c,d) 顺序的索引，d 是用不到索引的，如果建立 (a,b,d,c) 的索引则都可以用到，a,b,d 的顺序可以任意调整。

- MYSQL 如何挑选索引？

- 参考链接

  [MySQL 索引总结](https://zhuanlan.zhihu.com/p/29118331)
  
  [我以为我对Mysql索引很了解，直到我遇到了阿里的面试官_HollisChuang's Blog-CSDN博客](https://blog.csdn.net/hollis_chuang/article/details/95167242)
  
  [数据库索引是如何工作的？ - 程序员和软件面试问题和答案 (programmerinterview.com)](https://www.programmerinterview.com/database-sql/what-is-an-index/)
  
  [一通骚操作，我把SQL执行效率提高了10000000倍！ - 知乎](https://zhuanlan.zhihu.com/p/71763823)



### 存储引擎

#### InnoDB

MySQL默认采用的是InnoDB。

了解他和 **MyISAM** 的主要区别。



##### 页结构

页是 InnoDB 管理存储空间的基本单位，一个页的大小一般是 16kb。

数据页可以大致划分为 7 个部分：

| 字段名             | 中文名             | 大小    | 简单描述                           |
| ------------------ | ------------------ | ------- | ---------------------------------- |
| File Header        | 文件头部           | 38 字节 | 页的一些通用信息                   |
| Page Header        | 页面头部           | 56 字节 | 数据页专有的一些信息               |
| Infimum + Supremum | 最小记录和最大记录 | 26 字节 | 两个虚拟的行记录                   |
| User Records       | 用户记录           | 不确定  | 实际存储的行记录内容（大小不确定） |
| Free Space         | 空闲空间           | 不确定  | 页中尚未使用的空间                 |
| Page Directory     | 页面目录           | 不确定  | 页中的某些记录的相对位置           |
| File Trailer       | 文件尾部           | 8 字节  | 校验页是否完整                     |

当涉及到数据库读写的时候，规定数据库每次读写都是以16k为单位的，一次最少从磁盘中读取16KB的内容到内存中，一次最少把内存中的16KB内容刷新到磁盘中。

​    

为什么默认为16kb？

在操作系统的文件管理系统中进行一次io读写，默认读取的大小为4kb（一页）。又因为局部性原理，操作系统会将命中的页周围的三块页一同加载进innodb的缓存池中，因此innnodb缓存池中页的大小为16kb。

​    

参考：

[MySQL架构（二）- InnoDB的存储结构](https://blog.csdn.net/qq_32078397/article/details/115560939)

[MySQL架构（三）- 磁盘存储数据页](https://blog.csdn.net/qq_32078397/article/details/115653204)





### 日志

日志类型

- 逻辑日志：存储了逻辑 SQL 修改语句
- 物理日志：存储了数据被修改的值



#### binlog

MySQL 的逻辑日志，也叫二进制日志、归档日志，用于记录用户对数据库操作的 SQL 语句（除了查询语句）信息，以**二进制的形式**保存在磁盘中。

日志格式：STATMENT、ROW 和 MIXED

STATMENT：基于 SQL 语句的复制，每一条会修改数据的 sql 语句会记录到 binlog 中，是 binlog 的默认格式。

ROW：基于行的复制，不记录每一条 SQL 语句的上下文信息，仅保存哪条记录被修改。

MIXED 模式是基于 STATMENT 和 ROW 两种模式的混合复制，一般的复制使用 STATEMENT 模式保存 binlog，对于 STATEMENT 模式无法复制的操作使用 ROW 模式保存 binlog，MySQL 会根据执行的 SQL 语句选择日志保存方式。



#### redo/undo log

redo log 是 MySQL 的物理日志，也叫重做日志，记录存储引擎 InnoDB 的事务日志。

MySQL 每执行一条 SQL 更新语句，不是每次数据更改都立刻写到磁盘，而是先将记录写到 redo log 里面，并更新内存（这时内存与磁盘的数据不一致，将这种有差异的数据称为脏页），一段时间后，再一次性将多个操作记录写到到磁盘上，这样可以减少磁盘 io 成本，提高操作速度。**先写日志，再写磁盘**，这就是 MySQL 里经常说到的 WAL 技术，即 Write-Ahead Logging，又叫预写日志。MySQL 通过 WAL 技术保证事务的持久性。

**Crash Safe**（宕机重启）：

有了 redo log，当数据库发生宕机重启后，可通过 redo log 将未落盘的数据（check point 之后的数据）恢复，保证已经提交的事务记录不会丢失，这种能力称为 crash-safe。
两阶段提交：

有了 redo log，为什么还需要 binlog 呢？先来看看 binlog 和 redo log 的区别：

<table>
   <tr>
      <th></th>
      <th>redo log</th>
      <th>binlog</th>
   </tr>
   <tr>
      <td> 文件大小 </td>
      <td>redo log 的大小是固定的。</td>
      <td>binlog 可通过配置参数 max_binlog_size 设置每个 binlog 文件的大小。</td>
   </tr>
   <tr>
      <td> 实现方式 </td>
      <td>redo log 是 InnoDB 引擎层实现的，并不是所有引擎都有。</td>
      <td>binlog 是 Server 层实现的，所有引擎都可以使用 binlog 日志。</td>
   </tr>
   <tr>
      <td> 记录方式 </td>
      <td>redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。日志上的记录修改落盘后，日志会被覆盖掉，无法用于数据回滚/数据恢复等操作。</td>
      <td>binlog 通过追加的方式记录，当文件大小大于给定值后，日志会发生滚动，之后的日志记录到新的文件上，不会覆盖以前的记录。</td>
   </tr>
</table>
​    

由 binlog 和 redo log 的区别可知：binlog 日志只用于归档，只依靠 binlog 是没有 crash-safe 能力的。但只有 redo log 也不行，因为 redo log 是 InnoDB 特有的，且日志上的记录落盘后会被覆盖掉。因此需要 binlog 和 redo log 二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。

​    

参考链接

[MySQL 的日志系统](https://www.cnblogs.com/ivy-zheng/p/11094528.html)

[Crash Safe 和 Binlog 的关系](https://blog.csdn.net/shaochenshuo/article/details/73239949)





### 备份与恢复

- 冷备份，热备份
  - cp，mysqldump，lvm2 快照，xtrabackup
- [mysql 误删数据快速恢复](https://www.cnblogs.com/-mrl/p/9959365.html)



### 高级

- explain

  explain 显示了 mysql 如何使用索引来处理 select 语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句。

- 如何快速的删除一张大（TB 级别）表？

  1. 区分 drop，truncate，delete
  2. 利用 linux 中**硬链接**

- 慢日志

  可以设置一个时间，那么所有执行时间超过这个时间的 SQL 都会被记录下来。这样就可以通过慢日志快速的找到网站中 SQL 的瓶颈来进行优化。



### 分布式

- **主从**复制，分库分表

- 分布式锁





### 参数优化



#### innodb_buffer_pool_size

**InnoDB buffer pool 里包含什么？**

- **数据缓存**
  InnoDB数据页面
- **索引缓存**
  索引数据
- **缓冲数据**
  脏页（在内存中修改尚未刷新(写入)到磁盘的数据）
- **内部结构**
  如自适应哈希索引，行锁等。



**如何设置innodb_buffer_pool_size?**
innodb_buffer_pool_size默认大小为128M。最大值取决于CPU的架构。在32-bit平台上，最大值为2^32 -1,在64-bit平台上最大值为2^64-1。当缓冲池大小大于1G时，将innodb_buffer_pool_instances设置大于1的值可以提高服务器的可扩展性。

大的缓冲池可以减小多次磁盘I/O访问相同的表数据。**在专用数据库服务器上，可以将缓冲池大小设置为服务器物理内存的80%。**





## Redis

### 概述

1. Redis 是一种基于键值对 (Key-Value) 的 NoSQL 数据库，Redis 的 **Value** 的基础数据结构有 string、list、hash、set、zset；
2. 有 **Bitmaps，HyperLoglog，Geographic** 等多种高级数据结构和算法
3. Redis 还提供了键过期，发布订阅，事务，Lua 脚本，哨兵，Cluster 等功能
4. Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用**复制来扩展读性能**，使用分片来扩展写性能



### 数据类型

string、list、hash、set、zset

**选择**

选择 hash 还是 string 存储数据？

**编码**

`encoding` 记录了对象所保存的值的编码

下图展示了 redisObject 、Redis 所有数据类型、以及 Redis 所有编码方式（底层实现）三者之间的关系：

![redis1](../img/code/redis1.png)



### 数据结构

字典 dictht

跳跃表，是有序集合的底层实现之一

5.0新数据结构Stream



### 过期

Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。

对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。



### 淘汰

可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。

LRU 算法和 **LFU 算法**，redis 对 LRU 的改进

[让我们一起聊聊如何改进 LRU 算法-改进leach算法 (51cto.com)](https://www.51cto.com/article/717466.html)



### 高可用

主从复制

Sentinel，Codis，Cluster

[Redis 数据倾斜问题 集群模式 redis集群 数据一致性](https://blog.51cto.com/u_16099336/6598110)

[Redis主从集群切换数据丢失问题如何应对？](https://blog.51cto.com/u_16147814/6399335)



### 数据一致性

- 产生原因

  1. 并发的场景下，导致读取老的 DB 数据，更新到缓存中。
  2. 缓存和 DB 的操作，不在一个事务中，可能只有一个操作成功，而另一个操作失败，导致不一致。




- 更新缓存的设计模式

  1. Cache Aside Pattern（旁路缓存，**常用**）

     - **失效**：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。

     - **命中**：应用程序从cache中取数据，取到后返回。

     - **更新**：先把数据存到数据库中，成功后，再让缓存失效。

  2. Read/Write Through Pattern

     把更新数据库的操作由缓存自己代理了，但**Cache自己更新数据库是一个同步操作**

  3. Write Behind Caching Pattern（游戏开发会常用）

     Write Behind 又叫 Write Back。Write Behind 就是 Linux 文件系统的 Page Cache 算法。

     Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。

     > 这个设计的好处就是让数据的 I/O 操作飞快无比（因为直接操作内存嘛），因为异步，write backg 还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。




- 数据库与缓存双写问题

  - 思考

    按照Cache Aside Pattern的更新，这种方式真的没问题吗？

  - 最终一致性的解决方案

    从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。

    这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。

    不依赖于给缓存设置过期时间的方案：

    1. 先更新数据库，再更新缓存

       会有冷数据（多写少读）

    2. 先删除缓存，再更新数据库

       A线程删缓存但未更新DB，B线程读并写入缓存导致脏数据。解决方案是使用延迟双删（第二次**删除失败**怎么办?）

    3. 先更新数据库，再删除缓存

       缓存刚好失效，A线程读并写入缓存，过程中穿插了B线程的更新DB删除缓存。概率极小，该方案可满足大部分的应用场景。

    （为什么没有先更新缓存，再更新数据库这种策略？若先更新缓存，缓存更新成功，但是更新数据库时发生异常导致回滚，那么缓存中的数据无法回滚，导致数据不一致。看产生原因的第二点）
    
    删除缓存失败：
    
    解决方案是消息队列或者其他 binlog 同步，引入消息队列会带来更多的问题，并不推荐直接使用。
    
    参考：
    
    - [缓存的双写一致性解决方案 解决redis与mysql数据一致性 看不懂的你来打我~_kingtok的博客](https://blog.csdn.net/kingtok/article/details/106689121)



- 一致性恢复方案

  TODO 如果出现了问题，怎么解决？

- 主从DB与cache一致性

  TODO

- 回顾一下分布式事务一致性，别混淆



### 应用场景

分布式锁、延时队列、位图、HyperLogLog、布隆过滤器、简单限流（zset）、漏斗限流、GeoHash（地理位置）

- 限流

  [Redis应用-限流 - 掘金 (juejin.cn)](https://juejin.cn/post/6844903880858451976)

- 分布式锁

  1. 单实例中实现分布式锁：

     setnx（注意删除时最好使用 Lua 脚本删除，逻辑是先获取 key，如果存在并且值是自己设置的就删除此 key，否则就跳过）

     set key value px milliseconds nx（使用 set 代替 setnx，相当于 setnx + expire 实现了原子性，不必担心 setnx 成功，expire 失败的问题）

  2. 多节点 redis 实现的分布式锁

     RedLock
     
     可以看看 redission 的实现

  参考：

  * [redis分布式锁深度剖析(超时情况)](https://blog.csdn.net/u010325193/article/details/87887030)
  * [Redlock：Redis分布式锁最牛逼的实现](https://mp.weixin.qq.com/s/JLEzNqQsx-Lec03eAsXFOQ)
  * [Redlock（redis分布式锁）原理分析 - RGC](https://www.cnblogs.com/rgcLOVEyaya/p/RGC_LOVE_YAYA_1003days.html)

- 缓存穿透解决方案

  增加校验，缓存，**布隆过滤器（Bloom Filter）**，hyperloglog



### 持久化

**RDB 持久化**

将某个时间点的所有数据都存放到硬盘上

**AOF 持久化**

将写命令添加到 AOF 文件（Append Only File）的末尾

**技术**

使用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久化

bgsave 做全量持久化到 RDB 二进制文件中，aof 做增量持久化，存储的是文本协议数据



### 额外的知识点

1. Redis 的线程模型：单线程，IO 多路复用

2. 客户端与服务器的通信协议

3. 管道，事务

   注意 redis 事务**不保证原子性**，**不支持回滚**。他总结来说：**就是一次性、顺序性、排他性的执行一个队列中的一系列命令**。其他客户端提交的命令请求不会插入到事务执行命令序列中。

   思考一下，为什么这样设计？

4. Info 指令

5. 源码

   - [带有详细注释的 Redis 3.0 代码](https://github.com/huangz1990/redis-3.0-annotated)
   - jemalloc，Redis 默认使用 jemalloc(facebook) 库来管理内存

6. 一些面试题

   - [《吊打面试官》系列-缓存雪崩、击穿、穿透](https://blog.csdn.net/qq_35190492/article/details/102889333)

7. Java 的 Redis 客户端：Jedis，Redisson

   1. Redisson 不仅封装了 redis ，还封装了对更多数据结构的支持，以及锁等功能，相比于 Jedis 更加大。

      Redisson 的加锁/释放锁都是用 Lua 脚本，相比于 setnx 就能实现，为何多此一举？仔细看 Lua 脚本就会发现考虑得非常全面，其中包括锁的**重入性**。

   2. 但 Jedis 相比于 Redisson 更原生一些，更灵活。



### Redis模块

- ReJSON模块

  ReJSON 是一个Redis Module，它实现了`ECMA-404 The JSON Data Interchange Standard`作为本地数据类型，它允许从Redis Keys（documents）中存储，更新和获取 JSON 值

  主要特性：

  1. 完全支持JSON标准
  2. 对于在文档内选择元素类似 JSONPath 语法
  3. 文档作为二进制数据被存储在一个树形结构中，允许快速访问子元素
  4. 对所有 JSON 数据类型按照原子操作进行分类

  ReJSON 是由 Redis Labs 开发的，源码下载地址是 https://github.com/RedisLabsModules/ReJSON



### 书单

- 《redis 设计与实现 (第二版)》
- 《Redis 深度历险:核心原理与应用实践》





## Memcache

- Redis 之与 Memcached 的比较





## MongoDB

* [为什么 Mongodb 索引用 B 树，而 Mysql 用 B+树?](https://www.cnblogs.com/rjzheng/p/12316685.html)





## Oracle

- 冷备份

  1. 正常关闭数据库
  2. 备份所有重要的文件到备份目录（数据文件、控制文件、重做日志文件等）
  3. 完成备份后启动数据库

- 热备份

- 数据恢复

  [几种oracle数据库恢复的练习示例](https://www.cnblogs.com/rootq/articles/1065048.html)
