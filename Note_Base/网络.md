# 《网络》





## 计算机网络



### TCP/IP 四层（参考）模型

[OSI 七层模型与 TCP/IP 四层（参考）模型](https://www.jianshu.com/p/c793a279f698)





### 底层网络协议

ARP，ICMP（网际控制信息协议），路由选择，DHCP，NAT





### TCP/IP

#### TCP三次握手和四次挥手

三次握手：

![TCP握手](../img/数据结构与算法/TCP握手.png)

四次挥手：

![TCP挥手](../img/数据结构与算法/TCP挥手.png)

**为什么TCP握手，客户端最后还要发送一次确认呢？**

> 这主要是为了防止已失效的连接请求报文段突然又传到了 TCP 服务器，避免产生错误。
>
> 两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。
>
> 如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。



**为什么TCP挥手，客户端最后还要等待2MSL？**

> 第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。
>
> 第二，同时在这段时间内，该链接在对话期间于网际路由上产生的残留报文(因为路径过于崎岖，数据报文走的时间太长，重传的报文都收到了，原始报文还在路上)传过来时，都会被立即丢弃掉。4分钟的时间足以使得这些残留报文彻底消逝。不然当新的端口被重复利用时，这些残留报文可能会干扰新的链接。



**为什么建立连接是三次握手，关闭连接确是四次挥手呢？**

> 建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。
>
> 而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。



**如果已经建立了连接，但是客户端突然出现故障了怎么办？**

> TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。



**要点**

> 1. 三次挥手是确保双方都能收和发的最少确认次数
> 2. 四次挥手中间的两步并不总是会合成一步走，因为服务端处于“半关闭状态”，可能还有剩下的消息没发完，客户端此时能收不能发
> 3. 四次挥手的 time_wait 状态，2MSL(MSL 为报文最大生存时间，一般 2 分钟，可更改)，作用是重传最后一个 ack 报文



**参考**

[跟着动画来学习 TCP 三次握手和四次挥手](https://juejin.im/post/5b29d2c4e51d4558b80b1d8c)

[两张动图，彻底明白TCP的三次握手与四次挥手 - 墨天轮 (modb.pro)](https://www.modb.pro/db/33340)



#### TCP拥塞算法

**慢开始 、 拥塞避免 、快重传 和 快恢复**

两者的区别：**流量控制**是为了预防拥塞。如：在马路上行车，交警跟红绿灯是流量控制，当发生拥塞时，如何进行疏散，是拥塞控制。流量控制指点对点通信量的控制。而**拥塞控制**是全局性的，涉及到所有的主机和降低网络性能的因素。



#### TCP 和 UDP 的区别

TCP/IP 协议是一个**协议簇**。里面包括很多协议的。UDP 只是其中的一个。之所以命名为 TCP/IP 协议，因为 TCP,IP 协议是两个很重要的协议，就用他两命名了。[原文](https://www.cnblogs.com/bizhu/archive/2012/05/12/2497493.html)

[网络编程懒人入门(四)：快速理解TCP和UDP的差异](http://www.52im.net/thread-1160-1-1.html)





#### 一台服务器最大并发 TCP 连接数多少

系统用一个4四元组来唯一标识一个TCP连接：{localip, localport,remoteip,remoteport}

理论：

一个 client 对同一个 remoteip,remoteport 最大tcp连接数为65535；

server 端 tcp 连接4元组中只有 remoteip（也就是clientip）和 remote port（客户端port）是可变的，因此最大tcp 连接为客户端 ip 数 × 客户端 port 数，对IPV4，不考虑ip地址分类等因素，最大 tcp 连接数约为 2 的 32 次方（ip数）×2 的 16 次方（port数），也就是 server 端单机最大 tcp 连接数约为2的48次方。

实际：事实上，真正影响TCP连接数量的，是服务器的内存以及允许单一进程同时打开文件的数量，因为每创建一个TCP连接都要创建一个socket句柄，每个socket句柄都占用一部分系统内存，当系统内存被占用殆尽，允许的TCP并发连接数也就到了上限。一般来讲，通过增加服务器内存、修改最大文件描述符个数等，可以做到单台服务器支持10万+的TCP并发。

参考：

[一台服务器最大并发 TCP 连接数多少 - 网安 (wangan.com)](https://www.wangan.com/p/11v6ca748b341e6e)

[一台主机最多能创建多少个 TCP 连接？-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1825246)

注意：

一个进程**默认**打开文件的个数 1024，可修改。





#### 问题

1. “一个tcp服务端和一个tcp客户端，客户端和服务端建立连接后，服务端一直sleep，然后客户端一直发送数据会是什么现象”

   [【底层原理】一道高频腾讯面试题:tcp数据发送问题 (qq.com)](https://mp.weixin.qq.com/s/rpNTjTUt19Bbyx6IWm2-ig)

2. 没有accept，能建立TCP连接吗？

   [动图图解！没有accept，能建立TCP连接吗？ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzkxNTU5MjE0MQ==&mid=2247492926&idx=1&sn=b6d254b5aa11ffaae093c919c1b1fab8&source=41#wechat_redirect)





### http/https

- [彻底掌握网络通信](https://blog.csdn.net/yi_master/article/details/82863949) (httpclien，asynchttpclient，HttpURLConnection，OkHttp3)
- 一次经典的错误：https://github.com/Ariescat/lqz-test/blob/master/base-test/src/main/http/http.log





### websocket

背景：

- 因为 HTTP 协议有一个缺陷：通信只能由客户端发起
- 我们都知道轮询的效率低，非常浪费资源（因为必须不停连接，或者 HTTP 连接始终打开）, 因此websocket应运而生。

WebSocket用于在Web浏览器和服务器之间进行任意的双向数据传输的一种技术。





### ping 的实现

1. 首先查本地 arp cache 信息，看是否有对方的 mac 地址和 IP 地址映射条目记录
2. 如果没有，则发起一个 arp 请求广播包，等待对方告知具体的 mac 地址
3. 收到 arp 响应包之后，获得某个 IP 对应的具体 mac 地址，有了物理地址之后才可以开始通信了,同时对 ip-mac 地址做一个本地 cache
4. 发出 icmp echo request 包，收到 icmp echo reply 包





### 其他

- 反向代理为何叫反向代理？[原文](https://www.zhihu.com/question/24723688/answer/128105528)

- IPv6

  [网络编程懒人入门(十一)：一文读懂什么是IPv6-网络编程](http://www.52im.net/thread-2979-1-1.html)







## 网络安全

- 攻击

  - DDoS 攻击
  - XSS攻击

- 非对称加密

  在非对称加密中使用的主要算法有：RSA、Elgamal、Rabin、D-H（Diffie-Hellman）、ECC（椭圆曲线加密算法）等

  - https

    https 客户端无法判断自己收到的服务器的公钥是否是正确的，是否在服务器发送给客户端的过程中被第三方篡改了，所以还需要证明公开密钥正确性的数字证书。

    https 可以解决中间人劫持？

  - ssl/tls

    了解他们的握手过程

  - ssh

  - 数字签名，数字证书

    浏览器一般怎样校验证书呢？

  - 了解几个本质：（[原文](https://www.sohu.com/a/294450321_100134138)）

    1. 解决内容可能被窃听的问题——非对称加密
    2. 解决报文可能遭篡改问题——数字签名
    3. 解决通信方身份可能被伪装的问题——认证

- oauth协议

  如果不理解oauth协议的推荐阅读 阮一峰的 [理解OAuth 2.0](http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html)







## 多路复用



### 同步阻塞概念

**同步、异步：**

- 概念：消息的通知机制
- 解释：涉及到 IO 通知机制；所谓同步，就是发起调用后，被调用者处理消息，必须等处理完才直接返回结果，**没处理完之前是不返回的，调用者主动等待结果**；所谓异步，就是发起调用后，被调用者直接返回，但是并没有返回结果，等处理完消息后，通过状态、通知或者回调函数来通知调用者，调用者被动接收结果。

**阻塞、非阻塞：**

- 概念：**程序等待调用结果时的状态**
- 解释：涉及到 CPU 线程调度；所谓阻塞，就是调用结果返回之前，该执行线程会被挂起，不释放 CPU 执行权，线程不能做其它事情，只能等待，只有等到调用结果返回了，才能接着往下执行；所谓非阻塞，就是在没有获取调用结果时，不是一直等待，线程可以往下执行，如果是同步的，通过轮询的方式检查有没有调用结果返回，如果是异步的，会通知回调。



### I/O 模型

- 阻塞式 I/O
- 非阻塞式 I/O
- I/O 复用
- 信号驱动 I/O
- 异步 I/O
- 五大 I/O 模型比较

参考链接：

1. [IO 复用,AIO,BIO,NIO,同步，异步，阻塞和非阻塞 区别](https://www.cnblogs.com/aspirant/p/6877350.html)
2. [网络 IO 中的同步、异步、阻塞和非阻塞](https://ariescat.top/2019/02/14/%E7%BD%91%E7%BB%9CIO%E4%B8%AD%E7%9A%84%E5%90%8C%E6%AD%A5-%E5%BC%82%E6%AD%A5-%E9%98%BB%E5%A1%9E%E5%92%8C%E9%9D%9E%E9%98%BB%E5%A1%9E/)
3. [迄今为止把同步/异步/阻塞/非阻塞/BIO/NIO/AIO 讲的最清楚的好文章](https://juejin.im/post/5cff70c0f265da1ba56b14fd)
4. 《Netty Zookeeper Redis 高并发实战》[2.2 节](https://weread.qq.com/web/reader/1e732510718f63a11e7dee2k6f4322302126f4922f45dec)
5. [9.3 高性能网络模式：Reactor 和 Proactor | 小林coding (xiaolincoding.com)](https://www.xiaolincoding.com/os/8_network_system/reactor.html#演进)





### Socket

在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列：

- 一个是「还没完全建立」连接的队列，称为 **TCP 半连接队列**，这个队列都是没有完成三次握手的连接，此时服务端处于 `syn_rcvd` 的状态；
- 一个是「已经建立」连接的队列，称为 **TCP 全连接队列**，这个队列都是完成了三次握手的连接，此时服务端处于 `established` 状态；

当 TCP 全连接队列不为空后，服务端的 `accept()` 函数，就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket。

注意，监听的 Socket 和真正用来传数据的 Socket 是两个：

- 一个叫作**监听 Socket**；
- 一个叫作**已连接 Socket**；

参考：

[9.2 I/O 多路复用：select/poll/epoll | 小林coding (xiaolincoding.com)](https://www.xiaolincoding.com/os/8_network_system/selete_poll_epoll.html#最基本的-socket-模型)





### select/poll/epoll

select 实现多路复用的方式是，将已连接的 Socket 都放到一个**文件描述符集合**，然后调用 select 函数将文件描述符集合**拷贝**到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过**遍历**文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合**拷贝**回用户态里，然后用户态还需要再通过**遍历**的方法找到可读或可写的 Socket，然后再对其处理。

所以，对于 select 这种方式，需要进行 **2 次「遍历」文件描述符集合**，一次是在内核态里，一个次是在用户态里 ，而且还会发生 **2 次「拷贝」文件描述符集合**，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 `1024`，只能监听 0~1023 的文件描述符。

poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。

但是 poll 和 select 并没有太大的本质区别，**都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合**，这种方式随着并发数上来，性能的损耗会呈指数级增长。

​    

epoll 通过两个方面，很好解决了 select/poll 的问题。

*第一点*，epoll 在内核里使用**红黑树来跟踪进程所有待检测的文件描述字**，把需要监控的 socket 通过 `epoll_ctl()` 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 `O(logn)`。而 select/poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。

*第二点*， epoll 使用**事件驱动**的机制，内核里**维护了一个链表来记录就绪事件**，当某个 socket 有事件发生时，通过**回调函数**内核会将其加入到这个就绪事件列表中，当用户调用 `epoll_wait()` 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。



#### epoll 边缘触发和水平触发

- 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，**服务器端只会从 epoll_wait 中苏醒一次**，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；
- 使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**，目的是告诉我们有数据需要读取；





### Reactor 模式

Netty的架构模式是在此基础上演变而来的

个人认为 netty 对用户来说是异步，但是实际底层 IO 是 IO 多路复用模型，本质上还是一种同步非阻塞（是的，个人认为 IO 多路复用模型还是**同步**非阻塞，并且**真正的 IO 操作都将阻塞应用线程**），他只是多了一个 Selector（需要底层操作系统支持），如此一个线程就可以控制大量的通信（相比传统 IO，不管他是不是非阻塞）。



#### 真正的 IO 操作都将阻塞应用线程

因为在 read 调用时，内核将数据从内核空间拷贝到用户空间的过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。



#### IO 操作的真正耗时

我们开始以为 write 操作是要等到对方收到消息才会返回，但实际上不是这样的。write 操作只负责将数据写到本地操作系统内核的发送缓冲然后就返回了。剩下的事交给操作系统内核异步将数据送到目标机器。但是如果发送缓冲满了，那么就需要等待缓冲空出空闲空间来，这个就是写操作 IO 操作的真正耗时。

我们开始以为 read 操作是从目标机器拉取数据，但实际上不是这样的。read 操作只负责将数据从本地操作系统内核的接收缓冲中取出来就了事了。但是如果缓冲是空的，那么就需要等待数据到来，这个就是读操作 IO 操作的真正耗时。

这里可以配合《Netty、Redis、Zookeeper 高并发实战》2.2 节四种主要的 IO 模型来看一下。





### Proactor 模式

Boost.Asio用的是Proactor模式（看[C++/boost/asio](/_Code/C++.md#第三方库)）。

Proactor/Reactor模式也是否相像，二者都靠消息来驱动，都有回调函数，Proactor中，系统为你做了更多，告诉你结果，Reactor中，只是告诉你有事情发生了，可以做点什么了。

需要说明的是，并不是所有场合非阻塞异步方式的性能都最高，其实活还是那么多，系统帮你多做了些而已。如果只有少数几个连接，多线程+同步方式也许更适合。







## 零拷贝

- [Java 中的零拷贝](https://www.jianshu.com/p/2fd2f03b4cc3)

  这篇文章耐心看完，他讲的是真透彻，他从概念上区分了广义和狭义零拷贝，讲解了系统底层层面上的，JDK NIO 层面上的，Kafka、Netty 层面上的。

- [零拷贝 敖丙](https://mp.weixin.qq.com/s?__biz=MzAwNDA2OTM1Ng==&mid=2453146714&idx=2&sn=fa45883a655b280c949d0e1c33f4d844&scene=21#wechat_redirect)



#### DMA 技术

DMA 是一种**允许外围设备（硬件子系统）直接访问系统主内存的机制**。也就是说，基于 DMA 访问方式，系统主内存于硬盘或网卡之间的数据传输可以绕开 CPU 的调度。

参考：[DMA 技术是什么，在哪里用？看完绝对有收获 - 简书 (jianshu.com)](https://www.jianshu.com/p/3a26e8c9f402)



#### Linux 支持的 (常见) 零拷贝

mmap 内存映射，sendfile（linux 2.1 支持），Sendfile With DMA Scatter/Gather Copy（可以看作是 sendfile 的增强版，批量 sendfile），splice（linux 2.6.17 支持）。

Linux 零拷贝机制对比：无论是传统 IO 方式，还是引入零拷贝之后，2 次 DMA copy 是都少不了的。因为两次 DMA 都是依赖硬件完成的。



#### PageCache

磁盘高速缓存

主要是两个优点：缓存最近被访问的数据，预读功能

但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DRM 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能

大文件传输

「异步 I/O + 直接 I/O」来替代零拷贝技术



#### 直接 I/O

Liunx 提供了对这种需求的支持，即在 open() 系统调用中增加参数选项 O_DIRECT， 用它打开的文件便可以绕过内核缓冲区的直接访问，这样便有效避免了 CPU 和内存的多余时间开销。

Java本身并不支持直接IO。



#### Java NIO

- Java NIO 引入了用于通道的缓冲区的 ByteBuffer。 ByteBuffer 有三个主要的实现：

  HeapByteBuffer，DirectByteBuffer，MappedByteBuffer



#### Netty 中的零拷贝

Netty 中的 Zero-copy 与上面我们所提到到 OS 层面上的 Zero-copy 不太一样, Netty 的 Zero-copy 完全是在用户态 (Java 层面) 的，它的 Zero-copy 的更多的是偏向于优化数据操作这样的概念。

- Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝。
- 通过 wrap 操作，我们可以将 byte[] 数组、ByteBuf、 ByteBuffer 等包装成一个 Netty ByteBuf 对象，进而避免了拷贝操作。
- ByteBuf 支持 slice 操作，因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝。
- 通过 FileRegion 包装的 FileChannel.tranferTo 实现文件传输，可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环 write 方式导致的内存拷贝问题。

**前三个都是 广义零拷贝，都是减少不必要数据 copy；偏向于应用层数据优化的操作。**

